{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "from csv import writer\n",
    "\n",
    "\n",
    "\n",
    "#tensorflow import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.activations import relu,linear\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#logging\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "#custom functions import\n",
    "from ts_functions import time_window_generator\n",
    "from aux_functions import aux_functions\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option flags\n",
    "debug_mode = True\n",
    "debug_output_n = 2\n",
    "\n",
    "performance_log = True\n",
    "data_log_csv_path = \"training_log/newframe_sm_ma_hs300_30win.csv\"\n",
    "\n",
    "\n",
    "#tensorboard logging doesnt work for now\n",
    "tf_log_dir = \"logs/LSTM_stocks/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e2e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "filename = os.path.join(fileDir, r\"stock_data\\index300_05_22_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5903b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['change']\n",
    "\n",
    "df = pd.read_csv(filename).drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c452ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600783.SH</td>\n",
       "      <td>20221215</td>\n",
       "      <td>13.63</td>\n",
       "      <td>13.63</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>38397.67</td>\n",
       "      <td>51819.5570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600783.SH</td>\n",
       "      <td>20221214</td>\n",
       "      <td>13.54</td>\n",
       "      <td>13.82</td>\n",
       "      <td>13.42</td>\n",
       "      <td>13.55</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>57557.68</td>\n",
       "      <td>78307.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600783.SH</td>\n",
       "      <td>20221213</td>\n",
       "      <td>13.12</td>\n",
       "      <td>13.65</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.46</td>\n",
       "      <td>13.24</td>\n",
       "      <td>1.6616</td>\n",
       "      <td>74087.26</td>\n",
       "      <td>99829.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600783.SH</td>\n",
       "      <td>20221212</td>\n",
       "      <td>13.25</td>\n",
       "      <td>13.46</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.29</td>\n",
       "      <td>-0.3762</td>\n",
       "      <td>60428.45</td>\n",
       "      <td>79917.9930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600783.SH</td>\n",
       "      <td>20221209</td>\n",
       "      <td>13.56</td>\n",
       "      <td>13.60</td>\n",
       "      <td>13.19</td>\n",
       "      <td>13.29</td>\n",
       "      <td>13.53</td>\n",
       "      <td>-1.7738</td>\n",
       "      <td>66449.00</td>\n",
       "      <td>88408.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743021</th>\n",
       "      <td>002064.SZ</td>\n",
       "      <td>20060829</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>58861.23</td>\n",
       "      <td>56827.0509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743022</th>\n",
       "      <td>002064.SZ</td>\n",
       "      <td>20060828</td>\n",
       "      <td>9.61</td>\n",
       "      <td>9.91</td>\n",
       "      <td>9.42</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.54</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>75694.74</td>\n",
       "      <td>73239.1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743023</th>\n",
       "      <td>002064.SZ</td>\n",
       "      <td>20060825</td>\n",
       "      <td>9.22</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.13</td>\n",
       "      <td>9.54</td>\n",
       "      <td>9.28</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>121564.97</td>\n",
       "      <td>115534.6703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743024</th>\n",
       "      <td>002064.SZ</td>\n",
       "      <td>20060824</td>\n",
       "      <td>8.91</td>\n",
       "      <td>9.37</td>\n",
       "      <td>8.85</td>\n",
       "      <td>9.28</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>110143.17</td>\n",
       "      <td>100371.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743025</th>\n",
       "      <td>002064.SZ</td>\n",
       "      <td>20060823</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.55</td>\n",
       "      <td>8.97</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.70</td>\n",
       "      <td>37.0100</td>\n",
       "      <td>240612.86</td>\n",
       "      <td>220646.6362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743026 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts_code  trade_date   open   high    low  close  pre_close  \\\n",
       "0        600783.SH    20221215  13.63  13.63  13.38  13.58      13.55   \n",
       "1        600783.SH    20221214  13.54  13.82  13.42  13.55      13.46   \n",
       "2        600783.SH    20221213  13.12  13.65  13.10  13.46      13.24   \n",
       "3        600783.SH    20221212  13.25  13.46  13.04  13.24      13.29   \n",
       "4        600783.SH    20221209  13.56  13.60  13.19  13.29      13.53   \n",
       "...            ...         ...    ...    ...    ...    ...        ...   \n",
       "1743021  002064.SZ    20060829   9.60   9.79   9.50   9.65       9.63   \n",
       "1743022  002064.SZ    20060828   9.61   9.91   9.42   9.63       9.54   \n",
       "1743023  002064.SZ    20060825   9.22  10.00   9.13   9.54       9.28   \n",
       "1743024  002064.SZ    20060824   8.91   9.37   8.85   9.28       9.18   \n",
       "1743025  002064.SZ    20060823   9.00   9.55   8.97   9.18       6.70   \n",
       "\n",
       "         pct_chg        vol       amount  \n",
       "0         0.2214   38397.67   51819.5570  \n",
       "1         0.6686   57557.68   78307.7080  \n",
       "2         1.6616   74087.26   99829.4500  \n",
       "3        -0.3762   60428.45   79917.9930  \n",
       "4        -1.7738   66449.00   88408.6250  \n",
       "...          ...        ...          ...  \n",
       "1743021   0.2100   58861.23   56827.0509  \n",
       "1743022   0.9400   75694.74   73239.1825  \n",
       "1743023   2.8000  121564.97  115534.6703  \n",
       "1743024   1.0900  110143.17  100371.4400  \n",
       "1743025  37.0100  240612.86  220646.6362  \n",
       "\n",
       "[1743026 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53bd7e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "      <td>1.743026e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.015044e+07</td>\n",
       "      <td>2.407597e+01</td>\n",
       "      <td>2.461099e+01</td>\n",
       "      <td>2.359643e+01</td>\n",
       "      <td>2.411183e+01</td>\n",
       "      <td>2.409182e+01</td>\n",
       "      <td>9.849662e-02</td>\n",
       "      <td>3.072499e+05</td>\n",
       "      <td>4.143607e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.886860e+04</td>\n",
       "      <td>5.550575e+01</td>\n",
       "      <td>5.663507e+01</td>\n",
       "      <td>5.447674e+01</td>\n",
       "      <td>5.558351e+01</td>\n",
       "      <td>5.553809e+01</td>\n",
       "      <td>3.230163e+00</td>\n",
       "      <td>7.277838e+05</td>\n",
       "      <td>8.559828e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.005051e+07</td>\n",
       "      <td>1.700000e-01</td>\n",
       "      <td>1.800000e-01</td>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>1.700000e-01</td>\n",
       "      <td>1.700000e-01</td>\n",
       "      <td>-4.906000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.872000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.011082e+07</td>\n",
       "      <td>6.710000e+00</td>\n",
       "      <td>6.840000e+00</td>\n",
       "      <td>6.600000e+00</td>\n",
       "      <td>6.720000e+00</td>\n",
       "      <td>6.720000e+00</td>\n",
       "      <td>-1.326700e+00</td>\n",
       "      <td>4.509841e+04</td>\n",
       "      <td>6.219120e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.016011e+07</td>\n",
       "      <td>1.265000e+01</td>\n",
       "      <td>1.293000e+01</td>\n",
       "      <td>1.241000e+01</td>\n",
       "      <td>1.268000e+01</td>\n",
       "      <td>1.267000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.195087e+05</td>\n",
       "      <td>1.619238e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.019101e+07</td>\n",
       "      <td>2.469000e+01</td>\n",
       "      <td>2.520000e+01</td>\n",
       "      <td>2.420000e+01</td>\n",
       "      <td>2.472000e+01</td>\n",
       "      <td>2.470000e+01</td>\n",
       "      <td>1.390000e+00</td>\n",
       "      <td>3.034760e+05</td>\n",
       "      <td>4.145728e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.022122e+07</td>\n",
       "      <td>2.587980e+03</td>\n",
       "      <td>2.627880e+03</td>\n",
       "      <td>2.485000e+03</td>\n",
       "      <td>2.601000e+03</td>\n",
       "      <td>2.601000e+03</td>\n",
       "      <td>6.210000e+02</td>\n",
       "      <td>5.135467e+07</td>\n",
       "      <td>6.999139e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         trade_date          open          high           low         close  \\\n",
       "count  1.743026e+06  1.743026e+06  1.743026e+06  1.743026e+06  1.743026e+06   \n",
       "mean   2.015044e+07  2.407597e+01  2.461099e+01  2.359643e+01  2.411183e+01   \n",
       "std    4.886860e+04  5.550575e+01  5.663507e+01  5.447674e+01  5.558351e+01   \n",
       "min    2.005051e+07  1.700000e-01  1.800000e-01  1.600000e-01  1.700000e-01   \n",
       "25%    2.011082e+07  6.710000e+00  6.840000e+00  6.600000e+00  6.720000e+00   \n",
       "50%    2.016011e+07  1.265000e+01  1.293000e+01  1.241000e+01  1.268000e+01   \n",
       "75%    2.019101e+07  2.469000e+01  2.520000e+01  2.420000e+01  2.472000e+01   \n",
       "max    2.022122e+07  2.587980e+03  2.627880e+03  2.485000e+03  2.601000e+03   \n",
       "\n",
       "          pre_close       pct_chg           vol        amount  \n",
       "count  1.743026e+06  1.743026e+06  1.743026e+06  1.743026e+06  \n",
       "mean   2.409182e+01  9.849662e-02  3.072499e+05  4.143607e+05  \n",
       "std    5.553809e+01  3.230163e+00  7.277838e+05  8.559828e+05  \n",
       "min    1.700000e-01 -4.906000e+01  5.000000e+00  1.872000e+00  \n",
       "25%    6.720000e+00 -1.326700e+00  4.509841e+04  6.219120e+04  \n",
       "50%    1.267000e+01  0.000000e+00  1.195087e+05  1.619238e+05  \n",
       "75%    2.470000e+01  1.390000e+00  3.034760e+05  4.145728e+05  \n",
       "max    2.601000e+03  6.210000e+02  5.135467e+07  6.999139e+07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf46ce7",
   "metadata": {},
   "source": [
    "# Model DataFrame preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b5e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stocks :  577\n"
     ]
    }
   ],
   "source": [
    "#split data into different stock\n",
    "# stock_list = [x.sort_values(\"trade_date\", ascending = True) for _,x in df.groupby('ts_code')]\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ts_code, x in df.groupby('ts_code'):\n",
    "    stock_list.append(x.copy().sort_values(\"trade_date\", ascending = True).reset_index().drop('index', axis=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sort by trade_date, ascending\n",
    "if debug_mode:\n",
    "    print(\"number of stocks : \", len(stock_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HS300 into the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_trade_date</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>20050509</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>934.6500</td>\n",
       "      <td>937.3900</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>932.3950</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>20050510</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>905.5430</td>\n",
       "      <td>913.3880</td>\n",
       "      <td>892.3130</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>20050511</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>911.8380</td>\n",
       "      <td>917.2230</td>\n",
       "      <td>900.4380</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>20050512</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>899.9680</td>\n",
       "      <td>900.0630</td>\n",
       "      <td>883.5110</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>20050513</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221209</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221212</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221213</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221214</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221215</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4286 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index_trade_date  index_open  index_high  index_low  index_close  \\\n",
       "4285          20050509    909.1740    934.6500   937.3900     909.1740   \n",
       "4284          20050510    913.0760    905.5430   913.3880     892.3130   \n",
       "4283          20050511    901.8510    911.8380   917.2230     900.4380   \n",
       "4282          20050512    885.8200    899.9680   900.0630     883.5110   \n",
       "4281          20050513    887.5430    883.5050   898.5050     875.5760   \n",
       "...                ...         ...         ...        ...          ...   \n",
       "4             20221209   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "3             20221212   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "2             20221213   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "1             20221214   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "0             20221215   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  \n",
       "4285         932.3950        -2.4905  \n",
       "4284         909.1740         0.4292  \n",
       "4283         913.0760        -1.2294  \n",
       "4282         901.8510        -1.7776  \n",
       "4281         885.8200         0.1945  \n",
       "...               ...            ...  \n",
       "4           3959.1798         0.9867  \n",
       "3           3998.2442        -1.1205  \n",
       "2           3953.4433        -0.1963  \n",
       "1           3945.6813         0.2333  \n",
       "0           3954.8857        -0.0733  \n",
       "\n",
       "[4286 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hs300_filename = os.path.join(fileDir, r\"stock_data\\hs300index_05_22_day.csv\")\n",
    "\n",
    "df_hs300 = pd.read_csv(hs300_filename).drop(['index_ts_code', 'index_vol', 'index_change', 'index_amount'], axis=1).sort_values(\"index_trade_date\", ascending = True)\n",
    "\n",
    "display(df_hs300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #append hs300 by matching dates\n",
    "# invalid_stock_list = []# the stock that is fucked\n",
    "\n",
    "\n",
    "# for i in range(len(stock_list)):\n",
    "#     stock = stock_list[i]\n",
    "#     if stock['trade_date'].iloc[-1] != df_hs300['index_trade_date'].iloc[-1]:\n",
    "#         invalid_stock_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in invalid_stock_list:\n",
    "# #     print(stock_list[i].head(1))\n",
    "\n",
    "# invalid_stock_list = sorted(invalid_stock_list, reverse=True)\n",
    "\n",
    "# print(invalid_stock_list)\n",
    "\n",
    "\n",
    "# for i in invalid_stock_list:\n",
    "#     stock_list.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_trade_date</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20050509</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>934.6500</td>\n",
       "      <td>937.3900</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>932.3950</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20050510</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>905.5430</td>\n",
       "      <td>913.3880</td>\n",
       "      <td>892.3130</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20050511</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>911.8380</td>\n",
       "      <td>917.2230</td>\n",
       "      <td>900.4380</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20050512</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>899.9680</td>\n",
       "      <td>900.0630</td>\n",
       "      <td>883.5110</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20050513</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>20221209</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>20221212</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>20221213</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>20221214</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>20221215</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3919 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index_trade_date  index_open  index_high  index_low  index_close  \\\n",
       "0             20050509    909.1740    934.6500   937.3900     909.1740   \n",
       "1             20050510    913.0760    905.5430   913.3880     892.3130   \n",
       "2             20050511    901.8510    911.8380   917.2230     900.4380   \n",
       "3             20050512    885.8200    899.9680   900.0630     883.5110   \n",
       "4             20050513    887.5430    883.5050   898.5050     875.5760   \n",
       "...                ...         ...         ...        ...          ...   \n",
       "3914          20221209   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "3915          20221212   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "3916          20221213   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "3917          20221214   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "3918          20221215   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  \n",
       "0            932.3950        -2.4905  \n",
       "1            909.1740         0.4292  \n",
       "2            913.0760        -1.2294  \n",
       "3            901.8510        -1.7776  \n",
       "4            885.8200         0.1945  \n",
       "...               ...            ...  \n",
       "3914        3959.1798         0.9867  \n",
       "3915        3998.2442        -1.1205  \n",
       "3916        3953.4433        -0.1963  \n",
       "3917        3945.6813         0.2333  \n",
       "3918        3954.8857        -0.0733  \n",
       "\n",
       "[3919 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050509</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.88</td>\n",
       "      <td>-10.0300</td>\n",
       "      <td>15363.61</td>\n",
       "      <td>8531.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050510</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.29</td>\n",
       "      <td>-2.8400</td>\n",
       "      <td>13096.90</td>\n",
       "      <td>6571.2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050511</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.14</td>\n",
       "      <td>-0.1900</td>\n",
       "      <td>13298.00</td>\n",
       "      <td>6937.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050512</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.13</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>9775.74</td>\n",
       "      <td>5111.7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050513</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.9400</td>\n",
       "      <td>22874.01</td>\n",
       "      <td>12752.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221209</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.7937</td>\n",
       "      <td>242420.92</td>\n",
       "      <td>60641.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221212</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-1.6000</td>\n",
       "      <td>219788.92</td>\n",
       "      <td>54104.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221213</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.4065</td>\n",
       "      <td>153038.00</td>\n",
       "      <td>37742.1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221214</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-2.0243</td>\n",
       "      <td>222385.00</td>\n",
       "      <td>54181.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221215</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>171399.00</td>\n",
       "      <td>41672.3920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3919 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts_code  trade_date  open  high   low  close  pre_close  pct_chg  \\\n",
       "0     000008.SZ    20050509  5.89  6.10  5.29   5.29       5.88 -10.0300   \n",
       "1     000008.SZ    20050510  5.19  5.24  4.85   5.14       5.29  -2.8400   \n",
       "2     000008.SZ    20050511  5.08  5.34  5.06   5.13       5.14  -0.1900   \n",
       "3     000008.SZ    20050512  5.13  5.32  5.06   5.23       5.13   1.9500   \n",
       "4     000008.SZ    20050513  5.34  5.75  5.25   5.75       5.23   9.9400   \n",
       "...         ...         ...   ...   ...   ...    ...        ...      ...   \n",
       "3914  000008.SZ    20221209  2.51  2.54  2.48   2.50       2.52  -0.7937   \n",
       "3915  000008.SZ    20221212  2.50  2.50  2.44   2.46       2.50  -1.6000   \n",
       "3916  000008.SZ    20221213  2.45  2.48  2.45   2.47       2.46   0.4065   \n",
       "3917  000008.SZ    20221214  2.48  2.48  2.41   2.42       2.47  -2.0243   \n",
       "3918  000008.SZ    20221215  2.43  2.45  2.40   2.44       2.42   0.8264   \n",
       "\n",
       "            vol      amount  \n",
       "0      15363.61   8531.0565  \n",
       "1      13096.90   6571.2745  \n",
       "2      13298.00   6937.8679  \n",
       "3       9775.74   5111.7443  \n",
       "4      22874.01  12752.0454  \n",
       "...         ...         ...  \n",
       "3914  242420.92  60641.4020  \n",
       "3915  219788.92  54104.7550  \n",
       "3916  153038.00  37742.1110  \n",
       "3917  222385.00  54181.2000  \n",
       "3918  171399.00  41672.3920  \n",
       "\n",
       "[3919 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_trade_date</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>20050509</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>934.6500</td>\n",
       "      <td>937.3900</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>932.3950</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>20050510</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>905.5430</td>\n",
       "      <td>913.3880</td>\n",
       "      <td>892.3130</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>20050511</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>911.8380</td>\n",
       "      <td>917.2230</td>\n",
       "      <td>900.4380</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>20050512</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>899.9680</td>\n",
       "      <td>900.0630</td>\n",
       "      <td>883.5110</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>20050513</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221209</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221212</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221213</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221214</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221215</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4286 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index_trade_date  index_open  index_high  index_low  index_close  \\\n",
       "4285          20050509    909.1740    934.6500   937.3900     909.1740   \n",
       "4284          20050510    913.0760    905.5430   913.3880     892.3130   \n",
       "4283          20050511    901.8510    911.8380   917.2230     900.4380   \n",
       "4282          20050512    885.8200    899.9680   900.0630     883.5110   \n",
       "4281          20050513    887.5430    883.5050   898.5050     875.5760   \n",
       "...                ...         ...         ...        ...          ...   \n",
       "4             20221209   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "3             20221212   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "2             20221213   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "1             20221214   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "0             20221215   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  \n",
       "4285         932.3950        -2.4905  \n",
       "4284         909.1740         0.4292  \n",
       "4283         913.0760        -1.2294  \n",
       "4282         901.8510        -1.7776  \n",
       "4281         885.8200         0.1945  \n",
       "...               ...            ...  \n",
       "4           3959.1798         0.9867  \n",
       "3           3998.2442        -1.1205  \n",
       "2           3953.4433        -0.1963  \n",
       "1           3945.6813         0.2333  \n",
       "0           3954.8857        -0.0733  \n",
       "\n",
       "[4286 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_trade_date</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050509</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.88</td>\n",
       "      <td>-10.0300</td>\n",
       "      <td>15363.61</td>\n",
       "      <td>8531.0565</td>\n",
       "      <td>20050509</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>934.6500</td>\n",
       "      <td>937.3900</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>932.3950</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050510</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.29</td>\n",
       "      <td>-2.8400</td>\n",
       "      <td>13096.90</td>\n",
       "      <td>6571.2745</td>\n",
       "      <td>20050510</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>905.5430</td>\n",
       "      <td>913.3880</td>\n",
       "      <td>892.3130</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050511</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.14</td>\n",
       "      <td>-0.1900</td>\n",
       "      <td>13298.00</td>\n",
       "      <td>6937.8679</td>\n",
       "      <td>20050511</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>911.8380</td>\n",
       "      <td>917.2230</td>\n",
       "      <td>900.4380</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050512</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.13</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>9775.74</td>\n",
       "      <td>5111.7443</td>\n",
       "      <td>20050512</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>899.9680</td>\n",
       "      <td>900.0630</td>\n",
       "      <td>883.5110</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20050513</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.23</td>\n",
       "      <td>9.9400</td>\n",
       "      <td>22874.01</td>\n",
       "      <td>12752.0454</td>\n",
       "      <td>20050513</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221209</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.7937</td>\n",
       "      <td>242420.92</td>\n",
       "      <td>60641.4020</td>\n",
       "      <td>20221209</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221212</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-1.6000</td>\n",
       "      <td>219788.92</td>\n",
       "      <td>54104.7550</td>\n",
       "      <td>20221212</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221213</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.4065</td>\n",
       "      <td>153038.00</td>\n",
       "      <td>37742.1110</td>\n",
       "      <td>20221213</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221214</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-2.0243</td>\n",
       "      <td>222385.00</td>\n",
       "      <td>54181.2000</td>\n",
       "      <td>20221214</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>000008.SZ</td>\n",
       "      <td>20221215</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>171399.00</td>\n",
       "      <td>41672.3920</td>\n",
       "      <td>20221215</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3919 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts_code  trade_date  open  high   low  close  pre_close  pct_chg  \\\n",
       "0     000008.SZ    20050509  5.89  6.10  5.29   5.29       5.88 -10.0300   \n",
       "1     000008.SZ    20050510  5.19  5.24  4.85   5.14       5.29  -2.8400   \n",
       "2     000008.SZ    20050511  5.08  5.34  5.06   5.13       5.14  -0.1900   \n",
       "3     000008.SZ    20050512  5.13  5.32  5.06   5.23       5.13   1.9500   \n",
       "4     000008.SZ    20050513  5.34  5.75  5.25   5.75       5.23   9.9400   \n",
       "...         ...         ...   ...   ...   ...    ...        ...      ...   \n",
       "3914  000008.SZ    20221209  2.51  2.54  2.48   2.50       2.52  -0.7937   \n",
       "3915  000008.SZ    20221212  2.50  2.50  2.44   2.46       2.50  -1.6000   \n",
       "3916  000008.SZ    20221213  2.45  2.48  2.45   2.47       2.46   0.4065   \n",
       "3917  000008.SZ    20221214  2.48  2.48  2.41   2.42       2.47  -2.0243   \n",
       "3918  000008.SZ    20221215  2.43  2.45  2.40   2.44       2.42   0.8264   \n",
       "\n",
       "            vol      amount  index_trade_date  index_open  index_high  \\\n",
       "0      15363.61   8531.0565          20050509    909.1740    934.6500   \n",
       "1      13096.90   6571.2745          20050510    913.0760    905.5430   \n",
       "2      13298.00   6937.8679          20050511    901.8510    911.8380   \n",
       "3       9775.74   5111.7443          20050512    885.8200    899.9680   \n",
       "4      22874.01  12752.0454          20050513    887.5430    883.5050   \n",
       "...         ...         ...               ...         ...         ...   \n",
       "3914  242420.92  60641.4020          20221209   3998.2442   3961.9919   \n",
       "3915  219788.92  54104.7550          20221212   3953.4433   3976.1722   \n",
       "3916  153038.00  37742.1110          20221213   3945.6813   3953.5482   \n",
       "3917  222385.00  54181.2000          20221214   3954.8857   3952.7885   \n",
       "3918  171399.00  41672.3920          20221215   3951.9885   3954.6720   \n",
       "\n",
       "      index_low  index_close  index_pre_close  index_pct_chg  \n",
       "0      937.3900     909.1740         932.3950        -2.4905  \n",
       "1      913.3880     892.3130         909.1740         0.4292  \n",
       "2      917.2230     900.4380         913.0760        -1.2294  \n",
       "3      900.0630     883.5110         901.8510        -1.7776  \n",
       "4      898.5050     875.5760         885.8200         0.1945  \n",
       "...         ...          ...              ...            ...  \n",
       "3914  4003.3178    3944.4396        3959.1798         0.9867  \n",
       "3915  3983.4332    3950.3203        3998.2442        -1.1205  \n",
       "3916  3964.3957    3939.9795        3953.4433        -0.1963  \n",
       "3917  3972.7381    3935.7668        3945.6813         0.2333  \n",
       "3918  3963.5002    3926.4997        3954.8857        -0.0733  \n",
       "\n",
       "[3919 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_list[2]['trade_date']\n",
    "print(len(stock_list[2]['trade_date']))\n",
    "\n",
    "tx = df_hs300[df_hs300['index_trade_date'].isin(stock_list[2]['trade_date'])].sort_values(\"index_trade_date\", ascending = True).reset_index().drop('index', axis=1)\n",
    "display(tx)\n",
    "\n",
    "display(stock_list[2])\n",
    "\n",
    "display(df_hs300)\n",
    "\n",
    "txp = pd.concat([stock_list[2], tx], axis=1, join='inner')\n",
    "display(txp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat\n",
    "\n",
    "for i in range(len(stock_list)):\n",
    "\n",
    "    temp = df_hs300[df_hs300['index_trade_date'].isin(stock_list[i]['trade_date'])].sort_values(\"index_trade_date\", ascending = True).reset_index().drop('index', axis=1)\n",
    "    stock_list[i] = pd.concat([stock_list[i], temp], axis=1, join='inner').drop('index_trade_date', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20050509</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.66</td>\n",
       "      <td>-4.8900</td>\n",
       "      <td>16053.15</td>\n",
       "      <td>4156.8566</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>934.6500</td>\n",
       "      <td>937.3900</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>932.3950</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20050510</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>20829.41</td>\n",
       "      <td>5235.9416</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>905.5430</td>\n",
       "      <td>913.3880</td>\n",
       "      <td>892.3130</td>\n",
       "      <td>909.1740</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20050511</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>27403.02</td>\n",
       "      <td>7103.4251</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>911.8380</td>\n",
       "      <td>917.2230</td>\n",
       "      <td>900.4380</td>\n",
       "      <td>913.0760</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20050512</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.59</td>\n",
       "      <td>-4.2500</td>\n",
       "      <td>18046.36</td>\n",
       "      <td>4552.7859</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>899.9680</td>\n",
       "      <td>900.0630</td>\n",
       "      <td>883.5110</td>\n",
       "      <td>901.8510</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20050513</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>16437.64</td>\n",
       "      <td>4122.7014</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20221209</td>\n",
       "      <td>13.57</td>\n",
       "      <td>13.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-2.7007</td>\n",
       "      <td>718855.04</td>\n",
       "      <td>963415.9290</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20221212</td>\n",
       "      <td>13.23</td>\n",
       "      <td>13.26</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.33</td>\n",
       "      <td>-1.7254</td>\n",
       "      <td>396017.65</td>\n",
       "      <td>518509.2920</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20221213</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.18</td>\n",
       "      <td>12.86</td>\n",
       "      <td>12.95</td>\n",
       "      <td>13.10</td>\n",
       "      <td>-1.1450</td>\n",
       "      <td>329622.46</td>\n",
       "      <td>428539.1200</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20221214</td>\n",
       "      <td>12.98</td>\n",
       "      <td>13.07</td>\n",
       "      <td>12.81</td>\n",
       "      <td>12.91</td>\n",
       "      <td>12.95</td>\n",
       "      <td>-0.3089</td>\n",
       "      <td>225046.34</td>\n",
       "      <td>290139.0380</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>000009.SZ</td>\n",
       "      <td>20221215</td>\n",
       "      <td>12.82</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.76</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.6971</td>\n",
       "      <td>248271.12</td>\n",
       "      <td>320598.1020</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4085 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts_code  trade_date   open   high    low  close  pre_close  pct_chg  \\\n",
       "0     000009.SZ    20050509   2.65   2.68   2.52   2.53       2.66  -4.8900   \n",
       "1     000009.SZ    20050510   2.53   2.58   2.44   2.55       2.53   0.7900   \n",
       "2     000009.SZ    20050511   2.55   2.66   2.51   2.59       2.55   1.5700   \n",
       "3     000009.SZ    20050512   2.56   2.60   2.47   2.48       2.59  -4.2500   \n",
       "4     000009.SZ    20050513   2.47   2.56   2.46   2.52       2.48   1.6100   \n",
       "...         ...         ...    ...    ...    ...    ...        ...      ...   \n",
       "4080  000009.SZ    20221209  13.57  13.67  13.33  13.33      13.70  -2.7007   \n",
       "4081  000009.SZ    20221212  13.23  13.26  12.97  13.10      13.33  -1.7254   \n",
       "4082  000009.SZ    20221213  13.08  13.18  12.86  12.95      13.10  -1.1450   \n",
       "4083  000009.SZ    20221214  12.98  13.07  12.81  12.91      12.95  -0.3089   \n",
       "4084  000009.SZ    20221215  12.82  13.06  12.76  13.00      12.91   0.6971   \n",
       "\n",
       "            vol       amount  index_open  index_high  index_low  index_close  \\\n",
       "0      16053.15    4156.8566    909.1740    934.6500   937.3900     909.1740   \n",
       "1      20829.41    5235.9416    913.0760    905.5430   913.3880     892.3130   \n",
       "2      27403.02    7103.4251    901.8510    911.8380   917.2230     900.4380   \n",
       "3      18046.36    4552.7859    885.8200    899.9680   900.0630     883.5110   \n",
       "4      16437.64    4122.7014    887.5430    883.5050   898.5050     875.5760   \n",
       "...         ...          ...         ...         ...        ...          ...   \n",
       "4080  718855.04  963415.9290   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "4081  396017.65  518509.2920   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "4082  329622.46  428539.1200   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "4083  225046.34  290139.0380   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "4084  248271.12  320598.1020   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  \n",
       "0            932.3950        -2.4905  \n",
       "1            909.1740         0.4292  \n",
       "2            913.0760        -1.2294  \n",
       "3            901.8510        -1.7776  \n",
       "4            885.8200         0.1945  \n",
       "...               ...            ...  \n",
       "4080        3959.1798         0.9867  \n",
       "4081        3998.2442        -1.1205  \n",
       "4082        3953.4433        -0.1963  \n",
       "4083        3945.6813         0.2333  \n",
       "4084        3954.8857        -0.0733  \n",
       "\n",
       "[4085 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stock_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check time matching\n",
    "# for stock in stock_list:\n",
    "#     print(stock['trade_date'].isin(stock['index_trade_date']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050509</td>\n",
       "      <td>6.23</td>\n",
       "      <td>6.27</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.20</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>96939.11</td>\n",
       "      <td>59428.4874</td>\n",
       "      <td>909.174</td>\n",
       "      <td>934.650</td>\n",
       "      <td>937.390</td>\n",
       "      <td>909.174</td>\n",
       "      <td>932.395</td>\n",
       "      <td>-2.4905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050510</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.36</td>\n",
       "      <td>5.97</td>\n",
       "      <td>6.31</td>\n",
       "      <td>6.09</td>\n",
       "      <td>3.61</td>\n",
       "      <td>108414.13</td>\n",
       "      <td>67332.3061</td>\n",
       "      <td>913.076</td>\n",
       "      <td>905.543</td>\n",
       "      <td>913.388</td>\n",
       "      <td>892.313</td>\n",
       "      <td>909.174</td>\n",
       "      <td>0.4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050511</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.19</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>106868.37</td>\n",
       "      <td>66813.6905</td>\n",
       "      <td>901.851</td>\n",
       "      <td>911.838</td>\n",
       "      <td>917.223</td>\n",
       "      <td>900.438</td>\n",
       "      <td>913.076</td>\n",
       "      <td>-1.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050512</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.19</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79396.48</td>\n",
       "      <td>49387.0372</td>\n",
       "      <td>885.820</td>\n",
       "      <td>899.968</td>\n",
       "      <td>900.063</td>\n",
       "      <td>883.511</td>\n",
       "      <td>901.851</td>\n",
       "      <td>-1.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050513</td>\n",
       "      <td>6.19</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>111481.38</td>\n",
       "      <td>67292.1901</td>\n",
       "      <td>887.543</td>\n",
       "      <td>883.505</td>\n",
       "      <td>898.505</td>\n",
       "      <td>875.576</td>\n",
       "      <td>885.820</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050516</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>54461.62</td>\n",
       "      <td>32003.5853</td>\n",
       "      <td>875.271</td>\n",
       "      <td>885.389</td>\n",
       "      <td>885.389</td>\n",
       "      <td>869.334</td>\n",
       "      <td>887.543</td>\n",
       "      <td>-1.3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050517</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.71</td>\n",
       "      <td>60944.28</td>\n",
       "      <td>36815.7997</td>\n",
       "      <td>881.462</td>\n",
       "      <td>873.077</td>\n",
       "      <td>888.281</td>\n",
       "      <td>868.212</td>\n",
       "      <td>875.271</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050518</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.32</td>\n",
       "      <td>52046.44</td>\n",
       "      <td>31843.2828</td>\n",
       "      <td>883.196</td>\n",
       "      <td>881.141</td>\n",
       "      <td>890.403</td>\n",
       "      <td>871.821</td>\n",
       "      <td>881.462</td>\n",
       "      <td>0.1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050519</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.98</td>\n",
       "      <td>72994.06</td>\n",
       "      <td>45054.1898</td>\n",
       "      <td>884.171</td>\n",
       "      <td>882.842</td>\n",
       "      <td>888.016</td>\n",
       "      <td>871.289</td>\n",
       "      <td>883.196</td>\n",
       "      <td>0.1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050520</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>98810.85</td>\n",
       "      <td>61928.4089</td>\n",
       "      <td>882.763</td>\n",
       "      <td>883.513</td>\n",
       "      <td>891.020</td>\n",
       "      <td>879.180</td>\n",
       "      <td>884.171</td>\n",
       "      <td>-0.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050523</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.96</td>\n",
       "      <td>6.21</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>82638.00</td>\n",
       "      <td>49957.5488</td>\n",
       "      <td>863.341</td>\n",
       "      <td>880.281</td>\n",
       "      <td>880.281</td>\n",
       "      <td>862.098</td>\n",
       "      <td>882.763</td>\n",
       "      <td>-2.2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050524</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.23</td>\n",
       "      <td>5.91</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>69936.00</td>\n",
       "      <td>42826.9253</td>\n",
       "      <td>868.456</td>\n",
       "      <td>861.195</td>\n",
       "      <td>871.767</td>\n",
       "      <td>855.587</td>\n",
       "      <td>863.341</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050525</td>\n",
       "      <td>6.18</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>55267.70</td>\n",
       "      <td>34222.4088</td>\n",
       "      <td>868.451</td>\n",
       "      <td>867.658</td>\n",
       "      <td>876.305</td>\n",
       "      <td>861.659</td>\n",
       "      <td>868.456</td>\n",
       "      <td>-0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050526</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>43689.86</td>\n",
       "      <td>26903.1315</td>\n",
       "      <td>857.331</td>\n",
       "      <td>867.758</td>\n",
       "      <td>872.835</td>\n",
       "      <td>854.956</td>\n",
       "      <td>868.451</td>\n",
       "      <td>-1.2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>20050527</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>54319.51</td>\n",
       "      <td>33668.5103</td>\n",
       "      <td>849.508</td>\n",
       "      <td>855.595</td>\n",
       "      <td>864.963</td>\n",
       "      <td>848.398</td>\n",
       "      <td>857.331</td>\n",
       "      <td>-0.9125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ts_code  trade_date  open  high   low  close  pre_close  pct_chg  \\\n",
       "0   000001.SZ    20050509  6.23  6.27  5.98   6.09       6.20    -1.77   \n",
       "1   000001.SZ    20050510  6.09  6.36  5.97   6.31       6.09     3.61   \n",
       "2   000001.SZ    20050511  6.28  6.40  6.12   6.19       6.31    -1.90   \n",
       "3   000001.SZ    20050512  6.18  6.34  6.14   6.19       6.19     0.00   \n",
       "4   000001.SZ    20050513  6.19  6.24  5.90   6.02       6.19    -2.75   \n",
       "5   000001.SZ    20050516  6.02  6.02  5.76   5.90       6.02    -1.99   \n",
       "6   000001.SZ    20050517  5.90  6.15  5.81   6.06       5.90     2.71   \n",
       "7   000001.SZ    20050518  6.06  6.20  6.04   6.14       6.06     1.32   \n",
       "8   000001.SZ    20050519  6.14  6.27  6.01   6.20       6.14     0.98   \n",
       "9   000001.SZ    20050520  6.22  6.34  6.12   6.21       6.20     0.16   \n",
       "10  000001.SZ    20050523  6.13  6.16  5.96   5.96       6.21    -4.03   \n",
       "11  000001.SZ    20050524  5.95  6.23  5.91   6.16       5.96     3.36   \n",
       "12  000001.SZ    20050525  6.18  6.28  6.10   6.17       6.16     0.16   \n",
       "13  000001.SZ    20050526  6.16  6.21  6.12   6.14       6.17    -0.49   \n",
       "14  000001.SZ    20050527  6.14  6.28  6.12   6.15       6.14     0.16   \n",
       "\n",
       "          vol      amount  index_open  index_high  index_low  index_close  \\\n",
       "0    96939.11  59428.4874     909.174     934.650    937.390      909.174   \n",
       "1   108414.13  67332.3061     913.076     905.543    913.388      892.313   \n",
       "2   106868.37  66813.6905     901.851     911.838    917.223      900.438   \n",
       "3    79396.48  49387.0372     885.820     899.968    900.063      883.511   \n",
       "4   111481.38  67292.1901     887.543     883.505    898.505      875.576   \n",
       "5    54461.62  32003.5853     875.271     885.389    885.389      869.334   \n",
       "6    60944.28  36815.7997     881.462     873.077    888.281      868.212   \n",
       "7    52046.44  31843.2828     883.196     881.141    890.403      871.821   \n",
       "8    72994.06  45054.1898     884.171     882.842    888.016      871.289   \n",
       "9    98810.85  61928.4089     882.763     883.513    891.020      879.180   \n",
       "10   82638.00  49957.5488     863.341     880.281    880.281      862.098   \n",
       "11   69936.00  42826.9253     868.456     861.195    871.767      855.587   \n",
       "12   55267.70  34222.4088     868.451     867.658    876.305      861.659   \n",
       "13   43689.86  26903.1315     857.331     867.758    872.835      854.956   \n",
       "14   54319.51  33668.5103     849.508     855.595    864.963      848.398   \n",
       "\n",
       "    index_pre_close  index_pct_chg  \n",
       "0           932.395        -2.4905  \n",
       "1           909.174         0.4292  \n",
       "2           913.076        -1.2294  \n",
       "3           901.851        -1.7776  \n",
       "4           885.820         0.1945  \n",
       "5           887.543        -1.3827  \n",
       "6           875.271         0.7073  \n",
       "7           881.462         0.1967  \n",
       "8           883.196         0.1104  \n",
       "9           884.171        -0.1592  \n",
       "10          882.763        -2.2001  \n",
       "11          863.341         0.5925  \n",
       "12          868.456        -0.0006  \n",
       "13          868.451        -1.2804  \n",
       "14          857.331        -0.9125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stock_list[0][0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time periodicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b80602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup timestamp for year periodicity \n",
    "date_time_db = []\n",
    "\n",
    "for stock_i in stock_list:\n",
    "    date_time_db.append(pd.to_datetime(stock_i.pop('trade_date'), format='%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e59e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2005-05-09\n",
      "1      2005-05-10\n",
      "2      2005-05-11\n",
      "3      2005-05-12\n",
      "4      2005-05-13\n",
      "          ...    \n",
      "4135   2022-12-09\n",
      "4136   2022-12-12\n",
      "4137   2022-12-13\n",
      "4138   2022-12-14\n",
      "4139   2022-12-15\n",
      "Name: trade_date, Length: 4140, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    print(date_time_db[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea85e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_stamp_db = []\n",
    "\n",
    "for dt in date_time_db:\n",
    "    date_time_stamp_db.append(dt.map(pd.Timestamp.timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c8a0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    date_time_stamp_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e222a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 24*60*60*(365.2425)\n",
    "\n",
    "for i in range(len(stock_list)):\n",
    "    \n",
    "    stock_list[i][\"Year sin\"] = np.sin(date_time_stamp_db[i] * (2 * np.pi / year))\n",
    "    stock_list[i][\"Year cos\"] = np.cos(date_time_stamp_db[i] * (2 * np.pi / year))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f86ba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    plt.plot(np.array(stock_list[0]['Year sin'])[:1000])\n",
    "    plt.plot(np.array(stock_list[0]['Year cos'])[:1000])\n",
    "    plt.xlabel('Time [day]')\n",
    "    plt.title('Time of year signal, in day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f11616a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    stock_list[5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ee7cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df processing\n",
    "for stock in stock_list:\n",
    "    stock.name = stock.iloc[0,0]\n",
    "    stock.pop(\"ts_code\") #pop the stock code\n",
    "    #stock.pop(\"pre_close\") #pop previous day close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba18cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    stock_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_label = 'open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stock_list:\n",
    "    \n",
    "    #MA\n",
    "\n",
    "    processing_row = stock[ma_label].to_frame()\n",
    "\n",
    "    stock['sma5'] = processing_row[ma_label].rolling(5).mean()\n",
    "\n",
    "    stock['ema5'] = processing_row[ma_label].ewm(span=5).mean()\n",
    "\n",
    "    stock['ema20'] = processing_row[ma_label].ewm(span=20).mean()\n",
    "\n",
    "    stock['ema50'] = processing_row[ma_label].ewm(span=50).mean()\n",
    "\n",
    "    \n",
    "\n",
    "    # # Golden Cross  implementation\n",
    "    # np.where(stock['ema20'] > stock['ema50'], 1, 0)\n",
    "\n",
    "    # stock['ema20_50_GC'] = 0 \n",
    "\n",
    "    # for i in range(stock.shape[0]):\n",
    "    #     if i == 0:\n",
    "    #         pass\n",
    "    #     elif stock['ema20'][i] >= stock['ema50'][i] and stock['ema20'][i-1] < stock['ema50'][i-1]: #slow code, works for now\n",
    "    #         stock['ema20_50_GC'][i] = 1\n",
    "\n",
    "\n",
    "\n",
    "    stock.dropna(inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GC value count inspction\n",
    "# for stock in stock_list:\n",
    "#     print(stock['ema20_50_GC'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.19</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-2.7500</td>\n",
       "      <td>111481.38</td>\n",
       "      <td>6.729219e+04</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>6.194</td>\n",
       "      <td>6.194455</td>\n",
       "      <td>6.194201</td>\n",
       "      <td>6.194081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.9900</td>\n",
       "      <td>54461.62</td>\n",
       "      <td>3.200359e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>6.152</td>\n",
       "      <td>6.130707</td>\n",
       "      <td>6.157452</td>\n",
       "      <td>6.162090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.90</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>60944.28</td>\n",
       "      <td>3.681580e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>6.114</td>\n",
       "      <td>6.049024</td>\n",
       "      <td>6.108775</td>\n",
       "      <td>6.120009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.06</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>52046.44</td>\n",
       "      <td>3.184328e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>6.070</td>\n",
       "      <td>6.052831</td>\n",
       "      <td>6.100344</td>\n",
       "      <td>6.111417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.14</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>72994.06</td>\n",
       "      <td>4.505419e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>6.062</td>\n",
       "      <td>6.082663</td>\n",
       "      <td>6.106705</td>\n",
       "      <td>6.115124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.75</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.36</td>\n",
       "      <td>2.5449</td>\n",
       "      <td>1615831.92</td>\n",
       "      <td>2.197502e+06</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>13.262</td>\n",
       "      <td>13.228249</td>\n",
       "      <td>12.484849</td>\n",
       "      <td>12.083849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>13.58</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.06</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-4.3066</td>\n",
       "      <td>1392584.28</td>\n",
       "      <td>1.848278e+06</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>13.360</td>\n",
       "      <td>13.345499</td>\n",
       "      <td>12.589149</td>\n",
       "      <td>12.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>13.15</td>\n",
       "      <td>13.36</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.11</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>902285.13</td>\n",
       "      <td>1.194285e+06</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>13.322</td>\n",
       "      <td>13.280333</td>\n",
       "      <td>12.642563</td>\n",
       "      <td>12.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>13.23</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>13.24</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>974061.10</td>\n",
       "      <td>1.287868e+06</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>13.302</td>\n",
       "      <td>13.263555</td>\n",
       "      <td>12.698510</td>\n",
       "      <td>12.223127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>13.14</td>\n",
       "      <td>13.28</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.23</td>\n",
       "      <td>-0.9826</td>\n",
       "      <td>835349.26</td>\n",
       "      <td>1.094434e+06</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>13.300</td>\n",
       "      <td>13.222370</td>\n",
       "      <td>12.740556</td>\n",
       "      <td>12.259083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4136 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol  \\\n",
       "4      6.19   6.24   5.90   6.02       6.19  -2.7500   111481.38   \n",
       "5      6.02   6.02   5.76   5.90       6.02  -1.9900    54461.62   \n",
       "6      5.90   6.15   5.81   6.06       5.90   2.7100    60944.28   \n",
       "7      6.06   6.20   6.04   6.14       6.06   1.3200    52046.44   \n",
       "8      6.14   6.27   6.01   6.20       6.14   0.9800    72994.06   \n",
       "...     ...    ...    ...    ...        ...      ...         ...   \n",
       "4135  13.40  13.75  13.35  13.70      13.36   2.5449  1615831.92   \n",
       "4136  13.58  13.58  13.06  13.11      13.70  -4.3066  1392584.28   \n",
       "4137  13.15  13.36  13.14  13.24      13.11   0.9916   902285.13   \n",
       "4138  13.23  13.40  13.08  13.23      13.24  -0.0755   974061.10   \n",
       "4139  13.14  13.28  12.94  13.10      13.23  -0.9826   835349.26   \n",
       "\n",
       "            amount  index_open  index_high  index_low  index_close  \\\n",
       "4     6.729219e+04    887.5430    883.5050   898.5050     875.5760   \n",
       "5     3.200359e+04    875.2710    885.3890   885.3890     869.3340   \n",
       "6     3.681580e+04    881.4620    873.0770   888.2810     868.2120   \n",
       "7     3.184328e+04    883.1960    881.1410   890.4030     871.8210   \n",
       "8     4.505419e+04    884.1710    882.8420   888.0160     871.2890   \n",
       "...            ...         ...         ...        ...          ...   \n",
       "4135  2.197502e+06   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "4136  1.848278e+06   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "4137  1.194285e+06   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "4138  1.287868e+06   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "4139  1.094434e+06   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  Year sin  Year cos    sma5       ema5  \\\n",
       "4            885.8200         0.1945  0.759152 -0.650913   6.194   6.194455   \n",
       "5            887.5430        -1.3827  0.724564 -0.689208   6.152   6.130707   \n",
       "6            875.2710         0.7073  0.712601 -0.701570   6.114   6.049024   \n",
       "7            881.4620         0.1967  0.700427 -0.713724   6.070   6.052831   \n",
       "8            883.1960         0.1104  0.688046 -0.725667   6.062   6.082663   \n",
       "...               ...            ...       ...       ...     ...        ...   \n",
       "4135        3959.1798         0.9867 -0.383078  0.923716  13.262  13.228249   \n",
       "4136        3998.2442        -1.1205 -0.334918  0.942247  13.360  13.345499   \n",
       "4137        3953.4433        -0.1963 -0.318660  0.947869  13.322  13.280333   \n",
       "4138        3945.6813         0.2333 -0.302308  0.953210  13.302  13.263555   \n",
       "4139        3954.8857        -0.0733 -0.285866  0.958270  13.300  13.222370   \n",
       "\n",
       "          ema20      ema50  \n",
       "4      6.194201   6.194081  \n",
       "5      6.157452   6.162090  \n",
       "6      6.108775   6.120009  \n",
       "7      6.100344   6.111417  \n",
       "8      6.106705   6.115124  \n",
       "...         ...        ...  \n",
       "4135  12.484849  12.083849  \n",
       "4136  12.589149  12.142521  \n",
       "4137  12.642563  12.182030  \n",
       "4138  12.698510  12.223127  \n",
       "4139  12.740556  12.259083  \n",
       "\n",
       "[4136 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stock_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.19</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-2.7500</td>\n",
       "      <td>111481.38</td>\n",
       "      <td>6.729219e+04</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>6.194</td>\n",
       "      <td>6.194455</td>\n",
       "      <td>6.194201</td>\n",
       "      <td>6.194081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.9900</td>\n",
       "      <td>54461.62</td>\n",
       "      <td>3.200359e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>6.152</td>\n",
       "      <td>6.130707</td>\n",
       "      <td>6.157452</td>\n",
       "      <td>6.162090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.90</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>60944.28</td>\n",
       "      <td>3.681580e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>6.114</td>\n",
       "      <td>6.049024</td>\n",
       "      <td>6.108775</td>\n",
       "      <td>6.120009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.06</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>52046.44</td>\n",
       "      <td>3.184328e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>6.070</td>\n",
       "      <td>6.052831</td>\n",
       "      <td>6.100344</td>\n",
       "      <td>6.111417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.14</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>72994.06</td>\n",
       "      <td>4.505419e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>6.062</td>\n",
       "      <td>6.082663</td>\n",
       "      <td>6.106705</td>\n",
       "      <td>6.115124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.75</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.36</td>\n",
       "      <td>2.5449</td>\n",
       "      <td>1615831.92</td>\n",
       "      <td>2.197502e+06</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>13.262</td>\n",
       "      <td>13.228249</td>\n",
       "      <td>12.484849</td>\n",
       "      <td>12.083849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>13.58</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.06</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-4.3066</td>\n",
       "      <td>1392584.28</td>\n",
       "      <td>1.848278e+06</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>13.360</td>\n",
       "      <td>13.345499</td>\n",
       "      <td>12.589149</td>\n",
       "      <td>12.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>13.15</td>\n",
       "      <td>13.36</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.11</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>902285.13</td>\n",
       "      <td>1.194285e+06</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>13.322</td>\n",
       "      <td>13.280333</td>\n",
       "      <td>12.642563</td>\n",
       "      <td>12.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>13.23</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>13.24</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>974061.10</td>\n",
       "      <td>1.287868e+06</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>13.302</td>\n",
       "      <td>13.263555</td>\n",
       "      <td>12.698510</td>\n",
       "      <td>12.223127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>13.14</td>\n",
       "      <td>13.28</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.23</td>\n",
       "      <td>-0.9826</td>\n",
       "      <td>835349.26</td>\n",
       "      <td>1.094434e+06</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>13.300</td>\n",
       "      <td>13.222370</td>\n",
       "      <td>12.740556</td>\n",
       "      <td>12.259083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4136 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol  \\\n",
       "4      6.19   6.24   5.90   6.02       6.19  -2.7500   111481.38   \n",
       "5      6.02   6.02   5.76   5.90       6.02  -1.9900    54461.62   \n",
       "6      5.90   6.15   5.81   6.06       5.90   2.7100    60944.28   \n",
       "7      6.06   6.20   6.04   6.14       6.06   1.3200    52046.44   \n",
       "8      6.14   6.27   6.01   6.20       6.14   0.9800    72994.06   \n",
       "...     ...    ...    ...    ...        ...      ...         ...   \n",
       "4135  13.40  13.75  13.35  13.70      13.36   2.5449  1615831.92   \n",
       "4136  13.58  13.58  13.06  13.11      13.70  -4.3066  1392584.28   \n",
       "4137  13.15  13.36  13.14  13.24      13.11   0.9916   902285.13   \n",
       "4138  13.23  13.40  13.08  13.23      13.24  -0.0755   974061.10   \n",
       "4139  13.14  13.28  12.94  13.10      13.23  -0.9826   835349.26   \n",
       "\n",
       "            amount  index_open  index_high  index_low  index_close  \\\n",
       "4     6.729219e+04    887.5430    883.5050   898.5050     875.5760   \n",
       "5     3.200359e+04    875.2710    885.3890   885.3890     869.3340   \n",
       "6     3.681580e+04    881.4620    873.0770   888.2810     868.2120   \n",
       "7     3.184328e+04    883.1960    881.1410   890.4030     871.8210   \n",
       "8     4.505419e+04    884.1710    882.8420   888.0160     871.2890   \n",
       "...            ...         ...         ...        ...          ...   \n",
       "4135  2.197502e+06   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "4136  1.848278e+06   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "4137  1.194285e+06   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "4138  1.287868e+06   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "4139  1.094434e+06   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  Year sin  Year cos    sma5       ema5  \\\n",
       "4            885.8200         0.1945  0.759152 -0.650913   6.194   6.194455   \n",
       "5            887.5430        -1.3827  0.724564 -0.689208   6.152   6.130707   \n",
       "6            875.2710         0.7073  0.712601 -0.701570   6.114   6.049024   \n",
       "7            881.4620         0.1967  0.700427 -0.713724   6.070   6.052831   \n",
       "8            883.1960         0.1104  0.688046 -0.725667   6.062   6.082663   \n",
       "...               ...            ...       ...       ...     ...        ...   \n",
       "4135        3959.1798         0.9867 -0.383078  0.923716  13.262  13.228249   \n",
       "4136        3998.2442        -1.1205 -0.334918  0.942247  13.360  13.345499   \n",
       "4137        3953.4433        -0.1963 -0.318660  0.947869  13.322  13.280333   \n",
       "4138        3945.6813         0.2333 -0.302308  0.953210  13.302  13.263555   \n",
       "4139        3954.8857        -0.0733 -0.285866  0.958270  13.300  13.222370   \n",
       "\n",
       "          ema20      ema50  \n",
       "4      6.194201   6.194081  \n",
       "5      6.157452   6.162090  \n",
       "6      6.108775   6.120009  \n",
       "7      6.100344   6.111417  \n",
       "8      6.106705   6.115124  \n",
       "...         ...        ...  \n",
       "4135  12.484849  12.083849  \n",
       "4136  12.589149  12.142521  \n",
       "4137  12.642563  12.182030  \n",
       "4138  12.698510  12.223127  \n",
       "4139  12.740556  12.259083  \n",
       "\n",
       "[4136 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.43</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1841.65</td>\n",
       "      <td>630.2068</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.382038</td>\n",
       "      <td>3.365206</td>\n",
       "      <td>3.362035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.45</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.44</td>\n",
       "      <td>-0.2900</td>\n",
       "      <td>1610.50</td>\n",
       "      <td>547.8560</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>3.378</td>\n",
       "      <td>3.406872</td>\n",
       "      <td>3.383093</td>\n",
       "      <td>3.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.42</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.4600</td>\n",
       "      <td>2258.03</td>\n",
       "      <td>777.9526</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>3.406</td>\n",
       "      <td>3.411520</td>\n",
       "      <td>3.390071</td>\n",
       "      <td>3.384912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.47</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2772.47</td>\n",
       "      <td>954.1027</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>3.432</td>\n",
       "      <td>3.431805</td>\n",
       "      <td>3.403888</td>\n",
       "      <td>3.397095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.47</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>4025.47</td>\n",
       "      <td>1407.4897</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>3.448</td>\n",
       "      <td>3.444877</td>\n",
       "      <td>3.414492</td>\n",
       "      <td>3.406551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>13.72</td>\n",
       "      <td>13.79</td>\n",
       "      <td>13.57</td>\n",
       "      <td>13.79</td>\n",
       "      <td>13.69</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>49745.92</td>\n",
       "      <td>68044.9130</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>13.762</td>\n",
       "      <td>13.737769</td>\n",
       "      <td>13.622803</td>\n",
       "      <td>13.602945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>13.79</td>\n",
       "      <td>13.81</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.55</td>\n",
       "      <td>13.79</td>\n",
       "      <td>-1.7404</td>\n",
       "      <td>47332.20</td>\n",
       "      <td>64308.5080</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>13.770</td>\n",
       "      <td>13.755179</td>\n",
       "      <td>13.638727</td>\n",
       "      <td>13.610281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>13.53</td>\n",
       "      <td>13.64</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.60</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>26568.19</td>\n",
       "      <td>36080.4420</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>13.714</td>\n",
       "      <td>13.680119</td>\n",
       "      <td>13.628372</td>\n",
       "      <td>13.607132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>13.60</td>\n",
       "      <td>13.66</td>\n",
       "      <td>13.48</td>\n",
       "      <td>13.60</td>\n",
       "      <td>13.60</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>26729.47</td>\n",
       "      <td>36301.8130</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>13.674</td>\n",
       "      <td>13.653413</td>\n",
       "      <td>13.625670</td>\n",
       "      <td>13.606853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>13.59</td>\n",
       "      <td>13.62</td>\n",
       "      <td>13.46</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.60</td>\n",
       "      <td>-0.8088</td>\n",
       "      <td>26140.42</td>\n",
       "      <td>35346.8750</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>13.646</td>\n",
       "      <td>13.632275</td>\n",
       "      <td>13.622273</td>\n",
       "      <td>13.606192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3921 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg       vol      amount  \\\n",
       "4      3.43   3.48   3.37   3.44       3.42   0.5800   1841.65    630.2068   \n",
       "5      3.45   3.46   3.36   3.43       3.44  -0.2900   1610.50    547.8560   \n",
       "6      3.42   3.49   3.40   3.48       3.43   1.4600   2258.03    777.9526   \n",
       "7      3.47   3.49   3.41   3.48       3.48   0.0000   2772.47    954.1027   \n",
       "8      3.47   3.56   3.42   3.53       3.48   1.4400   4025.47   1407.4897   \n",
       "...     ...    ...    ...    ...        ...      ...       ...         ...   \n",
       "3920  13.72  13.79  13.57  13.79      13.69   0.7305  49745.92  68044.9130   \n",
       "3921  13.79  13.81  13.50  13.55      13.79  -1.7404  47332.20  64308.5080   \n",
       "3922  13.53  13.64  13.49  13.60      13.55   0.3690  26568.19  36080.4420   \n",
       "3923  13.60  13.66  13.48  13.60      13.60   0.0000  26729.47  36301.8130   \n",
       "3924  13.59  13.62  13.46  13.49      13.60  -0.8088  26140.42  35346.8750   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "4       887.5430    883.5050   898.5050     875.5760         885.8200   \n",
       "5       875.2710    885.3890   885.3890     869.3340         887.5430   \n",
       "6       881.4620    873.0770   888.2810     868.2120         875.2710   \n",
       "7       883.1960    881.1410   890.4030     871.8210         881.4620   \n",
       "8       884.1710    882.8420   888.0160     871.2890         883.1960   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "3920   3998.2442   3961.9919  4003.3178    3944.4396        3959.1798   \n",
       "3921   3953.4433   3976.1722  3983.4332    3950.3203        3998.2442   \n",
       "3922   3945.6813   3953.5482  3964.3957    3939.9795        3953.4433   \n",
       "3923   3954.8857   3952.7885  3972.7381    3935.7668        3945.6813   \n",
       "3924   3951.9885   3954.6720  3963.5002    3926.4997        3954.8857   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "4            0.1945  0.759152 -0.650913   3.360   3.382038   3.365206   \n",
       "5           -1.3827  0.724564 -0.689208   3.378   3.406872   3.383093   \n",
       "6            0.7073  0.712601 -0.701570   3.406   3.411520   3.390071   \n",
       "7            0.1967  0.700427 -0.713724   3.432   3.431805   3.403888   \n",
       "8            0.1104  0.688046 -0.725667   3.448   3.444877   3.414492   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "3920         0.9867 -0.383078  0.923716  13.762  13.737769  13.622803   \n",
       "3921        -1.1205 -0.334918  0.942247  13.770  13.755179  13.638727   \n",
       "3922        -0.1963 -0.318660  0.947869  13.714  13.680119  13.628372   \n",
       "3923         0.2333 -0.302308  0.953210  13.674  13.653413  13.625670   \n",
       "3924        -0.0733 -0.285866  0.958270  13.646  13.632275  13.622273   \n",
       "\n",
       "          ema50  \n",
       "4      3.362035  \n",
       "5      3.378200  \n",
       "6      3.384912  \n",
       "7      3.397095  \n",
       "8      3.406551  \n",
       "...         ...  \n",
       "3920  13.602945  \n",
       "3921  13.610281  \n",
       "3922  13.607132  \n",
       "3923  13.606853  \n",
       "3924  13.606192  \n",
       "\n",
       "[3921 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(stock_list[0])\n",
    "display(stock_list[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_lstm_1 = Sequential(\n",
    "\n",
    "#     [\n",
    "\n",
    "#         LSTM(units = 32, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         LSTM(units = 32, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "#     ],\n",
    "\n",
    "#     name = \"simple_stacked_lstm_stock_1\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_lstm_1_plus = Sequential(\n",
    "\n",
    "#     [\n",
    "\n",
    "#         LSTM(units = 64, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         LSTM(units = 64, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 24, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "#     ],\n",
    "\n",
    "#     name = \"simple_stacked_lstm_stock_1_plus\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28efbc4b",
   "metadata": {},
   "source": [
    "# Training for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data storage\n",
    "evaluation_result = {}\n",
    "\n",
    "\n",
    "#meta data\n",
    "labels = ['open']\n",
    "\n",
    "eval_iteration = 10 #the number of evaluation iterations for individual stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df instances :  4136\n",
      "df features :  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.19</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-2.7500</td>\n",
       "      <td>111481.38</td>\n",
       "      <td>6.729219e+04</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>6.194</td>\n",
       "      <td>6.194455</td>\n",
       "      <td>6.194201</td>\n",
       "      <td>6.194081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.9900</td>\n",
       "      <td>54461.62</td>\n",
       "      <td>3.200359e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>6.152</td>\n",
       "      <td>6.130707</td>\n",
       "      <td>6.157452</td>\n",
       "      <td>6.162090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.90</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>60944.28</td>\n",
       "      <td>3.681580e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>6.114</td>\n",
       "      <td>6.049024</td>\n",
       "      <td>6.108775</td>\n",
       "      <td>6.120009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.06</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>52046.44</td>\n",
       "      <td>3.184328e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>6.070</td>\n",
       "      <td>6.052831</td>\n",
       "      <td>6.100344</td>\n",
       "      <td>6.111417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.14</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>72994.06</td>\n",
       "      <td>4.505419e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>6.062</td>\n",
       "      <td>6.082663</td>\n",
       "      <td>6.106705</td>\n",
       "      <td>6.115124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.75</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.36</td>\n",
       "      <td>2.5449</td>\n",
       "      <td>1615831.92</td>\n",
       "      <td>2.197502e+06</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>13.262</td>\n",
       "      <td>13.228249</td>\n",
       "      <td>12.484849</td>\n",
       "      <td>12.083849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>13.58</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.06</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-4.3066</td>\n",
       "      <td>1392584.28</td>\n",
       "      <td>1.848278e+06</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>13.360</td>\n",
       "      <td>13.345499</td>\n",
       "      <td>12.589149</td>\n",
       "      <td>12.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>13.15</td>\n",
       "      <td>13.36</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.11</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>902285.13</td>\n",
       "      <td>1.194285e+06</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>13.322</td>\n",
       "      <td>13.280333</td>\n",
       "      <td>12.642563</td>\n",
       "      <td>12.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>13.23</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>13.24</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>974061.10</td>\n",
       "      <td>1.287868e+06</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>13.302</td>\n",
       "      <td>13.263555</td>\n",
       "      <td>12.698510</td>\n",
       "      <td>12.223127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>13.14</td>\n",
       "      <td>13.28</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.23</td>\n",
       "      <td>-0.9826</td>\n",
       "      <td>835349.26</td>\n",
       "      <td>1.094434e+06</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>13.300</td>\n",
       "      <td>13.222370</td>\n",
       "      <td>12.740556</td>\n",
       "      <td>12.259083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4136 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol  \\\n",
       "4      6.19   6.24   5.90   6.02       6.19  -2.7500   111481.38   \n",
       "5      6.02   6.02   5.76   5.90       6.02  -1.9900    54461.62   \n",
       "6      5.90   6.15   5.81   6.06       5.90   2.7100    60944.28   \n",
       "7      6.06   6.20   6.04   6.14       6.06   1.3200    52046.44   \n",
       "8      6.14   6.27   6.01   6.20       6.14   0.9800    72994.06   \n",
       "...     ...    ...    ...    ...        ...      ...         ...   \n",
       "4135  13.40  13.75  13.35  13.70      13.36   2.5449  1615831.92   \n",
       "4136  13.58  13.58  13.06  13.11      13.70  -4.3066  1392584.28   \n",
       "4137  13.15  13.36  13.14  13.24      13.11   0.9916   902285.13   \n",
       "4138  13.23  13.40  13.08  13.23      13.24  -0.0755   974061.10   \n",
       "4139  13.14  13.28  12.94  13.10      13.23  -0.9826   835349.26   \n",
       "\n",
       "            amount  index_open  index_high  index_low  index_close  \\\n",
       "4     6.729219e+04    887.5430    883.5050   898.5050     875.5760   \n",
       "5     3.200359e+04    875.2710    885.3890   885.3890     869.3340   \n",
       "6     3.681580e+04    881.4620    873.0770   888.2810     868.2120   \n",
       "7     3.184328e+04    883.1960    881.1410   890.4030     871.8210   \n",
       "8     4.505419e+04    884.1710    882.8420   888.0160     871.2890   \n",
       "...            ...         ...         ...        ...          ...   \n",
       "4135  2.197502e+06   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "4136  1.848278e+06   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "4137  1.194285e+06   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "4138  1.287868e+06   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "4139  1.094434e+06   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  Year sin  Year cos    sma5       ema5  \\\n",
       "4            885.8200         0.1945  0.759152 -0.650913   6.194   6.194455   \n",
       "5            887.5430        -1.3827  0.724564 -0.689208   6.152   6.130707   \n",
       "6            875.2710         0.7073  0.712601 -0.701570   6.114   6.049024   \n",
       "7            881.4620         0.1967  0.700427 -0.713724   6.070   6.052831   \n",
       "8            883.1960         0.1104  0.688046 -0.725667   6.062   6.082663   \n",
       "...               ...            ...       ...       ...     ...        ...   \n",
       "4135        3959.1798         0.9867 -0.383078  0.923716  13.262  13.228249   \n",
       "4136        3998.2442        -1.1205 -0.334918  0.942247  13.360  13.345499   \n",
       "4137        3953.4433        -0.1963 -0.318660  0.947869  13.322  13.280333   \n",
       "4138        3945.6813         0.2333 -0.302308  0.953210  13.302  13.263555   \n",
       "4139        3954.8857        -0.0733 -0.285866  0.958270  13.300  13.222370   \n",
       "\n",
       "          ema20      ema50  \n",
       "4      6.194201   6.194081  \n",
       "5      6.157452   6.162090  \n",
       "6      6.108775   6.120009  \n",
       "7      6.100344   6.111417  \n",
       "8      6.106705   6.115124  \n",
       "...         ...        ...  \n",
       "4135  12.484849  12.083849  \n",
       "4136  12.589149  12.142521  \n",
       "4137  12.642563  12.182030  \n",
       "4138  12.698510  12.223127  \n",
       "4139  12.740556  12.259083  \n",
       "\n",
       "[4136 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df instances :  2895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.19</td>\n",
       "      <td>6.24</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>111481.38</td>\n",
       "      <td>6.729219e+04</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>6.194</td>\n",
       "      <td>6.194455</td>\n",
       "      <td>6.194201</td>\n",
       "      <td>6.194081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.02</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>54461.62</td>\n",
       "      <td>3.200359e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>6.152</td>\n",
       "      <td>6.130707</td>\n",
       "      <td>6.157452</td>\n",
       "      <td>6.162090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.90</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.06</td>\n",
       "      <td>5.90</td>\n",
       "      <td>2.71</td>\n",
       "      <td>60944.28</td>\n",
       "      <td>3.681580e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>6.114</td>\n",
       "      <td>6.049024</td>\n",
       "      <td>6.108775</td>\n",
       "      <td>6.120009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.06</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.32</td>\n",
       "      <td>52046.44</td>\n",
       "      <td>3.184328e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>6.070</td>\n",
       "      <td>6.052831</td>\n",
       "      <td>6.100344</td>\n",
       "      <td>6.111417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.14</td>\n",
       "      <td>6.27</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.98</td>\n",
       "      <td>72994.06</td>\n",
       "      <td>4.505419e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>6.062</td>\n",
       "      <td>6.082663</td>\n",
       "      <td>6.106705</td>\n",
       "      <td>6.115124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>11.36</td>\n",
       "      <td>11.58</td>\n",
       "      <td>11.26</td>\n",
       "      <td>11.54</td>\n",
       "      <td>11.40</td>\n",
       "      <td>1.23</td>\n",
       "      <td>604308.48</td>\n",
       "      <td>6.892299e+05</td>\n",
       "      <td>3997.1343</td>\n",
       "      <td>3994.0946</td>\n",
       "      <td>3999.2262</td>\n",
       "      <td>3971.3761</td>\n",
       "      <td>3996.6221</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>-0.855219</td>\n",
       "      <td>0.518266</td>\n",
       "      <td>11.442</td>\n",
       "      <td>11.437872</td>\n",
       "      <td>11.402517</td>\n",
       "      <td>11.204105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>11.49</td>\n",
       "      <td>11.68</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.39</td>\n",
       "      <td>11.54</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>743343.22</td>\n",
       "      <td>8.520321e+05</td>\n",
       "      <td>3992.6979</td>\n",
       "      <td>3992.3496</td>\n",
       "      <td>3999.3373</td>\n",
       "      <td>3963.0263</td>\n",
       "      <td>3997.1343</td>\n",
       "      <td>-0.1110</td>\n",
       "      <td>-0.846177</td>\n",
       "      <td>0.532901</td>\n",
       "      <td>11.502</td>\n",
       "      <td>11.455248</td>\n",
       "      <td>11.410849</td>\n",
       "      <td>11.215317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>11.42</td>\n",
       "      <td>11.42</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11.28</td>\n",
       "      <td>11.39</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>1029902.81</td>\n",
       "      <td>1.157304e+06</td>\n",
       "      <td>4020.8896</td>\n",
       "      <td>3989.1824</td>\n",
       "      <td>4021.6382</td>\n",
       "      <td>3975.4069</td>\n",
       "      <td>3992.6979</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>-0.817561</td>\n",
       "      <td>0.575842</td>\n",
       "      <td>11.476</td>\n",
       "      <td>11.443499</td>\n",
       "      <td>11.411720</td>\n",
       "      <td>11.223344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.09</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.92</td>\n",
       "      <td>11.28</td>\n",
       "      <td>5.67</td>\n",
       "      <td>2477163.26</td>\n",
       "      <td>2.914269e+06</td>\n",
       "      <td>4054.2465</td>\n",
       "      <td>4022.4018</td>\n",
       "      <td>4064.2178</td>\n",
       "      <td>4021.3639</td>\n",
       "      <td>4020.8896</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>-0.807534</td>\n",
       "      <td>0.589821</td>\n",
       "      <td>11.420</td>\n",
       "      <td>11.385666</td>\n",
       "      <td>11.398223</td>\n",
       "      <td>11.225173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>12.00</td>\n",
       "      <td>12.59</td>\n",
       "      <td>11.93</td>\n",
       "      <td>12.13</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4262825.73</td>\n",
       "      <td>5.199224e+06</td>\n",
       "      <td>4048.0057</td>\n",
       "      <td>4051.4935</td>\n",
       "      <td>4089.1457</td>\n",
       "      <td>4040.5772</td>\n",
       "      <td>4054.2465</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-0.797269</td>\n",
       "      <td>0.603624</td>\n",
       "      <td>11.508</td>\n",
       "      <td>11.590444</td>\n",
       "      <td>11.455535</td>\n",
       "      <td>11.255559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2895 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol  \\\n",
       "4      6.19   6.24   5.90   6.02       6.19    -2.75   111481.38   \n",
       "5      6.02   6.02   5.76   5.90       6.02    -1.99    54461.62   \n",
       "6      5.90   6.15   5.81   6.06       5.90     2.71    60944.28   \n",
       "7      6.06   6.20   6.04   6.14       6.06     1.32    52046.44   \n",
       "8      6.14   6.27   6.01   6.20       6.14     0.98    72994.06   \n",
       "...     ...    ...    ...    ...        ...      ...         ...   \n",
       "2894  11.36  11.58  11.26  11.54      11.40     1.23   604308.48   \n",
       "2895  11.49  11.68  11.35  11.39      11.54    -1.30   743343.22   \n",
       "2896  11.42  11.42  11.09  11.28      11.39    -0.97  1029902.81   \n",
       "2897  11.27  12.09  11.25  11.92      11.28     5.67  2477163.26   \n",
       "2898  12.00  12.59  11.93  12.13      11.92     1.76  4262825.73   \n",
       "\n",
       "            amount  index_open  index_high  index_low  index_close  \\\n",
       "4     6.729219e+04    887.5430    883.5050   898.5050     875.5760   \n",
       "5     3.200359e+04    875.2710    885.3890   885.3890     869.3340   \n",
       "6     3.681580e+04    881.4620    873.0770   888.2810     868.2120   \n",
       "7     3.184328e+04    883.1960    881.1410   890.4030     871.8210   \n",
       "8     4.505419e+04    884.1710    882.8420   888.0160     871.2890   \n",
       "...            ...         ...         ...        ...          ...   \n",
       "2894  6.892299e+05   3997.1343   3994.0946  3999.2262    3971.3761   \n",
       "2895  8.520321e+05   3992.6979   3992.3496  3999.3373    3963.0263   \n",
       "2896  1.157304e+06   4020.8896   3989.1824  4021.6382    3975.4069   \n",
       "2897  2.914269e+06   4054.2465   4022.4018  4064.2178    4021.3639   \n",
       "2898  5.199224e+06   4048.0057   4051.4935  4089.1457    4040.5772   \n",
       "\n",
       "      index_pre_close  index_pct_chg  Year sin  Year cos    sma5       ema5  \\\n",
       "4            885.8200         0.1945  0.759152 -0.650913   6.194   6.194455   \n",
       "5            887.5430        -1.3827  0.724564 -0.689208   6.152   6.130707   \n",
       "6            875.2710         0.7073  0.712601 -0.701570   6.114   6.049024   \n",
       "7            881.4620         0.1967  0.700427 -0.713724   6.070   6.052831   \n",
       "8            883.1960         0.1104  0.688046 -0.725667   6.062   6.082663   \n",
       "...               ...            ...       ...       ...     ...        ...   \n",
       "2894        3996.6221         0.0128 -0.855219  0.518266  11.442  11.437872   \n",
       "2895        3997.1343        -0.1110 -0.846177  0.532901  11.502  11.455248   \n",
       "2896        3992.6979         0.7061 -0.817561  0.575842  11.476  11.443499   \n",
       "2897        4020.8896         0.8296 -0.807534  0.589821  11.420  11.385666   \n",
       "2898        4054.2465        -0.1539 -0.797269  0.603624  11.508  11.590444   \n",
       "\n",
       "          ema20      ema50  \n",
       "4      6.194201   6.194081  \n",
       "5      6.157452   6.162090  \n",
       "6      6.108775   6.120009  \n",
       "7      6.100344   6.111417  \n",
       "8      6.106705   6.115124  \n",
       "...         ...        ...  \n",
       "2894  11.402517  11.204105  \n",
       "2895  11.410849  11.215317  \n",
       "2896  11.411720  11.223344  \n",
       "2897  11.398223  11.225173  \n",
       "2898  11.455535  11.255559  \n",
       "\n",
       "[2895 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "val_df instances :  827\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>12.20</td>\n",
       "      <td>12.57</td>\n",
       "      <td>12.15</td>\n",
       "      <td>12.33</td>\n",
       "      <td>12.13</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>2295289.34</td>\n",
       "      <td>2839861.735</td>\n",
       "      <td>4075.8998</td>\n",
       "      <td>4043.0663</td>\n",
       "      <td>4076.6102</td>\n",
       "      <td>4038.4004</td>\n",
       "      <td>4048.0057</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>-0.786767</td>\n",
       "      <td>0.617250</td>\n",
       "      <td>11.676</td>\n",
       "      <td>11.793629</td>\n",
       "      <td>11.526436</td>\n",
       "      <td>11.292596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>12.37</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.33</td>\n",
       "      <td>-0.2400</td>\n",
       "      <td>1757552.27</td>\n",
       "      <td>2167126.597</td>\n",
       "      <td>4111.9112</td>\n",
       "      <td>4070.2763</td>\n",
       "      <td>4116.7142</td>\n",
       "      <td>4067.6570</td>\n",
       "      <td>4075.8998</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>-0.776033</td>\n",
       "      <td>0.630692</td>\n",
       "      <td>11.852</td>\n",
       "      <td>11.985753</td>\n",
       "      <td>11.606776</td>\n",
       "      <td>11.334847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>12.35</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.35</td>\n",
       "      <td>12.90</td>\n",
       "      <td>12.30</td>\n",
       "      <td>4.8800</td>\n",
       "      <td>2566906.23</td>\n",
       "      <td>3307955.288</td>\n",
       "      <td>4128.0733</td>\n",
       "      <td>4115.5507</td>\n",
       "      <td>4137.6455</td>\n",
       "      <td>4115.5507</td>\n",
       "      <td>4111.9112</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>-0.742465</td>\n",
       "      <td>0.669885</td>\n",
       "      <td>12.038</td>\n",
       "      <td>12.107169</td>\n",
       "      <td>11.677559</td>\n",
       "      <td>11.374657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>12.95</td>\n",
       "      <td>13.26</td>\n",
       "      <td>12.81</td>\n",
       "      <td>12.95</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>1780302.47</td>\n",
       "      <td>2318092.534</td>\n",
       "      <td>4099.3510</td>\n",
       "      <td>4129.2736</td>\n",
       "      <td>4133.5462</td>\n",
       "      <td>4086.8903</td>\n",
       "      <td>4128.0733</td>\n",
       "      <td>-0.6958</td>\n",
       "      <td>-0.730832</td>\n",
       "      <td>0.682557</td>\n",
       "      <td>12.374</td>\n",
       "      <td>12.388112</td>\n",
       "      <td>11.798744</td>\n",
       "      <td>11.436435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>12.90</td>\n",
       "      <td>13.13</td>\n",
       "      <td>12.77</td>\n",
       "      <td>12.90</td>\n",
       "      <td>12.95</td>\n",
       "      <td>-0.3900</td>\n",
       "      <td>1263052.27</td>\n",
       "      <td>1627912.725</td>\n",
       "      <td>4073.6696</td>\n",
       "      <td>4084.2131</td>\n",
       "      <td>4102.8071</td>\n",
       "      <td>4055.7167</td>\n",
       "      <td>4099.3510</td>\n",
       "      <td>-0.6265</td>\n",
       "      <td>-0.718983</td>\n",
       "      <td>0.695028</td>\n",
       "      <td>12.554</td>\n",
       "      <td>12.558742</td>\n",
       "      <td>11.903625</td>\n",
       "      <td>11.493830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>21.28</td>\n",
       "      <td>21.65</td>\n",
       "      <td>21.20</td>\n",
       "      <td>21.49</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1.6556</td>\n",
       "      <td>785666.68</td>\n",
       "      <td>1684397.866</td>\n",
       "      <td>5046.8773</td>\n",
       "      <td>5052.2634</td>\n",
       "      <td>5086.6543</td>\n",
       "      <td>5010.3902</td>\n",
       "      <td>5037.9899</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>21.096</td>\n",
       "      <td>21.072778</td>\n",
       "      <td>21.458772</td>\n",
       "      <td>21.436481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>21.38</td>\n",
       "      <td>21.93</td>\n",
       "      <td>21.21</td>\n",
       "      <td>21.93</td>\n",
       "      <td>21.49</td>\n",
       "      <td>2.0475</td>\n",
       "      <td>738654.81</td>\n",
       "      <td>1601238.499</td>\n",
       "      <td>5094.7291</td>\n",
       "      <td>5043.0952</td>\n",
       "      <td>5106.0365</td>\n",
       "      <td>5032.7950</td>\n",
       "      <td>5046.8773</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.046055</td>\n",
       "      <td>21.058</td>\n",
       "      <td>21.175185</td>\n",
       "      <td>21.451270</td>\n",
       "      <td>21.434266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>21.77</td>\n",
       "      <td>22.07</td>\n",
       "      <td>21.60</td>\n",
       "      <td>22.01</td>\n",
       "      <td>21.93</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>777028.07</td>\n",
       "      <td>1699922.183</td>\n",
       "      <td>5048.3607</td>\n",
       "      <td>5085.9497</td>\n",
       "      <td>5085.9497</td>\n",
       "      <td>5015.6070</td>\n",
       "      <td>5094.7291</td>\n",
       "      <td>-0.9101</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.028864</td>\n",
       "      <td>21.170</td>\n",
       "      <td>21.373457</td>\n",
       "      <td>21.481625</td>\n",
       "      <td>21.447432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>22.08</td>\n",
       "      <td>22.11</td>\n",
       "      <td>21.50</td>\n",
       "      <td>21.78</td>\n",
       "      <td>22.01</td>\n",
       "      <td>-1.0450</td>\n",
       "      <td>544448.98</td>\n",
       "      <td>1183868.023</td>\n",
       "      <td>5110.7768</td>\n",
       "      <td>5059.9359</td>\n",
       "      <td>5115.4286</td>\n",
       "      <td>5056.8718</td>\n",
       "      <td>5048.3607</td>\n",
       "      <td>1.2364</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>21.470</td>\n",
       "      <td>21.608971</td>\n",
       "      <td>21.538613</td>\n",
       "      <td>21.472239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>21.70</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.36</td>\n",
       "      <td>21.50</td>\n",
       "      <td>21.78</td>\n",
       "      <td>-1.2856</td>\n",
       "      <td>581083.52</td>\n",
       "      <td>1249405.387</td>\n",
       "      <td>5161.5569</td>\n",
       "      <td>5129.8545</td>\n",
       "      <td>5169.8312</td>\n",
       "      <td>5116.3472</td>\n",
       "      <td>5110.7768</td>\n",
       "      <td>0.9936</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>-0.005537</td>\n",
       "      <td>21.642</td>\n",
       "      <td>21.639314</td>\n",
       "      <td>21.553983</td>\n",
       "      <td>21.481171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol       amount  \\\n",
       "2899  12.20  12.57  12.15  12.33      12.13   1.6500  2295289.34  2839861.735   \n",
       "2900  12.37  12.55  12.15  12.30      12.33  -0.2400  1757552.27  2167126.597   \n",
       "2901  12.35  13.10  12.35  12.90      12.30   4.8800  2566906.23  3307955.288   \n",
       "2902  12.95  13.26  12.81  12.95      12.90   0.3900  1780302.47  2318092.534   \n",
       "2903  12.90  13.13  12.77  12.90      12.95  -0.3900  1263052.27  1627912.725   \n",
       "...     ...    ...    ...    ...        ...      ...         ...          ...   \n",
       "3721  21.28  21.65  21.20  21.49      21.14   1.6556   785666.68  1684397.866   \n",
       "3722  21.38  21.93  21.21  21.93      21.49   2.0475   738654.81  1601238.499   \n",
       "3723  21.77  22.07  21.60  22.01      21.93   0.3648   777028.07  1699922.183   \n",
       "3724  22.08  22.11  21.50  21.78      22.01  -1.0450   544448.98  1183868.023   \n",
       "3725  21.70  21.73  21.36  21.50      21.78  -1.2856   581083.52  1249405.387   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "2899   4075.8998   4043.0663  4076.6102    4038.4004        4048.0057   \n",
       "2900   4111.9112   4070.2763  4116.7142    4067.6570        4075.8998   \n",
       "2901   4128.0733   4115.5507  4137.6455    4115.5507        4111.9112   \n",
       "2902   4099.3510   4129.2736  4133.5462    4086.8903        4128.0733   \n",
       "2903   4073.6696   4084.2131  4102.8071    4055.7167        4099.3510   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "3721   5046.8773   5052.2634  5086.6543    5010.3902        5037.9899   \n",
       "3722   5094.7291   5043.0952  5106.0365    5032.7950        5046.8773   \n",
       "3723   5048.3607   5085.9497  5085.9497    5015.6070        5094.7291   \n",
       "3724   5110.7768   5059.9359  5115.4286    5056.8718        5048.3607   \n",
       "3725   5161.5569   5129.8545  5169.8312    5116.3472        5110.7768   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "2899         0.6891 -0.786767  0.617250  11.676  11.793629  11.526436   \n",
       "2900         0.8835 -0.776033  0.630692  11.852  11.985753  11.606776   \n",
       "2901         0.3931 -0.742465  0.669885  12.038  12.107169  11.677559   \n",
       "2902        -0.6958 -0.730832  0.682557  12.374  12.388112  11.798744   \n",
       "2903        -0.6265 -0.718983  0.695028  12.554  12.558742  11.903625   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "3721         0.1764  0.997999  0.063232  21.096  21.072778  21.458772   \n",
       "3722         0.9481  0.998939  0.046055  21.058  21.175185  21.451270   \n",
       "3723        -0.9101  0.999583  0.028864  21.170  21.373457  21.481625   \n",
       "3724         1.2364  0.999932  0.011665  21.470  21.608971  21.538613   \n",
       "3725         0.9936  0.999985 -0.005537  21.642  21.639314  21.553983   \n",
       "\n",
       "          ema50  \n",
       "2899  11.292596  \n",
       "2900  11.334847  \n",
       "2901  11.374657  \n",
       "2902  11.436435  \n",
       "2903  11.493830  \n",
       "...         ...  \n",
       "3721  21.436481  \n",
       "3722  21.434266  \n",
       "3723  21.447432  \n",
       "3724  21.472239  \n",
       "3725  21.481171  \n",
       "\n",
       "[827 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "test_df instances :  414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>21.55</td>\n",
       "      <td>22.09</td>\n",
       "      <td>21.51</td>\n",
       "      <td>21.68</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>401102.82</td>\n",
       "      <td>873387.016</td>\n",
       "      <td>5140.3418</td>\n",
       "      <td>5178.6401</td>\n",
       "      <td>5181.1490</td>\n",
       "      <td>5125.3301</td>\n",
       "      <td>5161.5569</td>\n",
       "      <td>-0.4110</td>\n",
       "      <td>0.997237</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>21.696</td>\n",
       "      <td>21.609543</td>\n",
       "      <td>21.553604</td>\n",
       "      <td>21.483870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>21.88</td>\n",
       "      <td>21.93</td>\n",
       "      <td>21.31</td>\n",
       "      <td>21.64</td>\n",
       "      <td>21.68</td>\n",
       "      <td>-0.1845</td>\n",
       "      <td>517604.59</td>\n",
       "      <td>1116774.452</td>\n",
       "      <td>5103.7428</td>\n",
       "      <td>5141.6556</td>\n",
       "      <td>5141.6556</td>\n",
       "      <td>5065.1932</td>\n",
       "      <td>5140.3418</td>\n",
       "      <td>-0.7120</td>\n",
       "      <td>0.995812</td>\n",
       "      <td>-0.091423</td>\n",
       "      <td>21.796</td>\n",
       "      <td>21.699695</td>\n",
       "      <td>21.584689</td>\n",
       "      <td>21.499404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>21.46</td>\n",
       "      <td>21.73</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.56</td>\n",
       "      <td>21.64</td>\n",
       "      <td>-0.3697</td>\n",
       "      <td>383029.50</td>\n",
       "      <td>825170.840</td>\n",
       "      <td>5112.2086</td>\n",
       "      <td>5078.2627</td>\n",
       "      <td>5129.1318</td>\n",
       "      <td>5062.0725</td>\n",
       "      <td>5103.7428</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.994092</td>\n",
       "      <td>-0.108540</td>\n",
       "      <td>21.734</td>\n",
       "      <td>21.619797</td>\n",
       "      <td>21.572814</td>\n",
       "      <td>21.497859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>21.71</td>\n",
       "      <td>21.72</td>\n",
       "      <td>21.08</td>\n",
       "      <td>21.30</td>\n",
       "      <td>21.56</td>\n",
       "      <td>-1.2059</td>\n",
       "      <td>398960.28</td>\n",
       "      <td>849870.878</td>\n",
       "      <td>5035.3374</td>\n",
       "      <td>5100.0422</td>\n",
       "      <td>5100.0422</td>\n",
       "      <td>5022.0926</td>\n",
       "      <td>5112.2086</td>\n",
       "      <td>-1.5037</td>\n",
       "      <td>0.992078</td>\n",
       "      <td>-0.125624</td>\n",
       "      <td>21.660</td>\n",
       "      <td>21.649865</td>\n",
       "      <td>21.585879</td>\n",
       "      <td>21.506178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>21.51</td>\n",
       "      <td>21.51</td>\n",
       "      <td>20.63</td>\n",
       "      <td>20.70</td>\n",
       "      <td>21.30</td>\n",
       "      <td>-2.8169</td>\n",
       "      <td>594743.14</td>\n",
       "      <td>1240067.319</td>\n",
       "      <td>4947.7459</td>\n",
       "      <td>5026.9791</td>\n",
       "      <td>5045.6018</td>\n",
       "      <td>4933.0126</td>\n",
       "      <td>5035.3374</td>\n",
       "      <td>-1.7395</td>\n",
       "      <td>0.984277</td>\n",
       "      <td>-0.176633</td>\n",
       "      <td>21.622</td>\n",
       "      <td>21.603243</td>\n",
       "      <td>21.578653</td>\n",
       "      <td>21.506328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>13.40</td>\n",
       "      <td>13.75</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.36</td>\n",
       "      <td>2.5449</td>\n",
       "      <td>1615831.92</td>\n",
       "      <td>2197501.649</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>13.262</td>\n",
       "      <td>13.228249</td>\n",
       "      <td>12.484849</td>\n",
       "      <td>12.083849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>13.58</td>\n",
       "      <td>13.58</td>\n",
       "      <td>13.06</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.70</td>\n",
       "      <td>-4.3066</td>\n",
       "      <td>1392584.28</td>\n",
       "      <td>1848277.967</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>13.360</td>\n",
       "      <td>13.345499</td>\n",
       "      <td>12.589149</td>\n",
       "      <td>12.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>13.15</td>\n",
       "      <td>13.36</td>\n",
       "      <td>13.14</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.11</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>902285.13</td>\n",
       "      <td>1194285.343</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>13.322</td>\n",
       "      <td>13.280333</td>\n",
       "      <td>12.642563</td>\n",
       "      <td>12.182030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>13.23</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>13.24</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>974061.10</td>\n",
       "      <td>1287867.945</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>13.302</td>\n",
       "      <td>13.263555</td>\n",
       "      <td>12.698510</td>\n",
       "      <td>12.223127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>13.14</td>\n",
       "      <td>13.28</td>\n",
       "      <td>12.94</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.23</td>\n",
       "      <td>-0.9826</td>\n",
       "      <td>835349.26</td>\n",
       "      <td>1094434.006</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>13.300</td>\n",
       "      <td>13.222370</td>\n",
       "      <td>12.740556</td>\n",
       "      <td>12.259083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol       amount  \\\n",
       "3726  21.55  22.09  21.51  21.68      21.50   0.8372   401102.82   873387.016   \n",
       "3727  21.88  21.93  21.31  21.64      21.68  -0.1845   517604.59  1116774.452   \n",
       "3728  21.46  21.73  21.33  21.56      21.64  -0.3697   383029.50   825170.840   \n",
       "3729  21.71  21.72  21.08  21.30      21.56  -1.2059   398960.28   849870.878   \n",
       "3730  21.51  21.51  20.63  20.70      21.30  -2.8169   594743.14  1240067.319   \n",
       "...     ...    ...    ...    ...        ...      ...         ...          ...   \n",
       "4135  13.40  13.75  13.35  13.70      13.36   2.5449  1615831.92  2197501.649   \n",
       "4136  13.58  13.58  13.06  13.11      13.70  -4.3066  1392584.28  1848277.967   \n",
       "4137  13.15  13.36  13.14  13.24      13.11   0.9916   902285.13  1194285.343   \n",
       "4138  13.23  13.40  13.08  13.23      13.24  -0.0755   974061.10  1287867.945   \n",
       "4139  13.14  13.28  12.94  13.10      13.23  -0.9826   835349.26  1094434.006   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "3726   5140.3418   5178.6401  5181.1490    5125.3301        5161.5569   \n",
       "3727   5103.7428   5141.6556  5141.6556    5065.1932        5140.3418   \n",
       "3728   5112.2086   5078.2627  5129.1318    5062.0725        5103.7428   \n",
       "3729   5035.3374   5100.0422  5100.0422    5022.0926        5112.2086   \n",
       "3730   4947.7459   5026.9791  5045.6018    4933.0126        5035.3374   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "4135   3998.2442   3961.9919  4003.3178    3944.4396        3959.1798   \n",
       "4136   3953.4433   3976.1722  3983.4332    3950.3203        3998.2442   \n",
       "4137   3945.6813   3953.5482  3964.3957    3939.9795        3953.4433   \n",
       "4138   3954.8857   3952.7885  3972.7381    3935.7668        3945.6813   \n",
       "4139   3951.9885   3954.6720  3963.5002    3926.4997        3954.8857   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "3726        -0.4110  0.997237 -0.074280  21.696  21.609543  21.553604   \n",
       "3727        -0.7120  0.995812 -0.091423  21.796  21.699695  21.584689   \n",
       "3728         0.1659  0.994092 -0.108540  21.734  21.619797  21.572814   \n",
       "3729        -1.5037  0.992078 -0.125624  21.660  21.649865  21.585879   \n",
       "3730        -1.7395  0.984277 -0.176633  21.622  21.603243  21.578653   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "4135         0.9867 -0.383078  0.923716  13.262  13.228249  12.484849   \n",
       "4136        -1.1205 -0.334918  0.942247  13.360  13.345499  12.589149   \n",
       "4137        -0.1963 -0.318660  0.947869  13.322  13.280333  12.642563   \n",
       "4138         0.2333 -0.302308  0.953210  13.302  13.263555  12.698510   \n",
       "4139        -0.0733 -0.285866  0.958270  13.300  13.222370  12.740556   \n",
       "\n",
       "          ema50  \n",
       "3726  21.483870  \n",
       "3727  21.499404  \n",
       "3728  21.497859  \n",
       "3729  21.506178  \n",
       "3730  21.506328  \n",
       "...         ...  \n",
       "4135  12.083849  \n",
       "4136  12.142521  \n",
       "4137  12.182030  \n",
       "4138  12.223127  \n",
       "4139  12.259083  \n",
       "\n",
       "[414 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 7\n",
      "Input indices: [0 1 2 3 4 5]\n",
      "Label indices: [6]\n",
      "Label column name(s): ['open']\n",
      "(TensorSpec(shape=(None, 6, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))\n",
      "Inputs shape (batch, time, features): (8, 6, 20)\n",
      "Labels shape (batch, time, features): (8, 1, 1)\n",
      "Total window size: 30\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n",
      "Label indices: [29]\n",
      "Label column name(s): ['open']\n",
      "(TensorSpec(shape=(None, 29, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))\n",
      "Inputs shape (batch, time, features): (8, 29, 20)\n",
      "Labels shape (batch, time, features): (8, 1, 1)\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 7s 12ms/step - loss: 0.1939 - mean_absolute_percentage_error: 50.5879 - val_loss: 0.1101 - val_mean_absolute_percentage_error: 79.0346 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0887 - mean_absolute_percentage_error: 25.7372 - val_loss: 0.0692 - val_mean_absolute_percentage_error: 75.4696 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0585 - mean_absolute_percentage_error: 27.4266 - val_loss: 0.0455 - val_mean_absolute_percentage_error: 71.8268 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0438 - mean_absolute_percentage_error: 33.1327 - val_loss: 0.0344 - val_mean_absolute_percentage_error: 50.0845 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0322 - mean_absolute_percentage_error: 19.2933 - val_loss: 0.0259 - val_mean_absolute_percentage_error: 34.4108 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0312 - mean_absolute_percentage_error: 27.3804 - val_loss: 0.0189 - val_mean_absolute_percentage_error: 41.5878 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0215 - mean_absolute_percentage_error: 19.5147 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 28.5733 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0184 - mean_absolute_percentage_error: 17.6750 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 21.0648 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0195 - mean_absolute_percentage_error: 21.3610 - val_loss: 0.0119 - val_mean_absolute_percentage_error: 24.6595 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0145 - mean_absolute_percentage_error: 17.1989 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 69.9898 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0145 - mean_absolute_percentage_error: 18.2179 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 53.7478 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0119 - mean_absolute_percentage_error: 16.1876 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 24.7250 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0127 - mean_absolute_percentage_error: 21.9351 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 36.4020 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0112 - mean_absolute_percentage_error: 19.3695 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 60.8308 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 16.1617 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 31.2931 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0107 - mean_absolute_percentage_error: 20.7769 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 32.9569 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 16.2793 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 29.6356 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 17.0189 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 38.5240 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 17.3004 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 23.3160 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 18.6018 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 25.7350 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 16.6450 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 47.9915 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 17.2156 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 36.4828 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0081 - mean_absolute_percentage_error: 17.3794 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 18.4040 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 15.8484 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 19.6879 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 14.1604 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 43.9322 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 14.9832 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 29.2146 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 14.7881 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 48.4638 - lr: 3.8674e-04\n",
      "Learning rate of the model:  0.00038674125\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0059 - mean_absolute_percentage_error: 48.4638\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0060 - mean_absolute_percentage_error: 22.2671\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 6s 13ms/step - loss: 0.1777 - mean_absolute_percentage_error: 48.2034 - val_loss: 0.0979 - val_mean_absolute_percentage_error: 180.3690 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0717 - mean_absolute_percentage_error: 37.9365 - val_loss: 0.0566 - val_mean_absolute_percentage_error: 95.1849 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0468 - mean_absolute_percentage_error: 28.7065 - val_loss: 0.0421 - val_mean_absolute_percentage_error: 172.1328 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0358 - mean_absolute_percentage_error: 28.4997 - val_loss: 0.0302 - val_mean_absolute_percentage_error: 74.1387 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0264 - mean_absolute_percentage_error: 21.9810 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 106.0334 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0244 - mean_absolute_percentage_error: 26.7941 - val_loss: 0.0300 - val_mean_absolute_percentage_error: 145.1723 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0211 - mean_absolute_percentage_error: 20.7384 - val_loss: 0.0173 - val_mean_absolute_percentage_error: 93.9177 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0177 - mean_absolute_percentage_error: 23.6631 - val_loss: 0.0119 - val_mean_absolute_percentage_error: 19.7046 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0168 - mean_absolute_percentage_error: 18.3808 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 30.0026 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0148 - mean_absolute_percentage_error: 23.4517 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 24.2851 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0129 - mean_absolute_percentage_error: 23.2890 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 24.0717 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 25.0446 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 21.1384 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 18.7581 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 23.0441 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 22.2850 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 26.4511 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 23.2011 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 24.3890 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 21.9246 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 19.6044 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 22.2270 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 24.8757 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 22.7405 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 26.1061 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 21.6693 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 18.8116 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0090 - mean_absolute_percentage_error: 20.6485 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 24.4466 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 19.8346 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 17.6711 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 27.1969 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 16.5255 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 20.5228 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 35.6272 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 16.7010 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 18.5463 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 21.0714 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 23.7874 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 18.4125 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 28.8692 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 19.0592 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 16.8320 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 17.4159 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 30.2764 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 18.4298 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 20.7850 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 17.8417 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 20.1025 - lr: 3.3287e-04\n",
      "Learning rate of the model:  0.0003328713\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.1025\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0050 - mean_absolute_percentage_error: 9.2055\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 6s 12ms/step - loss: 0.1669 - mean_absolute_percentage_error: 45.8593 - val_loss: 0.1044 - val_mean_absolute_percentage_error: 139.7464 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0779 - mean_absolute_percentage_error: 28.4176 - val_loss: 0.0609 - val_mean_absolute_percentage_error: 142.5165 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0527 - mean_absolute_percentage_error: 28.5391 - val_loss: 0.0411 - val_mean_absolute_percentage_error: 100.1329 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0401 - mean_absolute_percentage_error: 24.3062 - val_loss: 0.0285 - val_mean_absolute_percentage_error: 68.0184 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0287 - mean_absolute_percentage_error: 20.9640 - val_loss: 0.0236 - val_mean_absolute_percentage_error: 65.3779 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0251 - mean_absolute_percentage_error: 22.8705 - val_loss: 0.0213 - val_mean_absolute_percentage_error: 116.9878 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0204 - mean_absolute_percentage_error: 21.9397 - val_loss: 0.0174 - val_mean_absolute_percentage_error: 83.8157 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0213 - mean_absolute_percentage_error: 22.8198 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 43.5771 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0160 - mean_absolute_percentage_error: 18.3577 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 45.4074 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0187 - mean_absolute_percentage_error: 27.6409 - val_loss: 0.0126 - val_mean_absolute_percentage_error: 67.0164 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0145 - mean_absolute_percentage_error: 19.8748 - val_loss: 0.0119 - val_mean_absolute_percentage_error: 36.4342 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0160 - mean_absolute_percentage_error: 22.5221 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 32.4567 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0127 - mean_absolute_percentage_error: 19.3858 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 35.7729 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 20.6586 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 62.5296 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 21.1895 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 27.3579 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0110 - mean_absolute_percentage_error: 16.9048 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 36.5604 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 18.9395 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 31.1503 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 17.0241 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 21.8259 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 18.0168 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 45.1502 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 15.0507 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 45.3499 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 15.8133 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 25.4751 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 16.0710 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 35.5686 - lr: 4.9659e-04\n",
      "Learning rate of the model:  0.0004965855\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0076 - mean_absolute_percentage_error: 35.5686\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0067 - mean_absolute_percentage_error: 15.4348\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 6s 12ms/step - loss: 0.1909 - mean_absolute_percentage_error: 87.9439 - val_loss: 0.1044 - val_mean_absolute_percentage_error: 82.5321 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0781 - mean_absolute_percentage_error: 33.3432 - val_loss: 0.0659 - val_mean_absolute_percentage_error: 88.2765 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0512 - mean_absolute_percentage_error: 26.3641 - val_loss: 0.0502 - val_mean_absolute_percentage_error: 46.9544 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0363 - mean_absolute_percentage_error: 23.9597 - val_loss: 0.0358 - val_mean_absolute_percentage_error: 38.4110 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0298 - mean_absolute_percentage_error: 25.0577 - val_loss: 0.0261 - val_mean_absolute_percentage_error: 49.4504 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0233 - mean_absolute_percentage_error: 26.6367 - val_loss: 0.0337 - val_mean_absolute_percentage_error: 127.9239 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0214 - mean_absolute_percentage_error: 26.4970 - val_loss: 0.0224 - val_mean_absolute_percentage_error: 41.7770 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0205 - mean_absolute_percentage_error: 21.8720 - val_loss: 0.0249 - val_mean_absolute_percentage_error: 36.3274 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0161 - mean_absolute_percentage_error: 20.4346 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 54.5938 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0172 - mean_absolute_percentage_error: 20.5846 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 64.6828 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0136 - mean_absolute_percentage_error: 21.0343 - val_loss: 0.0130 - val_mean_absolute_percentage_error: 36.4025 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0138 - mean_absolute_percentage_error: 20.6507 - val_loss: 0.0184 - val_mean_absolute_percentage_error: 44.7963 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0119 - mean_absolute_percentage_error: 21.3046 - val_loss: 0.0146 - val_mean_absolute_percentage_error: 54.0213 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 19.3711 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 88.1033 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0107 - mean_absolute_percentage_error: 17.2361 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 30.3903 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0104 - mean_absolute_percentage_error: 18.6325 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 36.8633 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 16.5427 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 36.9992 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 16.4544 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 27.9973 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 16.0630 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 33.6742 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 17.7160 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 46.5281 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 16.0366 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 24.1226 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 18.0127 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 36.1659 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0081 - mean_absolute_percentage_error: 16.4796 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 24.5938 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 17.6604 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 36.2924 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 15.4765 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 29.2754 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 22.9698 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 26.2959 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 13.4468 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 26.7761 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 15.3091 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 29.7180 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 16.0130 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 26.1519 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 17.2761 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 25.4823 - lr: 3.3287e-04\n",
      "Learning rate of the model:  0.0003328713\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0058 - mean_absolute_percentage_error: 25.4823\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0057 - mean_absolute_percentage_error: 12.6231\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 7s 13ms/step - loss: 0.1684 - mean_absolute_percentage_error: 39.2723 - val_loss: 0.0906 - val_mean_absolute_percentage_error: 155.3212 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0733 - mean_absolute_percentage_error: 24.5666 - val_loss: 0.0542 - val_mean_absolute_percentage_error: 43.7050 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0475 - mean_absolute_percentage_error: 28.6629 - val_loss: 0.0438 - val_mean_absolute_percentage_error: 47.7863 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0376 - mean_absolute_percentage_error: 27.1721 - val_loss: 0.0283 - val_mean_absolute_percentage_error: 48.3511 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0263 - mean_absolute_percentage_error: 23.1442 - val_loss: 0.0206 - val_mean_absolute_percentage_error: 39.0046 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0228 - mean_absolute_percentage_error: 24.6976 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 66.3013 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0195 - mean_absolute_percentage_error: 22.5348 - val_loss: 0.0150 - val_mean_absolute_percentage_error: 43.4630 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0171 - mean_absolute_percentage_error: 18.9482 - val_loss: 0.0135 - val_mean_absolute_percentage_error: 82.2410 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0163 - mean_absolute_percentage_error: 21.6050 - val_loss: 0.0160 - val_mean_absolute_percentage_error: 137.9043 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0146 - mean_absolute_percentage_error: 18.3273 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 30.7263 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0132 - mean_absolute_percentage_error: 17.6782 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 35.1916 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0125 - mean_absolute_percentage_error: 15.5975 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 29.9846 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0120 - mean_absolute_percentage_error: 19.7405 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 32.3396 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0120 - mean_absolute_percentage_error: 16.7928 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 20.7043 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0108 - mean_absolute_percentage_error: 20.8853 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 29.9054 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0099 - mean_absolute_percentage_error: 13.9573 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 28.3644 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 16.2128 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 25.7517 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 16.6024 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 34.7499 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0099 - mean_absolute_percentage_error: 18.1260 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 52.1223 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0091 - mean_absolute_percentage_error: 15.4854 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 41.8318 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 14.4084 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 37.2617 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0085 - mean_absolute_percentage_error: 19.1413 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 21.0101 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0079 - mean_absolute_percentage_error: 15.0865 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 51.0090 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0079 - mean_absolute_percentage_error: 15.0158 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 40.7420 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0074 - mean_absolute_percentage_error: 13.7419 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 29.5656 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 14.1084 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 21.5020 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0072 - mean_absolute_percentage_error: 16.0556 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 25.8535 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.3414 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 17.6097 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 13.9146 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 30.9101 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 13.0684 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 19.5591 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 13.1378 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 25.8999 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 14.0549 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 26.3550 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 12.4059 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 26.1511 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0063 - mean_absolute_percentage_error: 12.5658 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 24.5415 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 12.4083 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 18.8881 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0062 - mean_absolute_percentage_error: 12.4308 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 21.6489 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 12.5974 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 25.3300 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 12.2774 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 23.0817 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 12.7672 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 22.2394 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 11.8881 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 20.6853 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 13.0217 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 25.2220 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 11.8514 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 25.1905 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "359/359 [==============================] - 4s 12ms/step - loss: 0.0056 - mean_absolute_percentage_error: 14.0621 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 23.4844 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 11.9865 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 24.7443 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0044 - mean_absolute_percentage_error: 24.7443\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0045 - mean_absolute_percentage_error: 12.5539\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 6s 12ms/step - loss: 0.1655 - mean_absolute_percentage_error: 45.8745 - val_loss: 0.0962 - val_mean_absolute_percentage_error: 98.3117 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0712 - mean_absolute_percentage_error: 28.5488 - val_loss: 0.0610 - val_mean_absolute_percentage_error: 50.3756 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0465 - mean_absolute_percentage_error: 31.8868 - val_loss: 0.0393 - val_mean_absolute_percentage_error: 45.4119 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0352 - mean_absolute_percentage_error: 26.5597 - val_loss: 0.0289 - val_mean_absolute_percentage_error: 42.5273 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0258 - mean_absolute_percentage_error: 24.1654 - val_loss: 0.0226 - val_mean_absolute_percentage_error: 35.0886 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0207 - mean_absolute_percentage_error: 21.7020 - val_loss: 0.0251 - val_mean_absolute_percentage_error: 87.1037 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0193 - mean_absolute_percentage_error: 23.5151 - val_loss: 0.0235 - val_mean_absolute_percentage_error: 51.3189 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0164 - mean_absolute_percentage_error: 20.9023 - val_loss: 0.0152 - val_mean_absolute_percentage_error: 54.5012 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0150 - mean_absolute_percentage_error: 21.2104 - val_loss: 0.0250 - val_mean_absolute_percentage_error: 73.3824 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0136 - mean_absolute_percentage_error: 19.3908 - val_loss: 0.0148 - val_mean_absolute_percentage_error: 52.8372 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0131 - mean_absolute_percentage_error: 18.7128 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 48.5339 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 18.7186 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 39.1636 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0108 - mean_absolute_percentage_error: 20.5279 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 53.0702 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0103 - mean_absolute_percentage_error: 17.8449 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 49.3550 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0099 - mean_absolute_percentage_error: 18.8668 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 50.1677 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 17.0421 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 39.0465 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 16.1122 - val_loss: 0.0123 - val_mean_absolute_percentage_error: 59.6433 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0091 - mean_absolute_percentage_error: 18.5447 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 59.3865 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0087 - mean_absolute_percentage_error: 17.0697 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 24.4042 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0084 - mean_absolute_percentage_error: 17.0978 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 60.0849 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 18.0405 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 27.9356 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 16.0031 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 27.4041 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 18.0246 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 24.5622 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 0.0073 - mean_absolute_percentage_error: 16.1095 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 24.6905 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 16.1949 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 24.7267 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 15.9413 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 51.4910 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 21.9448 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 24.1709 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 15.1364 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 41.0299 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 16.5988 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 20.0811 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 14.9297 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 23.1266 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 15.0165 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 38.6378 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 13.3402 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 21.1033 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 14.0732 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 26.9019 - lr: 2.8651e-04\n",
      "Learning rate of the model:  0.000286505\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0057 - mean_absolute_percentage_error: 26.9019\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0046 - mean_absolute_percentage_error: 10.7279\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 7s 12ms/step - loss: 0.1729 - mean_absolute_percentage_error: 41.9479 - val_loss: 0.0887 - val_mean_absolute_percentage_error: 57.8790 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0729 - mean_absolute_percentage_error: 27.9670 - val_loss: 0.0508 - val_mean_absolute_percentage_error: 38.6571 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0449 - mean_absolute_percentage_error: 24.5778 - val_loss: 0.0401 - val_mean_absolute_percentage_error: 61.5859 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0347 - mean_absolute_percentage_error: 27.3097 - val_loss: 0.0261 - val_mean_absolute_percentage_error: 37.3574 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0284 - mean_absolute_percentage_error: 23.5513 - val_loss: 0.0209 - val_mean_absolute_percentage_error: 36.7639 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0229 - mean_absolute_percentage_error: 21.0390 - val_loss: 0.0190 - val_mean_absolute_percentage_error: 33.4290 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0203 - mean_absolute_percentage_error: 22.0557 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 68.3057 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0176 - mean_absolute_percentage_error: 20.1274 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 39.6672 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0157 - mean_absolute_percentage_error: 19.6413 - val_loss: 0.0138 - val_mean_absolute_percentage_error: 54.4761 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0166 - mean_absolute_percentage_error: 20.2575 - val_loss: 0.0122 - val_mean_absolute_percentage_error: 29.0677 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0137 - mean_absolute_percentage_error: 17.0567 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 28.5741 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0130 - mean_absolute_percentage_error: 18.5258 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 47.4454 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0142 - mean_absolute_percentage_error: 22.1699 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 26.1514 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0122 - mean_absolute_percentage_error: 15.9655 - val_loss: 0.0125 - val_mean_absolute_percentage_error: 64.1360 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0110 - mean_absolute_percentage_error: 16.5699 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 25.0878 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 16.5677 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 38.3134 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 16.3851 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 49.4493 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 20.1894 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 30.5150 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 16.3807 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 29.3286 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 15.6676 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 29.6410 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 17.1847 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 27.4660 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 15.1493 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 24.8413 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 18.1016 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 26.5440 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 15.2318 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 26.1149 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 14.5188 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 28.4222 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 14.3968 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 43.3476 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 17.5959 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 32.8410 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 16.1590 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 41.4836 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 15.7081 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 32.2695 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 14.1378 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 29.6150 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 12.8568 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 27.4572 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 12.8715 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 22.9865 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.6610 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 24.3578 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 12.9830 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 27.6654 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 15.1260 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 24.4245 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 13.1656 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 26.9075 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 13.1794 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 27.4503 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 12.5672 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 19.0267 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 12.8244 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 22.1294 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0062 - mean_absolute_percentage_error: 11.5459 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 20.4692 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 11.4839 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 18.9232 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 12.4121 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 18.7976 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 13.3228 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 18.6331 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 12.3547 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 21.1073 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 13.2859 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 22.2677 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0062 - mean_absolute_percentage_error: 13.3998 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 18.6271 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 11.6015 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 18.4549 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0058 - mean_absolute_percentage_error: 11.7199 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 21.6862 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0058 - mean_absolute_percentage_error: 11.8502 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 20.6851 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 12.8857 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 19.9228 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 14.4259 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 40.5685 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 13.1153 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 18.6255 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 13.0552 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 25.3216 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 14.1836 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 22.4488 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 12.3942 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 20.2737 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 13.9873 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 19.6859 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0045 - mean_absolute_percentage_error: 19.6859\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0044 - mean_absolute_percentage_error: 11.4622\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 6s 12ms/step - loss: 0.1672 - mean_absolute_percentage_error: 53.4098 - val_loss: 0.0895 - val_mean_absolute_percentage_error: 79.8818 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0724 - mean_absolute_percentage_error: 29.1995 - val_loss: 0.0555 - val_mean_absolute_percentage_error: 63.0647 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0476 - mean_absolute_percentage_error: 28.8810 - val_loss: 0.0446 - val_mean_absolute_percentage_error: 156.8183 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0351 - mean_absolute_percentage_error: 24.5032 - val_loss: 0.0307 - val_mean_absolute_percentage_error: 97.7591 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0274 - mean_absolute_percentage_error: 22.4466 - val_loss: 0.0225 - val_mean_absolute_percentage_error: 107.3348 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0219 - mean_absolute_percentage_error: 21.2214 - val_loss: 0.0209 - val_mean_absolute_percentage_error: 59.4015 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0216 - mean_absolute_percentage_error: 21.8444 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 81.6070 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0167 - mean_absolute_percentage_error: 24.0172 - val_loss: 0.0161 - val_mean_absolute_percentage_error: 78.1093 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0154 - mean_absolute_percentage_error: 21.1844 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 91.3651 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0139 - mean_absolute_percentage_error: 18.2968 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 62.7796 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0123 - mean_absolute_percentage_error: 17.7108 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 62.5251 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0123 - mean_absolute_percentage_error: 20.9034 - val_loss: 0.0130 - val_mean_absolute_percentage_error: 45.5942 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0137 - mean_absolute_percentage_error: 19.6557 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 56.7133 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 17.5683 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 94.3193 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0105 - mean_absolute_percentage_error: 20.2515 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 31.1500 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0107 - mean_absolute_percentage_error: 16.4815 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 30.3000 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 21.1883 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 79.0965 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 15.2414 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 60.1466 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 17.1317 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 43.6259 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 16.8792 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 45.1041 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 16.3726 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 49.0507 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 14.5586 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 54.0427 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 16.6241 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 52.9365 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 14.7301 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 21.6443 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 14.2471 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 31.6025 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 15.3623 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 38.5523 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 15.0212 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 31.2111 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.5841 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 48.8689 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.4377 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 39.0690 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 16.0094 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 30.1488 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 12.2309 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 30.2128 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 15.9970 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 29.9856 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 14.3544 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 21.9678 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 13.5562 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 40.0007 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 14.4086 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 22.3494 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 13.8076 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 42.8107 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 12.9661 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 37.5616 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0060 - mean_absolute_percentage_error: 13.4020 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 60.2833 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 12.5143 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 37.1805 - lr: 2.1225e-04\n",
      "Learning rate of the model:  0.00021224817\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0049 - mean_absolute_percentage_error: 37.1805\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0049 - mean_absolute_percentage_error: 10.4802\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 7s 13ms/step - loss: 0.2481 - mean_absolute_percentage_error: 65.8896 - val_loss: 0.0950 - val_mean_absolute_percentage_error: 154.6616 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0708 - mean_absolute_percentage_error: 28.0031 - val_loss: 0.0560 - val_mean_absolute_percentage_error: 186.7971 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0476 - mean_absolute_percentage_error: 26.5651 - val_loss: 0.0382 - val_mean_absolute_percentage_error: 113.0859 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0357 - mean_absolute_percentage_error: 22.1586 - val_loss: 0.0304 - val_mean_absolute_percentage_error: 97.0603 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0274 - mean_absolute_percentage_error: 21.0858 - val_loss: 0.0248 - val_mean_absolute_percentage_error: 69.4860 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0236 - mean_absolute_percentage_error: 21.2987 - val_loss: 0.0178 - val_mean_absolute_percentage_error: 34.4126 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0206 - mean_absolute_percentage_error: 24.2149 - val_loss: 0.0165 - val_mean_absolute_percentage_error: 37.5689 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0184 - mean_absolute_percentage_error: 19.9986 - val_loss: 0.0165 - val_mean_absolute_percentage_error: 48.7137 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0154 - mean_absolute_percentage_error: 18.2842 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 47.1548 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0147 - mean_absolute_percentage_error: 18.5656 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 30.3630 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0154 - mean_absolute_percentage_error: 19.1044 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 50.6009 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 20.0461 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 22.4750 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0130 - mean_absolute_percentage_error: 21.5093 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 33.1050 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0124 - mean_absolute_percentage_error: 21.3685 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 75.8409 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0110 - mean_absolute_percentage_error: 17.7592 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 25.4192 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 14.2816 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 21.3721 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0107 - mean_absolute_percentage_error: 15.6660 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 24.5897 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 15.5676 - val_loss: 0.0110 - val_mean_absolute_percentage_error: 46.1103 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 15.9974 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 22.6310 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0095 - mean_absolute_percentage_error: 16.1479 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 22.0584 - lr: 5.4881e-04\n",
      "Learning rate of the model:  0.00054881186\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0090 - mean_absolute_percentage_error: 22.0584\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0080 - mean_absolute_percentage_error: 14.9708\n",
      "Epoch 1/60\n",
      "359/359 [==============================] - 7s 13ms/step - loss: 0.2027 - mean_absolute_percentage_error: 59.8170 - val_loss: 0.1182 - val_mean_absolute_percentage_error: 191.9127 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0847 - mean_absolute_percentage_error: 27.7909 - val_loss: 0.0621 - val_mean_absolute_percentage_error: 119.3887 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0548 - mean_absolute_percentage_error: 29.1057 - val_loss: 0.0428 - val_mean_absolute_percentage_error: 55.5471 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0401 - mean_absolute_percentage_error: 23.3536 - val_loss: 0.0303 - val_mean_absolute_percentage_error: 73.9037 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0300 - mean_absolute_percentage_error: 22.2328 - val_loss: 0.0225 - val_mean_absolute_percentage_error: 43.5440 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0252 - mean_absolute_percentage_error: 26.6672 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 27.6827 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0210 - mean_absolute_percentage_error: 22.8602 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 43.5457 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0182 - mean_absolute_percentage_error: 21.6224 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 37.2980 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0163 - mean_absolute_percentage_error: 22.8980 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 21.2132 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0152 - mean_absolute_percentage_error: 18.0448 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 26.7815 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0138 - mean_absolute_percentage_error: 19.3251 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 24.5242 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0129 - mean_absolute_percentage_error: 19.9913 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 19.8792 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0122 - mean_absolute_percentage_error: 19.8775 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 27.7091 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 17.1108 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 20.0734 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0110 - mean_absolute_percentage_error: 22.2382 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 20.8299 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0099 - mean_absolute_percentage_error: 16.9000 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 21.8939 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0103 - mean_absolute_percentage_error: 16.9561 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 27.3397 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 16.2351 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 32.6042 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 15.4761 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 22.0896 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 19.2312 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 18.8100 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 16.6561 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 29.0998 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0085 - mean_absolute_percentage_error: 17.2278 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 23.1330 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0079 - mean_absolute_percentage_error: 15.1038 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 23.7702 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0079 - mean_absolute_percentage_error: 16.5027 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 27.6137 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 16.5986 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 18.4794 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 16.9964 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 19.1812 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 15.5699 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 23.0408 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 19.7377 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 24.6782 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.3502 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 18.6220 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 15.2989 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 19.1634 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0067 - mean_absolute_percentage_error: 13.2018 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 26.1906 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 17.3341 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 21.8085 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 14.4676 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 18.9840 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 16.9303 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 17.8606 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 14.2424 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 18.6470 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 14.2134 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 20.5698 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0059 - mean_absolute_percentage_error: 13.7399 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 22.1229 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 15.3857 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 21.8561 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 13.2182 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 20.9066 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 13.4705 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 19.1342 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 14.6633 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 19.7482 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 13.0414 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 27.8865 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 13.5214 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 19.8366 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0056 - mean_absolute_percentage_error: 13.4503 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 18.0672 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 13.7774 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 20.9667 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0055 - mean_absolute_percentage_error: 15.2009 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 18.5688 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0054 - mean_absolute_percentage_error: 12.6751 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 20.7963 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0053 - mean_absolute_percentage_error: 13.0122 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 19.6950 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0054 - mean_absolute_percentage_error: 12.6399 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 19.7499 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0052 - mean_absolute_percentage_error: 13.8071 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 21.0011 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0052 - mean_absolute_percentage_error: 13.4621 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 20.5444 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "359/359 [==============================] - 3s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 11.9404 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 18.7380 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0054 - mean_absolute_percentage_error: 13.9622 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 37.8352 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 13.3430 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 21.9384 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0050 - mean_absolute_percentage_error: 12.0004 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 18.8837 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.0053 - mean_absolute_percentage_error: 13.6124 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 18.8249 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0042 - mean_absolute_percentage_error: 18.8249\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0043 - mean_absolute_percentage_error: 9.9169\n",
      "df instances :  4085\n",
      "df features :  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.30</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>-6.0200</td>\n",
       "      <td>396529.96</td>\n",
       "      <td>1.997286e+05</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>5.620</td>\n",
       "      <td>5.506161</td>\n",
       "      <td>5.590849</td>\n",
       "      <td>5.608366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.90</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>188469.93</td>\n",
       "      <td>9.152611e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>5.420</td>\n",
       "      <td>5.284662</td>\n",
       "      <td>5.445111</td>\n",
       "      <td>5.478191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.90</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2.4500</td>\n",
       "      <td>91916.37</td>\n",
       "      <td>4.574560e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>5.260</td>\n",
       "      <td>5.148470</td>\n",
       "      <td>5.342044</td>\n",
       "      <td>5.385357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.02</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.97</td>\n",
       "      <td>5.02</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>57946.94</td>\n",
       "      <td>2.888704e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>5.114</td>\n",
       "      <td>5.103908</td>\n",
       "      <td>5.286377</td>\n",
       "      <td>5.333044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.98</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>86893.16</td>\n",
       "      <td>4.336294e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.061502</td>\n",
       "      <td>5.237233</td>\n",
       "      <td>5.287254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>19.37</td>\n",
       "      <td>20.63</td>\n",
       "      <td>19.26</td>\n",
       "      <td>20.46</td>\n",
       "      <td>19.38</td>\n",
       "      <td>5.5728</td>\n",
       "      <td>2177339.59</td>\n",
       "      <td>4.380718e+06</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>18.906</td>\n",
       "      <td>18.858026</td>\n",
       "      <td>17.515825</td>\n",
       "      <td>16.816367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>20.11</td>\n",
       "      <td>20.25</td>\n",
       "      <td>19.36</td>\n",
       "      <td>19.45</td>\n",
       "      <td>20.46</td>\n",
       "      <td>-4.9365</td>\n",
       "      <td>1159201.79</td>\n",
       "      <td>2.288940e+06</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>19.148</td>\n",
       "      <td>19.275351</td>\n",
       "      <td>17.762889</td>\n",
       "      <td>16.945529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>19.45</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.16</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>752615.03</td>\n",
       "      <td>1.460347e+06</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>19.278</td>\n",
       "      <td>19.333567</td>\n",
       "      <td>17.923566</td>\n",
       "      <td>17.043744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>19.40</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-1.1807</td>\n",
       "      <td>790763.58</td>\n",
       "      <td>1.524378e+06</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>19.376</td>\n",
       "      <td>19.355711</td>\n",
       "      <td>18.064179</td>\n",
       "      <td>17.136146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>18.88</td>\n",
       "      <td>19.24</td>\n",
       "      <td>18.50</td>\n",
       "      <td>19.12</td>\n",
       "      <td>19.25</td>\n",
       "      <td>-0.6753</td>\n",
       "      <td>915828.17</td>\n",
       "      <td>1.723767e+06</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>19.442</td>\n",
       "      <td>19.197141</td>\n",
       "      <td>18.141876</td>\n",
       "      <td>17.204533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4085 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol  \\\n",
       "4      5.30   5.30   4.79   5.00       5.32  -6.0200   396529.96   \n",
       "5      4.90   4.92   4.80   4.90       5.00  -2.0000   188469.93   \n",
       "6      4.90   5.06   4.86   5.02       4.90   2.4500    91916.37   \n",
       "7      5.02   5.05   4.90   4.97       5.02  -1.0000    57946.94   \n",
       "8      4.98   5.08   4.91   5.01       4.97   0.8000    86893.16   \n",
       "...     ...    ...    ...    ...        ...      ...         ...   \n",
       "4084  19.37  20.63  19.26  20.46      19.38   5.5728  2177339.59   \n",
       "4085  20.11  20.25  19.36  19.45      20.46  -4.9365  1159201.79   \n",
       "4086  19.45  19.60  19.16  19.48      19.45   0.1542   752615.03   \n",
       "4087  19.40  19.60  19.05  19.25      19.48  -1.1807   790763.58   \n",
       "4088  18.88  19.24  18.50  19.12      19.25  -0.6753   915828.17   \n",
       "\n",
       "            amount  index_open  index_high  index_low  index_close  \\\n",
       "4     1.997286e+05    887.5430    883.5050   898.5050     875.5760   \n",
       "5     9.152611e+04    875.2710    885.3890   885.3890     869.3340   \n",
       "6     4.574560e+04    881.4620    873.0770   888.2810     868.2120   \n",
       "7     2.888704e+04    883.1960    881.1410   890.4030     871.8210   \n",
       "8     4.336294e+04    884.1710    882.8420   888.0160     871.2890   \n",
       "...            ...         ...         ...        ...          ...   \n",
       "4084  4.380718e+06   3998.2442   3961.9919  4003.3178    3944.4396   \n",
       "4085  2.288940e+06   3953.4433   3976.1722  3983.4332    3950.3203   \n",
       "4086  1.460347e+06   3945.6813   3953.5482  3964.3957    3939.9795   \n",
       "4087  1.524378e+06   3954.8857   3952.7885  3972.7381    3935.7668   \n",
       "4088  1.723767e+06   3951.9885   3954.6720  3963.5002    3926.4997   \n",
       "\n",
       "      index_pre_close  index_pct_chg  Year sin  Year cos    sma5       ema5  \\\n",
       "4            885.8200         0.1945  0.759152 -0.650913   5.620   5.506161   \n",
       "5            887.5430        -1.3827  0.724564 -0.689208   5.420   5.284662   \n",
       "6            875.2710         0.7073  0.712601 -0.701570   5.260   5.148470   \n",
       "7            881.4620         0.1967  0.700427 -0.713724   5.114   5.103908   \n",
       "8            883.1960         0.1104  0.688046 -0.725667   5.020   5.061502   \n",
       "...               ...            ...       ...       ...     ...        ...   \n",
       "4084        3959.1798         0.9867 -0.383078  0.923716  18.906  18.858026   \n",
       "4085        3998.2442        -1.1205 -0.334918  0.942247  19.148  19.275351   \n",
       "4086        3953.4433        -0.1963 -0.318660  0.947869  19.278  19.333567   \n",
       "4087        3945.6813         0.2333 -0.302308  0.953210  19.376  19.355711   \n",
       "4088        3954.8857        -0.0733 -0.285866  0.958270  19.442  19.197141   \n",
       "\n",
       "          ema20      ema50  \n",
       "4      5.590849   5.608366  \n",
       "5      5.445111   5.478191  \n",
       "6      5.342044   5.385357  \n",
       "7      5.286377   5.333044  \n",
       "8      5.237233   5.287254  \n",
       "...         ...        ...  \n",
       "4084  17.515825  16.816367  \n",
       "4085  17.762889  16.945529  \n",
       "4086  17.923566  17.043744  \n",
       "4087  18.064179  17.136146  \n",
       "4088  18.141876  17.204533  \n",
       "\n",
       "[4085 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df instances :  2859\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.30</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>-6.02</td>\n",
       "      <td>396529.96</td>\n",
       "      <td>1.997286e+05</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>883.5050</td>\n",
       "      <td>898.5050</td>\n",
       "      <td>875.5760</td>\n",
       "      <td>885.8200</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.759152</td>\n",
       "      <td>-0.650913</td>\n",
       "      <td>5.620</td>\n",
       "      <td>5.506161</td>\n",
       "      <td>5.590849</td>\n",
       "      <td>5.608366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.90</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>188469.93</td>\n",
       "      <td>9.152611e+04</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>885.3890</td>\n",
       "      <td>869.3340</td>\n",
       "      <td>887.5430</td>\n",
       "      <td>-1.3827</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>-0.689208</td>\n",
       "      <td>5.420</td>\n",
       "      <td>5.284662</td>\n",
       "      <td>5.445111</td>\n",
       "      <td>5.478191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.90</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2.45</td>\n",
       "      <td>91916.37</td>\n",
       "      <td>4.574560e+04</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>873.0770</td>\n",
       "      <td>888.2810</td>\n",
       "      <td>868.2120</td>\n",
       "      <td>875.2710</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.712601</td>\n",
       "      <td>-0.701570</td>\n",
       "      <td>5.260</td>\n",
       "      <td>5.148470</td>\n",
       "      <td>5.342044</td>\n",
       "      <td>5.385357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.02</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.97</td>\n",
       "      <td>5.02</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>57946.94</td>\n",
       "      <td>2.888704e+04</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>881.1410</td>\n",
       "      <td>890.4030</td>\n",
       "      <td>871.8210</td>\n",
       "      <td>881.4620</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.700427</td>\n",
       "      <td>-0.713724</td>\n",
       "      <td>5.114</td>\n",
       "      <td>5.103908</td>\n",
       "      <td>5.286377</td>\n",
       "      <td>5.333044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.98</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>86893.16</td>\n",
       "      <td>4.336294e+04</td>\n",
       "      <td>884.1710</td>\n",
       "      <td>882.8420</td>\n",
       "      <td>888.0160</td>\n",
       "      <td>871.2890</td>\n",
       "      <td>883.1960</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>-0.725667</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.061502</td>\n",
       "      <td>5.237233</td>\n",
       "      <td>5.287254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>32.42</td>\n",
       "      <td>32.74</td>\n",
       "      <td>31.02</td>\n",
       "      <td>31.30</td>\n",
       "      <td>32.50</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>580325.38</td>\n",
       "      <td>1.851670e+06</td>\n",
       "      <td>4102.3966</td>\n",
       "      <td>4213.3781</td>\n",
       "      <td>4214.1895</td>\n",
       "      <td>4086.9018</td>\n",
       "      <td>4227.5666</td>\n",
       "      <td>-2.9608</td>\n",
       "      <td>-0.616835</td>\n",
       "      <td>0.787092</td>\n",
       "      <td>30.102</td>\n",
       "      <td>30.546949</td>\n",
       "      <td>28.701428</td>\n",
       "      <td>27.353648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>31.18</td>\n",
       "      <td>32.29</td>\n",
       "      <td>30.47</td>\n",
       "      <td>31.80</td>\n",
       "      <td>31.30</td>\n",
       "      <td>1.60</td>\n",
       "      <td>524343.06</td>\n",
       "      <td>1.653488e+06</td>\n",
       "      <td>4104.2034</td>\n",
       "      <td>4089.4723</td>\n",
       "      <td>4116.5942</td>\n",
       "      <td>4057.4894</td>\n",
       "      <td>4102.3966</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>-0.603204</td>\n",
       "      <td>0.797587</td>\n",
       "      <td>30.568</td>\n",
       "      <td>30.757966</td>\n",
       "      <td>28.937482</td>\n",
       "      <td>27.503701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>31.45</td>\n",
       "      <td>32.60</td>\n",
       "      <td>30.59</td>\n",
       "      <td>31.52</td>\n",
       "      <td>31.80</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>521581.28</td>\n",
       "      <td>1.640697e+06</td>\n",
       "      <td>4049.9475</td>\n",
       "      <td>4088.9318</td>\n",
       "      <td>4088.9318</td>\n",
       "      <td>4037.1457</td>\n",
       "      <td>4104.2034</td>\n",
       "      <td>-1.3220</td>\n",
       "      <td>-0.561257</td>\n",
       "      <td>0.827641</td>\n",
       "      <td>31.098</td>\n",
       "      <td>30.988644</td>\n",
       "      <td>29.176770</td>\n",
       "      <td>27.658458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>31.09</td>\n",
       "      <td>31.35</td>\n",
       "      <td>30.10</td>\n",
       "      <td>30.75</td>\n",
       "      <td>31.52</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>405786.49</td>\n",
       "      <td>1.243496e+06</td>\n",
       "      <td>4055.8235</td>\n",
       "      <td>4034.2057</td>\n",
       "      <td>4056.4753</td>\n",
       "      <td>4010.2955</td>\n",
       "      <td>4049.9475</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>-0.546937</td>\n",
       "      <td>0.837174</td>\n",
       "      <td>31.608</td>\n",
       "      <td>31.022429</td>\n",
       "      <td>29.358982</td>\n",
       "      <td>27.793028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>30.78</td>\n",
       "      <td>33.83</td>\n",
       "      <td>30.28</td>\n",
       "      <td>33.82</td>\n",
       "      <td>30.75</td>\n",
       "      <td>9.98</td>\n",
       "      <td>897712.59</td>\n",
       "      <td>2.894401e+06</td>\n",
       "      <td>4053.7529</td>\n",
       "      <td>4061.3545</td>\n",
       "      <td>4069.2418</td>\n",
       "      <td>4004.6870</td>\n",
       "      <td>4055.8235</td>\n",
       "      <td>-0.0511</td>\n",
       "      <td>-0.532455</td>\n",
       "      <td>0.846458</td>\n",
       "      <td>31.384</td>\n",
       "      <td>30.941620</td>\n",
       "      <td>29.494317</td>\n",
       "      <td>27.910164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2859 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg        vol        amount  \\\n",
       "4      5.30   5.30   4.79   5.00       5.32    -6.02  396529.96  1.997286e+05   \n",
       "5      4.90   4.92   4.80   4.90       5.00    -2.00  188469.93  9.152611e+04   \n",
       "6      4.90   5.06   4.86   5.02       4.90     2.45   91916.37  4.574560e+04   \n",
       "7      5.02   5.05   4.90   4.97       5.02    -1.00   57946.94  2.888704e+04   \n",
       "8      4.98   5.08   4.91   5.01       4.97     0.80   86893.16  4.336294e+04   \n",
       "...     ...    ...    ...    ...        ...      ...        ...           ...   \n",
       "2858  32.42  32.74  31.02  31.30      32.50    -3.69  580325.38  1.851670e+06   \n",
       "2859  31.18  32.29  30.47  31.80      31.30     1.60  524343.06  1.653488e+06   \n",
       "2860  31.45  32.60  30.59  31.52      31.80    -0.88  521581.28  1.640697e+06   \n",
       "2861  31.09  31.35  30.10  30.75      31.52    -2.44  405786.49  1.243496e+06   \n",
       "2862  30.78  33.83  30.28  33.82      30.75     9.98  897712.59  2.894401e+06   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "4       887.5430    883.5050   898.5050     875.5760         885.8200   \n",
       "5       875.2710    885.3890   885.3890     869.3340         887.5430   \n",
       "6       881.4620    873.0770   888.2810     868.2120         875.2710   \n",
       "7       883.1960    881.1410   890.4030     871.8210         881.4620   \n",
       "8       884.1710    882.8420   888.0160     871.2890         883.1960   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "2858   4102.3966   4213.3781  4214.1895    4086.9018        4227.5666   \n",
       "2859   4104.2034   4089.4723  4116.5942    4057.4894        4102.3966   \n",
       "2860   4049.9475   4088.9318  4088.9318    4037.1457        4104.2034   \n",
       "2861   4055.8235   4034.2057  4056.4753    4010.2955        4049.9475   \n",
       "2862   4053.7529   4061.3545  4069.2418    4004.6870        4055.8235   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "4            0.1945  0.759152 -0.650913   5.620   5.506161   5.590849   \n",
       "5           -1.3827  0.724564 -0.689208   5.420   5.284662   5.445111   \n",
       "6            0.7073  0.712601 -0.701570   5.260   5.148470   5.342044   \n",
       "7            0.1967  0.700427 -0.713724   5.114   5.103908   5.286377   \n",
       "8            0.1104  0.688046 -0.725667   5.020   5.061502   5.237233   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "2858        -2.9608 -0.616835  0.787092  30.102  30.546949  28.701428   \n",
       "2859         0.0440 -0.603204  0.797587  30.568  30.757966  28.937482   \n",
       "2860        -1.3220 -0.561257  0.827641  31.098  30.988644  29.176770   \n",
       "2861         0.1451 -0.546937  0.837174  31.608  31.022429  29.358982   \n",
       "2862        -0.0511 -0.532455  0.846458  31.384  30.941620  29.494317   \n",
       "\n",
       "          ema50  \n",
       "4      5.608366  \n",
       "5      5.478191  \n",
       "6      5.385357  \n",
       "7      5.333044  \n",
       "8      5.287254  \n",
       "...         ...  \n",
       "2858  27.353648  \n",
       "2859  27.503701  \n",
       "2860  27.658458  \n",
       "2861  27.793028  \n",
       "2862  27.910164  \n",
       "\n",
       "[2859 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "val_df instances :  817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>33.10</td>\n",
       "      <td>33.40</td>\n",
       "      <td>30.68</td>\n",
       "      <td>31.22</td>\n",
       "      <td>33.82</td>\n",
       "      <td>-7.6900</td>\n",
       "      <td>1000665.49</td>\n",
       "      <td>3213854.404</td>\n",
       "      <td>4006.0993</td>\n",
       "      <td>4034.0091</td>\n",
       "      <td>4052.7970</td>\n",
       "      <td>3988.0018</td>\n",
       "      <td>4053.7529</td>\n",
       "      <td>-1.1755</td>\n",
       "      <td>-0.517816</td>\n",
       "      <td>0.855492</td>\n",
       "      <td>31.520</td>\n",
       "      <td>31.661080</td>\n",
       "      <td>29.837715</td>\n",
       "      <td>28.113687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>30.50</td>\n",
       "      <td>32.03</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.22</td>\n",
       "      <td>-1.5700</td>\n",
       "      <td>557438.55</td>\n",
       "      <td>1733100.368</td>\n",
       "      <td>3998.1365</td>\n",
       "      <td>4003.5604</td>\n",
       "      <td>4027.1064</td>\n",
       "      <td>3984.3776</td>\n",
       "      <td>4006.0993</td>\n",
       "      <td>-0.1988</td>\n",
       "      <td>-0.503023</td>\n",
       "      <td>0.864273</td>\n",
       "      <td>31.384</td>\n",
       "      <td>31.274053</td>\n",
       "      <td>29.900790</td>\n",
       "      <td>28.207268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>30.60</td>\n",
       "      <td>31.30</td>\n",
       "      <td>29.90</td>\n",
       "      <td>30.85</td>\n",
       "      <td>30.73</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>379890.01</td>\n",
       "      <td>1160069.276</td>\n",
       "      <td>4018.8571</td>\n",
       "      <td>3989.0466</td>\n",
       "      <td>4032.9859</td>\n",
       "      <td>3982.3182</td>\n",
       "      <td>3998.1365</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>-0.457769</td>\n",
       "      <td>0.889071</td>\n",
       "      <td>31.214</td>\n",
       "      <td>31.049369</td>\n",
       "      <td>29.967382</td>\n",
       "      <td>28.301101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>30.60</td>\n",
       "      <td>31.48</td>\n",
       "      <td>30.20</td>\n",
       "      <td>31.03</td>\n",
       "      <td>30.85</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>564302.01</td>\n",
       "      <td>1747240.922</td>\n",
       "      <td>4040.1704</td>\n",
       "      <td>4007.9361</td>\n",
       "      <td>4045.9331</td>\n",
       "      <td>4006.5432</td>\n",
       "      <td>4018.8571</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>-0.442408</td>\n",
       "      <td>0.896814</td>\n",
       "      <td>31.116</td>\n",
       "      <td>30.899579</td>\n",
       "      <td>30.027631</td>\n",
       "      <td>28.391254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>30.73</td>\n",
       "      <td>31.20</td>\n",
       "      <td>30.26</td>\n",
       "      <td>30.77</td>\n",
       "      <td>31.03</td>\n",
       "      <td>-0.8400</td>\n",
       "      <td>389794.45</td>\n",
       "      <td>1197517.724</td>\n",
       "      <td>4015.8211</td>\n",
       "      <td>4027.1231</td>\n",
       "      <td>4031.7533</td>\n",
       "      <td>3964.8087</td>\n",
       "      <td>4040.1704</td>\n",
       "      <td>-0.6027</td>\n",
       "      <td>-0.426916</td>\n",
       "      <td>0.904291</td>\n",
       "      <td>31.106</td>\n",
       "      <td>30.843053</td>\n",
       "      <td>30.094523</td>\n",
       "      <td>28.482969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.43</td>\n",
       "      <td>30.00</td>\n",
       "      <td>-1.9000</td>\n",
       "      <td>583845.70</td>\n",
       "      <td>1724509.734</td>\n",
       "      <td>5140.3418</td>\n",
       "      <td>5178.6401</td>\n",
       "      <td>5181.1490</td>\n",
       "      <td>5125.3301</td>\n",
       "      <td>5161.5569</td>\n",
       "      <td>-0.4110</td>\n",
       "      <td>0.997237</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>30.392</td>\n",
       "      <td>30.286332</td>\n",
       "      <td>30.883498</td>\n",
       "      <td>30.591909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>29.50</td>\n",
       "      <td>29.72</td>\n",
       "      <td>29.27</td>\n",
       "      <td>29.70</td>\n",
       "      <td>29.43</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>488440.53</td>\n",
       "      <td>1441764.754</td>\n",
       "      <td>5103.7428</td>\n",
       "      <td>5141.6556</td>\n",
       "      <td>5141.6556</td>\n",
       "      <td>5065.1932</td>\n",
       "      <td>5140.3418</td>\n",
       "      <td>-0.7120</td>\n",
       "      <td>0.995812</td>\n",
       "      <td>-0.091423</td>\n",
       "      <td>30.094</td>\n",
       "      <td>30.024221</td>\n",
       "      <td>30.751736</td>\n",
       "      <td>30.549089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>29.40</td>\n",
       "      <td>29.48</td>\n",
       "      <td>28.98</td>\n",
       "      <td>29.17</td>\n",
       "      <td>29.70</td>\n",
       "      <td>-1.7845</td>\n",
       "      <td>630400.64</td>\n",
       "      <td>1836528.786</td>\n",
       "      <td>5112.2086</td>\n",
       "      <td>5078.2627</td>\n",
       "      <td>5129.1318</td>\n",
       "      <td>5062.0725</td>\n",
       "      <td>5103.7428</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.994092</td>\n",
       "      <td>-0.108540</td>\n",
       "      <td>29.780</td>\n",
       "      <td>29.816147</td>\n",
       "      <td>30.622999</td>\n",
       "      <td>30.504027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>29.30</td>\n",
       "      <td>29.32</td>\n",
       "      <td>28.73</td>\n",
       "      <td>28.86</td>\n",
       "      <td>29.17</td>\n",
       "      <td>-1.0627</td>\n",
       "      <td>528595.80</td>\n",
       "      <td>1527734.333</td>\n",
       "      <td>5035.3374</td>\n",
       "      <td>5100.0422</td>\n",
       "      <td>5100.0422</td>\n",
       "      <td>5022.0926</td>\n",
       "      <td>5112.2086</td>\n",
       "      <td>-1.5037</td>\n",
       "      <td>0.992078</td>\n",
       "      <td>-0.125624</td>\n",
       "      <td>29.640</td>\n",
       "      <td>29.644098</td>\n",
       "      <td>30.496999</td>\n",
       "      <td>30.456810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>29.01</td>\n",
       "      <td>29.09</td>\n",
       "      <td>28.50</td>\n",
       "      <td>28.59</td>\n",
       "      <td>28.86</td>\n",
       "      <td>-0.9356</td>\n",
       "      <td>635227.77</td>\n",
       "      <td>1826857.600</td>\n",
       "      <td>4947.7459</td>\n",
       "      <td>5026.9791</td>\n",
       "      <td>5045.6018</td>\n",
       "      <td>4933.0126</td>\n",
       "      <td>5035.3374</td>\n",
       "      <td>-1.7395</td>\n",
       "      <td>0.984277</td>\n",
       "      <td>-0.176633</td>\n",
       "      <td>29.442</td>\n",
       "      <td>29.432732</td>\n",
       "      <td>30.355380</td>\n",
       "      <td>30.400072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol       amount  \\\n",
       "2863  33.10  33.40  30.68  31.22      33.82  -7.6900  1000665.49  3213854.404   \n",
       "2864  30.50  32.03  30.50  30.73      31.22  -1.5700   557438.55  1733100.368   \n",
       "2865  30.60  31.30  29.90  30.85      30.73   0.3900   379890.01  1160069.276   \n",
       "2866  30.60  31.48  30.20  31.03      30.85   0.5800   564302.01  1747240.922   \n",
       "2867  30.73  31.20  30.26  30.77      31.03  -0.8400   389794.45  1197517.724   \n",
       "...     ...    ...    ...    ...        ...      ...         ...          ...   \n",
       "3675  30.00  30.00  29.22  29.43      30.00  -1.9000   583845.70  1724509.734   \n",
       "3676  29.50  29.72  29.27  29.70      29.43   0.9174   488440.53  1441764.754   \n",
       "3677  29.40  29.48  28.98  29.17      29.70  -1.7845   630400.64  1836528.786   \n",
       "3678  29.30  29.32  28.73  28.86      29.17  -1.0627   528595.80  1527734.333   \n",
       "3679  29.01  29.09  28.50  28.59      28.86  -0.9356   635227.77  1826857.600   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "2863   4006.0993   4034.0091  4052.7970    3988.0018        4053.7529   \n",
       "2864   3998.1365   4003.5604  4027.1064    3984.3776        4006.0993   \n",
       "2865   4018.8571   3989.0466  4032.9859    3982.3182        3998.1365   \n",
       "2866   4040.1704   4007.9361  4045.9331    4006.5432        4018.8571   \n",
       "2867   4015.8211   4027.1231  4031.7533    3964.8087        4040.1704   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "3675   5140.3418   5178.6401  5181.1490    5125.3301        5161.5569   \n",
       "3676   5103.7428   5141.6556  5141.6556    5065.1932        5140.3418   \n",
       "3677   5112.2086   5078.2627  5129.1318    5062.0725        5103.7428   \n",
       "3678   5035.3374   5100.0422  5100.0422    5022.0926        5112.2086   \n",
       "3679   4947.7459   5026.9791  5045.6018    4933.0126        5035.3374   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "2863        -1.1755 -0.517816  0.855492  31.520  31.661080  29.837715   \n",
       "2864        -0.1988 -0.503023  0.864273  31.384  31.274053  29.900790   \n",
       "2865         0.5183 -0.457769  0.889071  31.214  31.049369  29.967382   \n",
       "2866         0.5303 -0.442408  0.896814  31.116  30.899579  30.027631   \n",
       "2867        -0.6027 -0.426916  0.904291  31.106  30.843053  30.094523   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "3675        -0.4110  0.997237 -0.074280  30.392  30.286332  30.883498   \n",
       "3676        -0.7120  0.995812 -0.091423  30.094  30.024221  30.751736   \n",
       "3677         0.1659  0.994092 -0.108540  29.780  29.816147  30.622999   \n",
       "3678        -1.5037  0.992078 -0.125624  29.640  29.644098  30.496999   \n",
       "3679        -1.7395  0.984277 -0.176633  29.442  29.432732  30.355380   \n",
       "\n",
       "          ema50  \n",
       "2863  28.113687  \n",
       "2864  28.207268  \n",
       "2865  28.301101  \n",
       "2866  28.391254  \n",
       "2867  28.482969  \n",
       "...         ...  \n",
       "3675  30.591909  \n",
       "3676  30.549089  \n",
       "3677  30.504027  \n",
       "3678  30.456810  \n",
       "3679  30.400072  \n",
       "\n",
       "[817 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "test_df instances :  409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>index_open</th>\n",
       "      <th>index_high</th>\n",
       "      <th>index_low</th>\n",
       "      <th>index_close</th>\n",
       "      <th>index_pre_close</th>\n",
       "      <th>index_pct_chg</th>\n",
       "      <th>Year sin</th>\n",
       "      <th>Year cos</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>28.70</td>\n",
       "      <td>28.80</td>\n",
       "      <td>28.13</td>\n",
       "      <td>28.29</td>\n",
       "      <td>28.59</td>\n",
       "      <td>-1.0493</td>\n",
       "      <td>669694.80</td>\n",
       "      <td>1899238.929</td>\n",
       "      <td>4939.6438</td>\n",
       "      <td>4949.8074</td>\n",
       "      <td>4994.5404</td>\n",
       "      <td>4924.1979</td>\n",
       "      <td>4947.7459</td>\n",
       "      <td>-0.1638</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>-0.193539</td>\n",
       "      <td>29.182</td>\n",
       "      <td>29.188488</td>\n",
       "      <td>30.197725</td>\n",
       "      <td>30.333403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>28.40</td>\n",
       "      <td>28.85</td>\n",
       "      <td>28.31</td>\n",
       "      <td>28.76</td>\n",
       "      <td>28.29</td>\n",
       "      <td>1.6614</td>\n",
       "      <td>544164.59</td>\n",
       "      <td>1559705.230</td>\n",
       "      <td>4980.6279</td>\n",
       "      <td>4945.6857</td>\n",
       "      <td>4987.1191</td>\n",
       "      <td>4940.2686</td>\n",
       "      <td>4939.6438</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.977618</td>\n",
       "      <td>-0.210387</td>\n",
       "      <td>28.962</td>\n",
       "      <td>28.925659</td>\n",
       "      <td>30.026513</td>\n",
       "      <td>30.257583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>28.65</td>\n",
       "      <td>28.89</td>\n",
       "      <td>28.29</td>\n",
       "      <td>28.63</td>\n",
       "      <td>28.76</td>\n",
       "      <td>-0.4520</td>\n",
       "      <td>503527.28</td>\n",
       "      <td>1436503.927</td>\n",
       "      <td>4948.9741</td>\n",
       "      <td>4969.9099</td>\n",
       "      <td>4969.9099</td>\n",
       "      <td>4900.3033</td>\n",
       "      <td>4980.6279</td>\n",
       "      <td>-0.6355</td>\n",
       "      <td>0.973855</td>\n",
       "      <td>-0.227172</td>\n",
       "      <td>28.812</td>\n",
       "      <td>28.833772</td>\n",
       "      <td>29.895417</td>\n",
       "      <td>30.194541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>28.79</td>\n",
       "      <td>28.87</td>\n",
       "      <td>28.51</td>\n",
       "      <td>28.87</td>\n",
       "      <td>28.63</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>395753.23</td>\n",
       "      <td>1137450.227</td>\n",
       "      <td>4966.1811</td>\n",
       "      <td>4966.8999</td>\n",
       "      <td>4979.1731</td>\n",
       "      <td>4917.9596</td>\n",
       "      <td>4948.9741</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.969803</td>\n",
       "      <td>-0.243891</td>\n",
       "      <td>28.710</td>\n",
       "      <td>28.819182</td>\n",
       "      <td>29.790139</td>\n",
       "      <td>30.139461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>28.83</td>\n",
       "      <td>29.07</td>\n",
       "      <td>28.45</td>\n",
       "      <td>29.00</td>\n",
       "      <td>28.87</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>619893.79</td>\n",
       "      <td>1786257.528</td>\n",
       "      <td>5087.0165</td>\n",
       "      <td>4966.4090</td>\n",
       "      <td>5088.2106</td>\n",
       "      <td>4940.7473</td>\n",
       "      <td>4966.1811</td>\n",
       "      <td>2.4332</td>\n",
       "      <td>0.955930</td>\n",
       "      <td>-0.293594</td>\n",
       "      <td>28.674</td>\n",
       "      <td>28.822788</td>\n",
       "      <td>29.698697</td>\n",
       "      <td>30.088109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>19.37</td>\n",
       "      <td>20.63</td>\n",
       "      <td>19.26</td>\n",
       "      <td>20.46</td>\n",
       "      <td>19.38</td>\n",
       "      <td>5.5728</td>\n",
       "      <td>2177339.59</td>\n",
       "      <td>4380717.630</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>3961.9919</td>\n",
       "      <td>4003.3178</td>\n",
       "      <td>3944.4396</td>\n",
       "      <td>3959.1798</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.383078</td>\n",
       "      <td>0.923716</td>\n",
       "      <td>18.906</td>\n",
       "      <td>18.858026</td>\n",
       "      <td>17.515825</td>\n",
       "      <td>16.816367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>20.11</td>\n",
       "      <td>20.25</td>\n",
       "      <td>19.36</td>\n",
       "      <td>19.45</td>\n",
       "      <td>20.46</td>\n",
       "      <td>-4.9365</td>\n",
       "      <td>1159201.79</td>\n",
       "      <td>2288939.781</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>3976.1722</td>\n",
       "      <td>3983.4332</td>\n",
       "      <td>3950.3203</td>\n",
       "      <td>3998.2442</td>\n",
       "      <td>-1.1205</td>\n",
       "      <td>-0.334918</td>\n",
       "      <td>0.942247</td>\n",
       "      <td>19.148</td>\n",
       "      <td>19.275351</td>\n",
       "      <td>17.762889</td>\n",
       "      <td>16.945529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>19.45</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.16</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>752615.03</td>\n",
       "      <td>1460346.558</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>3953.5482</td>\n",
       "      <td>3964.3957</td>\n",
       "      <td>3939.9795</td>\n",
       "      <td>3953.4433</td>\n",
       "      <td>-0.1963</td>\n",
       "      <td>-0.318660</td>\n",
       "      <td>0.947869</td>\n",
       "      <td>19.278</td>\n",
       "      <td>19.333567</td>\n",
       "      <td>17.923566</td>\n",
       "      <td>17.043744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>19.40</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.05</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.48</td>\n",
       "      <td>-1.1807</td>\n",
       "      <td>790763.58</td>\n",
       "      <td>1524377.946</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>3952.7885</td>\n",
       "      <td>3972.7381</td>\n",
       "      <td>3935.7668</td>\n",
       "      <td>3945.6813</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>19.376</td>\n",
       "      <td>19.355711</td>\n",
       "      <td>18.064179</td>\n",
       "      <td>17.136146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>18.88</td>\n",
       "      <td>19.24</td>\n",
       "      <td>18.50</td>\n",
       "      <td>19.12</td>\n",
       "      <td>19.25</td>\n",
       "      <td>-0.6753</td>\n",
       "      <td>915828.17</td>\n",
       "      <td>1723767.162</td>\n",
       "      <td>3951.9885</td>\n",
       "      <td>3954.6720</td>\n",
       "      <td>3963.5002</td>\n",
       "      <td>3926.4997</td>\n",
       "      <td>3954.8857</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.285866</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>19.442</td>\n",
       "      <td>19.197141</td>\n",
       "      <td>18.141876</td>\n",
       "      <td>17.204533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open   high    low  close  pre_close  pct_chg         vol       amount  \\\n",
       "3680  28.70  28.80  28.13  28.29      28.59  -1.0493   669694.80  1899238.929   \n",
       "3681  28.40  28.85  28.31  28.76      28.29   1.6614   544164.59  1559705.230   \n",
       "3682  28.65  28.89  28.29  28.63      28.76  -0.4520   503527.28  1436503.927   \n",
       "3683  28.79  28.87  28.51  28.87      28.63   0.8383   395753.23  1137450.227   \n",
       "3684  28.83  29.07  28.45  29.00      28.87   0.4503   619893.79  1786257.528   \n",
       "...     ...    ...    ...    ...        ...      ...         ...          ...   \n",
       "4084  19.37  20.63  19.26  20.46      19.38   5.5728  2177339.59  4380717.630   \n",
       "4085  20.11  20.25  19.36  19.45      20.46  -4.9365  1159201.79  2288939.781   \n",
       "4086  19.45  19.60  19.16  19.48      19.45   0.1542   752615.03  1460346.558   \n",
       "4087  19.40  19.60  19.05  19.25      19.48  -1.1807   790763.58  1524377.946   \n",
       "4088  18.88  19.24  18.50  19.12      19.25  -0.6753   915828.17  1723767.162   \n",
       "\n",
       "      index_open  index_high  index_low  index_close  index_pre_close  \\\n",
       "3680   4939.6438   4949.8074  4994.5404    4924.1979        4947.7459   \n",
       "3681   4980.6279   4945.6857  4987.1191    4940.2686        4939.6438   \n",
       "3682   4948.9741   4969.9099  4969.9099    4900.3033        4980.6279   \n",
       "3683   4966.1811   4966.8999  4979.1731    4917.9596        4948.9741   \n",
       "3684   5087.0165   4966.4090  5088.2106    4940.7473        4966.1811   \n",
       "...          ...         ...        ...          ...              ...   \n",
       "4084   3998.2442   3961.9919  4003.3178    3944.4396        3959.1798   \n",
       "4085   3953.4433   3976.1722  3983.4332    3950.3203        3998.2442   \n",
       "4086   3945.6813   3953.5482  3964.3957    3939.9795        3953.4433   \n",
       "4087   3954.8857   3952.7885  3972.7381    3935.7668        3945.6813   \n",
       "4088   3951.9885   3954.6720  3963.5002    3926.4997        3954.8857   \n",
       "\n",
       "      index_pct_chg  Year sin  Year cos    sma5       ema5      ema20  \\\n",
       "3680        -0.1638  0.981093 -0.193539  29.182  29.188488  30.197725   \n",
       "3681         0.8297  0.977618 -0.210387  28.962  28.925659  30.026513   \n",
       "3682        -0.6355  0.973855 -0.227172  28.812  28.833772  29.895417   \n",
       "3683         0.3477  0.969803 -0.243891  28.710  28.819182  29.790139   \n",
       "3684         2.4332  0.955930 -0.293594  28.674  28.822788  29.698697   \n",
       "...             ...       ...       ...     ...        ...        ...   \n",
       "4084         0.9867 -0.383078  0.923716  18.906  18.858026  17.515825   \n",
       "4085        -1.1205 -0.334918  0.942247  19.148  19.275351  17.762889   \n",
       "4086        -0.1963 -0.318660  0.947869  19.278  19.333567  17.923566   \n",
       "4087         0.2333 -0.302308  0.953210  19.376  19.355711  18.064179   \n",
       "4088        -0.0733 -0.285866  0.958270  19.442  19.197141  18.141876   \n",
       "\n",
       "          ema50  \n",
       "3680  30.333403  \n",
       "3681  30.257583  \n",
       "3682  30.194541  \n",
       "3683  30.139461  \n",
       "3684  30.088109  \n",
       "...         ...  \n",
       "4084  16.816367  \n",
       "4085  16.945529  \n",
       "4086  17.043744  \n",
       "4087  17.136146  \n",
       "4088  17.204533  \n",
       "\n",
       "[409 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 7\n",
      "Input indices: [0 1 2 3 4 5]\n",
      "Label indices: [6]\n",
      "Label column name(s): ['open']\n",
      "(TensorSpec(shape=(None, 6, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))\n",
      "Inputs shape (batch, time, features): (8, 6, 20)\n",
      "Labels shape (batch, time, features): (8, 1, 1)\n",
      "Total window size: 30\n",
      "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n",
      "Label indices: [29]\n",
      "Label column name(s): ['open']\n",
      "(TensorSpec(shape=(None, 29, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))\n",
      "Inputs shape (batch, time, features): (8, 29, 20)\n",
      "Labels shape (batch, time, features): (8, 1, 1)\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.2164 - mean_absolute_percentage_error: 27.0581 - val_loss: 0.1958 - val_mean_absolute_percentage_error: 10.3082 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0857 - mean_absolute_percentage_error: 15.7497 - val_loss: 0.1019 - val_mean_absolute_percentage_error: 6.8995 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0539 - mean_absolute_percentage_error: 14.0753 - val_loss: 0.0693 - val_mean_absolute_percentage_error: 5.9049 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0391 - mean_absolute_percentage_error: 12.5444 - val_loss: 0.0449 - val_mean_absolute_percentage_error: 3.7677 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0306 - mean_absolute_percentage_error: 14.0816 - val_loss: 0.0340 - val_mean_absolute_percentage_error: 3.2463 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0243 - mean_absolute_percentage_error: 13.3461 - val_loss: 0.0401 - val_mean_absolute_percentage_error: 5.8292 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 8ms/step - loss: 0.0223 - mean_absolute_percentage_error: 13.4681 - val_loss: 0.0634 - val_mean_absolute_percentage_error: 7.1849 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0209 - mean_absolute_percentage_error: 14.1771 - val_loss: 0.0981 - val_mean_absolute_percentage_error: 11.7391 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0172 - mean_absolute_percentage_error: 12.1350 - val_loss: 0.0349 - val_mean_absolute_percentage_error: 4.3394 - lr: 9.5123e-04\n",
      "Learning rate of the model:  0.0009512295\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0349 - mean_absolute_percentage_error: 4.3394\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0236 - mean_absolute_percentage_error: 11.4652\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.2022 - mean_absolute_percentage_error: 29.8079 - val_loss: 0.2620 - val_mean_absolute_percentage_error: 17.6695 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0757 - mean_absolute_percentage_error: 16.4307 - val_loss: 0.0836 - val_mean_absolute_percentage_error: 6.4793 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0485 - mean_absolute_percentage_error: 14.4657 - val_loss: 0.1257 - val_mean_absolute_percentage_error: 12.8488 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 3s 8ms/step - loss: 0.0343 - mean_absolute_percentage_error: 14.5898 - val_loss: 0.0394 - val_mean_absolute_percentage_error: 3.9051 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0282 - mean_absolute_percentage_error: 14.4553 - val_loss: 0.0317 - val_mean_absolute_percentage_error: 3.8109 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 13ms/step - loss: 0.0217 - mean_absolute_percentage_error: 13.5858 - val_loss: 0.0265 - val_mean_absolute_percentage_error: 3.1620 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0194 - mean_absolute_percentage_error: 13.2244 - val_loss: 0.0313 - val_mean_absolute_percentage_error: 4.5098 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 13ms/step - loss: 0.0156 - mean_absolute_percentage_error: 12.2896 - val_loss: 0.0214 - val_mean_absolute_percentage_error: 3.3557 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 12ms/step - loss: 0.0138 - mean_absolute_percentage_error: 11.9856 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 2.1243 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 12ms/step - loss: 0.0136 - mean_absolute_percentage_error: 12.0122 - val_loss: 0.0232 - val_mean_absolute_percentage_error: 3.8697 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 12.1715 - val_loss: 0.0235 - val_mean_absolute_percentage_error: 4.1090 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 10.3502 - val_loss: 0.0130 - val_mean_absolute_percentage_error: 2.1538 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 10.4674 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 2.0915 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 10.7591 - val_loss: 0.0196 - val_mean_absolute_percentage_error: 4.4513 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0100 - mean_absolute_percentage_error: 10.4620 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 2.7689 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 10.5442 - val_loss: 0.0125 - val_mean_absolute_percentage_error: 2.6548 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.4772 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 2.5858 - lr: 6.3763e-04\n",
      "Learning rate of the model:  0.00063762837\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0129 - mean_absolute_percentage_error: 2.5858\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0092 - mean_absolute_percentage_error: 5.5295\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1524 - mean_absolute_percentage_error: 26.2694 - val_loss: 0.1221 - val_mean_absolute_percentage_error: 6.8839 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0706 - mean_absolute_percentage_error: 18.0789 - val_loss: 0.0709 - val_mean_absolute_percentage_error: 4.8013 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0452 - mean_absolute_percentage_error: 15.6775 - val_loss: 0.0540 - val_mean_absolute_percentage_error: 4.5886 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0329 - mean_absolute_percentage_error: 15.3272 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 3.7089 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0277 - mean_absolute_percentage_error: 15.7880 - val_loss: 0.0291 - val_mean_absolute_percentage_error: 3.4000 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0205 - mean_absolute_percentage_error: 13.8283 - val_loss: 0.0279 - val_mean_absolute_percentage_error: 3.9371 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0178 - mean_absolute_percentage_error: 13.1606 - val_loss: 0.0227 - val_mean_absolute_percentage_error: 3.3817 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0167 - mean_absolute_percentage_error: 14.4807 - val_loss: 0.0196 - val_mean_absolute_percentage_error: 3.2048 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0151 - mean_absolute_percentage_error: 12.6914 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 2.9609 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0142 - mean_absolute_percentage_error: 12.7840 - val_loss: 0.0159 - val_mean_absolute_percentage_error: 2.5294 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0129 - mean_absolute_percentage_error: 11.1600 - val_loss: 0.0286 - val_mean_absolute_percentage_error: 4.9639 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0108 - mean_absolute_percentage_error: 10.8610 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 4.0725 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0104 - mean_absolute_percentage_error: 10.7059 - val_loss: 0.0142 - val_mean_absolute_percentage_error: 2.9038 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 10.0266 - val_loss: 0.0110 - val_mean_absolute_percentage_error: 2.3581 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 10.5997 - val_loss: 0.0367 - val_mean_absolute_percentage_error: 7.4920 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 10.6646 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 2.8008 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.4476 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 2.3165 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.8612 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 2.0148 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.3638 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 2.1212 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 9.8437 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 2.4786 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.1685 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 2.0251 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 8.9797 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 2.7888 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.4313 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 2.0279 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 8.9271 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 1.9616 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.1968 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 2.7720 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 8.5998 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 2.0560 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 8.5375 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 2.8459 - lr: 3.8674e-04\n",
      "Learning rate of the model:  0.00038674125\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0113 - mean_absolute_percentage_error: 2.8459\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_absolute_percentage_error: 5.0039\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1610 - mean_absolute_percentage_error: 30.7175 - val_loss: 0.1932 - val_mean_absolute_percentage_error: 10.8232 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0725 - mean_absolute_percentage_error: 16.6081 - val_loss: 0.1058 - val_mean_absolute_percentage_error: 7.8549 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0476 - mean_absolute_percentage_error: 15.2072 - val_loss: 0.0770 - val_mean_absolute_percentage_error: 7.1117 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0328 - mean_absolute_percentage_error: 13.9449 - val_loss: 0.0344 - val_mean_absolute_percentage_error: 3.1241 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0265 - mean_absolute_percentage_error: 15.0294 - val_loss: 0.0360 - val_mean_absolute_percentage_error: 4.3991 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0210 - mean_absolute_percentage_error: 13.5063 - val_loss: 0.0378 - val_mean_absolute_percentage_error: 6.2130 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0184 - mean_absolute_percentage_error: 12.7192 - val_loss: 0.0257 - val_mean_absolute_percentage_error: 4.2267 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0170 - mean_absolute_percentage_error: 13.5173 - val_loss: 0.0377 - val_mean_absolute_percentage_error: 6.7806 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0140 - mean_absolute_percentage_error: 11.7885 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 3.3901 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 11.4491 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 5.8254 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0121 - mean_absolute_percentage_error: 11.0038 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 2.3969 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0113 - mean_absolute_percentage_error: 11.4816 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 2.5622 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0113 - mean_absolute_percentage_error: 10.5350 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 4.0637 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0104 - mean_absolute_percentage_error: 10.3310 - val_loss: 0.0169 - val_mean_absolute_percentage_error: 4.0503 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0100 - mean_absolute_percentage_error: 10.8215 - val_loss: 0.0228 - val_mean_absolute_percentage_error: 5.0831 - lr: 7.0469e-04\n",
      "Learning rate of the model:  0.00070468825\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0228 - mean_absolute_percentage_error: 5.0831\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0078 - mean_absolute_percentage_error: 4.2191\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1835 - mean_absolute_percentage_error: 32.0967 - val_loss: 0.1655 - val_mean_absolute_percentage_error: 9.9481 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0782 - mean_absolute_percentage_error: 18.1684 - val_loss: 0.1232 - val_mean_absolute_percentage_error: 10.7143 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0504 - mean_absolute_percentage_error: 14.9281 - val_loss: 0.2682 - val_mean_absolute_percentage_error: 22.0008 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0374 - mean_absolute_percentage_error: 15.0268 - val_loss: 0.0407 - val_mean_absolute_percentage_error: 3.8357 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0284 - mean_absolute_percentage_error: 13.4080 - val_loss: 0.0945 - val_mean_absolute_percentage_error: 12.1638 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0236 - mean_absolute_percentage_error: 13.9080 - val_loss: 0.0291 - val_mean_absolute_percentage_error: 3.8695 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0194 - mean_absolute_percentage_error: 11.9316 - val_loss: 0.0936 - val_mean_absolute_percentage_error: 12.0637 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0177 - mean_absolute_percentage_error: 11.2577 - val_loss: 0.0436 - val_mean_absolute_percentage_error: 8.0193 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0163 - mean_absolute_percentage_error: 11.6511 - val_loss: 0.0189 - val_mean_absolute_percentage_error: 3.3286 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0139 - mean_absolute_percentage_error: 11.6245 - val_loss: 0.0386 - val_mean_absolute_percentage_error: 7.2133 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0138 - mean_absolute_percentage_error: 10.3419 - val_loss: 0.0220 - val_mean_absolute_percentage_error: 3.6520 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 11.5076 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 2.0439 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0114 - mean_absolute_percentage_error: 10.2300 - val_loss: 0.0231 - val_mean_absolute_percentage_error: 5.0453 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0114 - mean_absolute_percentage_error: 10.5917 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 2.6927 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0104 - mean_absolute_percentage_error: 10.4870 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 2.6114 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0102 - mean_absolute_percentage_error: 10.8251 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 2.3269 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 9.5880 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 4.2081 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 9.9323 - val_loss: 0.0152 - val_mean_absolute_percentage_error: 2.7822 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 9.5393 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 2.5372 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.6069 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 2.4591 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 9.6583 - val_loss: 0.0381 - val_mean_absolute_percentage_error: 7.9593 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 9.2109 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 2.1326 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 9.9693 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 3.9992 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 9.5737 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 2.9386 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 9.6785 - val_loss: 0.0165 - val_mean_absolute_percentage_error: 4.1760 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 9.1429 - val_loss: 0.0144 - val_mean_absolute_percentage_error: 3.8908 - lr: 4.0657e-04\n",
      "Learning rate of the model:  0.0004065699\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0144 - mean_absolute_percentage_error: 3.8908\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0169 - mean_absolute_percentage_error: 11.3647\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 13ms/step - loss: 0.1730 - mean_absolute_percentage_error: 36.0675 - val_loss: 0.1643 - val_mean_absolute_percentage_error: 8.2141 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0720 - mean_absolute_percentage_error: 18.9564 - val_loss: 0.0733 - val_mean_absolute_percentage_error: 5.2044 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0448 - mean_absolute_percentage_error: 14.8560 - val_loss: 0.0491 - val_mean_absolute_percentage_error: 4.3572 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0328 - mean_absolute_percentage_error: 16.7788 - val_loss: 0.0617 - val_mean_absolute_percentage_error: 6.4902 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0250 - mean_absolute_percentage_error: 14.7047 - val_loss: 0.0251 - val_mean_absolute_percentage_error: 3.0690 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0213 - mean_absolute_percentage_error: 15.6252 - val_loss: 0.0251 - val_mean_absolute_percentage_error: 3.2505 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0178 - mean_absolute_percentage_error: 13.0478 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 3.5393 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0174 - mean_absolute_percentage_error: 13.3221 - val_loss: 0.0842 - val_mean_absolute_percentage_error: 11.5159 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0161 - mean_absolute_percentage_error: 14.1409 - val_loss: 0.0192 - val_mean_absolute_percentage_error: 2.8690 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 12.3183 - val_loss: 0.0176 - val_mean_absolute_percentage_error: 3.2364 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 11.2598 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 2.7165 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0113 - mean_absolute_percentage_error: 12.1521 - val_loss: 0.0204 - val_mean_absolute_percentage_error: 4.7215 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 10.9815 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 3.3319 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 10.7828 - val_loss: 0.0142 - val_mean_absolute_percentage_error: 2.5978 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 11.8689 - val_loss: 0.0197 - val_mean_absolute_percentage_error: 4.7215 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 11.3998 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 2.5824 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.5918 - val_loss: 0.0276 - val_mean_absolute_percentage_error: 5.0500 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.3281 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 3.1684 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 9.8191 - val_loss: 0.0142 - val_mean_absolute_percentage_error: 3.1630 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0076 - mean_absolute_percentage_error: 9.7812 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 2.1443 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 9.1608 - val_loss: 0.0155 - val_mean_absolute_percentage_error: 3.2140 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 9.5377 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 2.6219 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 9.3118 - val_loss: 0.0205 - val_mean_absolute_percentage_error: 4.4552 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 8.1667 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 3.7752 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0140 - mean_absolute_percentage_error: 3.7752\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0156 - mean_absolute_percentage_error: 10.1000\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 7s 13ms/step - loss: 0.1595 - mean_absolute_percentage_error: 30.6182 - val_loss: 0.1729 - val_mean_absolute_percentage_error: 10.0591 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0725 - mean_absolute_percentage_error: 15.3191 - val_loss: 0.1051 - val_mean_absolute_percentage_error: 8.8513 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0469 - mean_absolute_percentage_error: 14.7562 - val_loss: 0.1428 - val_mean_absolute_percentage_error: 14.1712 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0356 - mean_absolute_percentage_error: 14.5675 - val_loss: 0.0983 - val_mean_absolute_percentage_error: 11.7728 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0256 - mean_absolute_percentage_error: 13.1927 - val_loss: 0.0325 - val_mean_absolute_percentage_error: 4.0136 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0214 - mean_absolute_percentage_error: 13.7491 - val_loss: 0.0310 - val_mean_absolute_percentage_error: 3.8810 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0188 - mean_absolute_percentage_error: 12.5242 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 8.7065 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0201 - mean_absolute_percentage_error: 14.6797 - val_loss: 0.0248 - val_mean_absolute_percentage_error: 4.4919 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0145 - mean_absolute_percentage_error: 12.0811 - val_loss: 0.0159 - val_mean_absolute_percentage_error: 2.4007 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 11.2678 - val_loss: 0.0295 - val_mean_absolute_percentage_error: 6.0399 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0121 - mean_absolute_percentage_error: 10.0039 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 2.8156 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 10.3562 - val_loss: 0.0368 - val_mean_absolute_percentage_error: 6.1853 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 10.3733 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 2.7411 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0100 - mean_absolute_percentage_error: 9.8799 - val_loss: 0.0501 - val_mean_absolute_percentage_error: 8.9623 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 10.0171 - val_loss: 0.0277 - val_mean_absolute_percentage_error: 6.0835 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 10.4109 - val_loss: 0.0504 - val_mean_absolute_percentage_error: 9.2732 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 9.9430 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 2.2100 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 9.8064 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 2.5285 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 11.7046 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 2.2582 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 8.7271 - val_loss: 0.0224 - val_mean_absolute_percentage_error: 5.4632 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 8.6769 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 2.0490 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 8.7383 - val_loss: 0.0202 - val_mean_absolute_percentage_error: 5.2569 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 8.9970 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 1.9523 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 8.5062 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 3.7800 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 8.0246 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 3.3090 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 7.7640 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 2.1133 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 8.1001 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 2.1847 - lr: 3.8674e-04\n",
      "Learning rate of the model:  0.00038674125\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0081 - mean_absolute_percentage_error: 2.1847\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0057 - mean_absolute_percentage_error: 4.3061\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 13ms/step - loss: 0.1599 - mean_absolute_percentage_error: 25.1380 - val_loss: 0.1825 - val_mean_absolute_percentage_error: 9.6688 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0706 - mean_absolute_percentage_error: 17.3678 - val_loss: 0.1676 - val_mean_absolute_percentage_error: 13.7701 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0436 - mean_absolute_percentage_error: 16.1312 - val_loss: 0.0483 - val_mean_absolute_percentage_error: 4.2596 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0303 - mean_absolute_percentage_error: 13.6776 - val_loss: 0.0343 - val_mean_absolute_percentage_error: 3.9431 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0241 - mean_absolute_percentage_error: 13.9508 - val_loss: 0.0335 - val_mean_absolute_percentage_error: 5.5701 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0197 - mean_absolute_percentage_error: 14.4146 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 2.3201 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0174 - mean_absolute_percentage_error: 14.1048 - val_loss: 0.0186 - val_mean_absolute_percentage_error: 2.8181 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0173 - mean_absolute_percentage_error: 14.6196 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 4.5898 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0145 - mean_absolute_percentage_error: 11.4784 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 3.4163 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0134 - mean_absolute_percentage_error: 12.1742 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 2.2634 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0128 - mean_absolute_percentage_error: 11.5155 - val_loss: 0.0189 - val_mean_absolute_percentage_error: 2.6882 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 11.0770 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 4.1996 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0106 - mean_absolute_percentage_error: 10.3270 - val_loss: 0.0214 - val_mean_absolute_percentage_error: 3.2983 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 10.6603 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 1.9373 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 12ms/step - loss: 0.0105 - mean_absolute_percentage_error: 10.0556 - val_loss: 0.0264 - val_mean_absolute_percentage_error: 5.4024 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0098 - mean_absolute_percentage_error: 9.6176 - val_loss: 0.0218 - val_mean_absolute_percentage_error: 4.6598 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 9.9261 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 2.3305 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 9.0995 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 5.4422 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0082 - mean_absolute_percentage_error: 8.7222 - val_loss: 0.0280 - val_mean_absolute_percentage_error: 6.4429 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 9.7699 - val_loss: 0.0132 - val_mean_absolute_percentage_error: 3.5709 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.8943 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 1.7032 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 9.4754 - val_loss: 0.0168 - val_mean_absolute_percentage_error: 4.2863 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 8.8111 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 3.5191 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 8.6006 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 2.4035 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 8.6597 - val_loss: 0.0192 - val_mean_absolute_percentage_error: 4.9889 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.0192 - mean_absolute_percentage_error: 4.9889\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_absolute_percentage_error: 7.0865\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1687 - mean_absolute_percentage_error: 30.2126 - val_loss: 0.1393 - val_mean_absolute_percentage_error: 7.9621 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0730 - mean_absolute_percentage_error: 16.0339 - val_loss: 0.0850 - val_mean_absolute_percentage_error: 5.5026 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0500 - mean_absolute_percentage_error: 15.6180 - val_loss: 0.0489 - val_mean_absolute_percentage_error: 3.9867 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0333 - mean_absolute_percentage_error: 14.9082 - val_loss: 0.0385 - val_mean_absolute_percentage_error: 3.9674 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0258 - mean_absolute_percentage_error: 14.7222 - val_loss: 0.0301 - val_mean_absolute_percentage_error: 3.6691 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0223 - mean_absolute_percentage_error: 14.5590 - val_loss: 0.0267 - val_mean_absolute_percentage_error: 3.7148 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0179 - mean_absolute_percentage_error: 13.7371 - val_loss: 0.0202 - val_mean_absolute_percentage_error: 2.7560 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0159 - mean_absolute_percentage_error: 13.8993 - val_loss: 0.0286 - val_mean_absolute_percentage_error: 4.7190 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0143 - mean_absolute_percentage_error: 12.8934 - val_loss: 0.0339 - val_mean_absolute_percentage_error: 5.8656 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0126 - mean_absolute_percentage_error: 12.1457 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 5.1830 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 12.5452 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 2.6247 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 12.1151 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 3.2640 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0104 - mean_absolute_percentage_error: 12.1265 - val_loss: 0.0555 - val_mean_absolute_percentage_error: 9.6378 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 10.8979 - val_loss: 0.0208 - val_mean_absolute_percentage_error: 4.7333 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.5080 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 4.9201 - lr: 7.0469e-04\n",
      "Learning rate of the model:  0.00070468825\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0219 - mean_absolute_percentage_error: 4.9201\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0092 - mean_absolute_percentage_error: 6.4693\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 13ms/step - loss: 0.1617 - mean_absolute_percentage_error: 30.5298 - val_loss: 0.1299 - val_mean_absolute_percentage_error: 7.9158 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0656 - mean_absolute_percentage_error: 17.1909 - val_loss: 0.0718 - val_mean_absolute_percentage_error: 5.6111 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0406 - mean_absolute_percentage_error: 15.6352 - val_loss: 0.0542 - val_mean_absolute_percentage_error: 4.7218 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0309 - mean_absolute_percentage_error: 16.3624 - val_loss: 0.0426 - val_mean_absolute_percentage_error: 5.0512 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0232 - mean_absolute_percentage_error: 13.8804 - val_loss: 0.0302 - val_mean_absolute_percentage_error: 3.8789 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0186 - mean_absolute_percentage_error: 13.2400 - val_loss: 0.1562 - val_mean_absolute_percentage_error: 15.9571 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0178 - mean_absolute_percentage_error: 15.8551 - val_loss: 0.0366 - val_mean_absolute_percentage_error: 6.5375 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0153 - mean_absolute_percentage_error: 13.4327 - val_loss: 0.0188 - val_mean_absolute_percentage_error: 3.3436 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0146 - mean_absolute_percentage_error: 13.7974 - val_loss: 0.0168 - val_mean_absolute_percentage_error: 2.7462 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0129 - mean_absolute_percentage_error: 12.0702 - val_loss: 0.0143 - val_mean_absolute_percentage_error: 2.4827 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 12.8383 - val_loss: 0.0180 - val_mean_absolute_percentage_error: 4.1042 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0109 - mean_absolute_percentage_error: 11.4611 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 4.2046 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0105 - mean_absolute_percentage_error: 10.7314 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 3.3229 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0098 - mean_absolute_percentage_error: 11.5007 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 2.4164 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 11.1219 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 2.4393 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 11.6106 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 5.4587 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 9.8202 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 1.9807 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.0659 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 2.8318 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.4246 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 2.0991 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.9249 - val_loss: 0.0169 - val_mean_absolute_percentage_error: 4.2186 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 9.5944 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 1.9447 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 8.8768 - val_loss: 0.0157 - val_mean_absolute_percentage_error: 4.1018 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 9.2214 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 2.6133 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.2873 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 2.5460 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 8.2288 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 4.0349 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0154 - mean_absolute_percentage_error: 4.0349\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0066 - mean_absolute_percentage_error: 4.9674\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2612 - mean_absolute_percentage_error: 252.8881 - val_loss: 0.3833 - val_mean_absolute_percentage_error: 36.2600 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.1147 - mean_absolute_percentage_error: 104.2541 - val_loss: 0.3198 - val_mean_absolute_percentage_error: 35.1290 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0817 - mean_absolute_percentage_error: 89.4891 - val_loss: 0.2238 - val_mean_absolute_percentage_error: 28.2499 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0648 - mean_absolute_percentage_error: 90.0219 - val_loss: 0.1371 - val_mean_absolute_percentage_error: 19.9915 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0546 - mean_absolute_percentage_error: 77.2294 - val_loss: 0.0773 - val_mean_absolute_percentage_error: 11.8460 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0489 - mean_absolute_percentage_error: 73.3847 - val_loss: 0.0569 - val_mean_absolute_percentage_error: 9.9220 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0441 - mean_absolute_percentage_error: 77.1418 - val_loss: 0.0577 - val_mean_absolute_percentage_error: 11.3274 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0423 - mean_absolute_percentage_error: 58.6096 - val_loss: 0.0452 - val_mean_absolute_percentage_error: 8.6901 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0350 - mean_absolute_percentage_error: 52.9512 - val_loss: 0.0486 - val_mean_absolute_percentage_error: 10.6152 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0367 - mean_absolute_percentage_error: 41.8403 - val_loss: 0.0481 - val_mean_absolute_percentage_error: 10.7901 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0338 - mean_absolute_percentage_error: 61.4025 - val_loss: 0.0536 - val_mean_absolute_percentage_error: 12.2571 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0285 - mean_absolute_percentage_error: 40.4671 - val_loss: 0.0344 - val_mean_absolute_percentage_error: 8.0981 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0289 - mean_absolute_percentage_error: 45.6896 - val_loss: 0.0562 - val_mean_absolute_percentage_error: 13.8927 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0290 - mean_absolute_percentage_error: 57.7236 - val_loss: 0.0479 - val_mean_absolute_percentage_error: 10.6587 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0297 - mean_absolute_percentage_error: 54.8356 - val_loss: 0.0565 - val_mean_absolute_percentage_error: 13.1659 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0267 - mean_absolute_percentage_error: 46.4106 - val_loss: 0.0279 - val_mean_absolute_percentage_error: 7.0204 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0264 - mean_absolute_percentage_error: 43.5818 - val_loss: 0.0317 - val_mean_absolute_percentage_error: 8.1634 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0239 - mean_absolute_percentage_error: 43.7313 - val_loss: 0.0346 - val_mean_absolute_percentage_error: 8.4207 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0241 - mean_absolute_percentage_error: 39.2416 - val_loss: 0.0460 - val_mean_absolute_percentage_error: 11.8166 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0235 - mean_absolute_percentage_error: 42.7991 - val_loss: 0.0254 - val_mean_absolute_percentage_error: 7.4099 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0235 - mean_absolute_percentage_error: 51.0510 - val_loss: 0.0310 - val_mean_absolute_percentage_error: 7.9470 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0222 - mean_absolute_percentage_error: 49.3757 - val_loss: 0.0453 - val_mean_absolute_percentage_error: 11.9834 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0223 - mean_absolute_percentage_error: 37.0802 - val_loss: 0.0432 - val_mean_absolute_percentage_error: 11.8654 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0216 - mean_absolute_percentage_error: 29.6843 - val_loss: 0.0345 - val_mean_absolute_percentage_error: 9.0444 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.0345 - mean_absolute_percentage_error: 9.0444\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.0633 - mean_absolute_percentage_error: 13.7261\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2260 - mean_absolute_percentage_error: 172.6090 - val_loss: 0.4195 - val_mean_absolute_percentage_error: 39.1539 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.1034 - mean_absolute_percentage_error: 87.1968 - val_loss: 0.2588 - val_mean_absolute_percentage_error: 29.1716 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0769 - mean_absolute_percentage_error: 82.4681 - val_loss: 0.1549 - val_mean_absolute_percentage_error: 20.8343 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0644 - mean_absolute_percentage_error: 93.6006 - val_loss: 0.1220 - val_mean_absolute_percentage_error: 19.0570 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0500 - mean_absolute_percentage_error: 69.7594 - val_loss: 0.0971 - val_mean_absolute_percentage_error: 15.1955 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0454 - mean_absolute_percentage_error: 64.0950 - val_loss: 0.0921 - val_mean_absolute_percentage_error: 16.0321 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0387 - mean_absolute_percentage_error: 64.2664 - val_loss: 0.1273 - val_mean_absolute_percentage_error: 21.1232 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0408 - mean_absolute_percentage_error: 68.2723 - val_loss: 0.0426 - val_mean_absolute_percentage_error: 9.9463 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0402 - mean_absolute_percentage_error: 66.4234 - val_loss: 0.0619 - val_mean_absolute_percentage_error: 13.2969 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0349 - mean_absolute_percentage_error: 80.5457 - val_loss: 0.0686 - val_mean_absolute_percentage_error: 13.7238 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0320 - mean_absolute_percentage_error: 50.0266 - val_loss: 0.0393 - val_mean_absolute_percentage_error: 9.7564 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0290 - mean_absolute_percentage_error: 55.9961 - val_loss: 0.0394 - val_mean_absolute_percentage_error: 9.6049 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0265 - mean_absolute_percentage_error: 54.4570 - val_loss: 0.0408 - val_mean_absolute_percentage_error: 10.0810 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0260 - mean_absolute_percentage_error: 46.8793 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 8.2322 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0256 - mean_absolute_percentage_error: 51.5878 - val_loss: 0.0331 - val_mean_absolute_percentage_error: 8.2380 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0239 - mean_absolute_percentage_error: 58.3744 - val_loss: 0.0322 - val_mean_absolute_percentage_error: 8.7911 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0238 - mean_absolute_percentage_error: 46.4872 - val_loss: 0.0288 - val_mean_absolute_percentage_error: 7.0292 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0212 - mean_absolute_percentage_error: 38.6419 - val_loss: 0.0318 - val_mean_absolute_percentage_error: 8.2061 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0215 - mean_absolute_percentage_error: 39.3666 - val_loss: 0.0439 - val_mean_absolute_percentage_error: 10.6129 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0227 - mean_absolute_percentage_error: 53.0779 - val_loss: 0.0300 - val_mean_absolute_percentage_error: 8.7636 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0218 - mean_absolute_percentage_error: 50.1456 - val_loss: 0.0328 - val_mean_absolute_percentage_error: 8.5763 - lr: 5.2205e-04\n",
      "Learning rate of the model:  0.000522046\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0328 - mean_absolute_percentage_error: 8.5763\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0902 - mean_absolute_percentage_error: 17.2215\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2519 - mean_absolute_percentage_error: 274.4609 - val_loss: 0.4706 - val_mean_absolute_percentage_error: 42.5563 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.1168 - mean_absolute_percentage_error: 85.2193 - val_loss: 0.2722 - val_mean_absolute_percentage_error: 28.6127 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0827 - mean_absolute_percentage_error: 68.5110 - val_loss: 0.2891 - val_mean_absolute_percentage_error: 32.8390 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0636 - mean_absolute_percentage_error: 61.9846 - val_loss: 0.1924 - val_mean_absolute_percentage_error: 26.2499 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0563 - mean_absolute_percentage_error: 61.1468 - val_loss: 0.2180 - val_mean_absolute_percentage_error: 29.0899 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0494 - mean_absolute_percentage_error: 60.0802 - val_loss: 0.1450 - val_mean_absolute_percentage_error: 22.4371 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0421 - mean_absolute_percentage_error: 69.8398 - val_loss: 0.1046 - val_mean_absolute_percentage_error: 17.6844 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0378 - mean_absolute_percentage_error: 71.9422 - val_loss: 0.1217 - val_mean_absolute_percentage_error: 21.0599 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0330 - mean_absolute_percentage_error: 61.4848 - val_loss: 0.0830 - val_mean_absolute_percentage_error: 15.9083 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0327 - mean_absolute_percentage_error: 67.3830 - val_loss: 0.1138 - val_mean_absolute_percentage_error: 21.4172 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0331 - mean_absolute_percentage_error: 57.7238 - val_loss: 0.0496 - val_mean_absolute_percentage_error: 12.4849 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0304 - mean_absolute_percentage_error: 62.6410 - val_loss: 0.1021 - val_mean_absolute_percentage_error: 20.5983 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0297 - mean_absolute_percentage_error: 61.1687 - val_loss: 0.0740 - val_mean_absolute_percentage_error: 16.0526 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0289 - mean_absolute_percentage_error: 50.8990 - val_loss: 0.1368 - val_mean_absolute_percentage_error: 23.5140 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0266 - mean_absolute_percentage_error: 65.8403 - val_loss: 0.0533 - val_mean_absolute_percentage_error: 11.7564 - lr: 7.0469e-04\n",
      "Learning rate of the model:  0.00070468825\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.0533 - mean_absolute_percentage_error: 11.7564\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1154 - mean_absolute_percentage_error: 19.5746\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2286 - mean_absolute_percentage_error: 145.0349 - val_loss: 0.2839 - val_mean_absolute_percentage_error: 29.0885 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.1049 - mean_absolute_percentage_error: 76.8660 - val_loss: 0.1339 - val_mean_absolute_percentage_error: 15.7834 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0768 - mean_absolute_percentage_error: 64.4684 - val_loss: 0.1149 - val_mean_absolute_percentage_error: 15.5195 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0604 - mean_absolute_percentage_error: 58.7540 - val_loss: 0.0845 - val_mean_absolute_percentage_error: 11.9499 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0499 - mean_absolute_percentage_error: 65.3834 - val_loss: 0.0572 - val_mean_absolute_percentage_error: 8.8278 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0473 - mean_absolute_percentage_error: 56.5250 - val_loss: 0.0593 - val_mean_absolute_percentage_error: 9.8387 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0433 - mean_absolute_percentage_error: 52.4414 - val_loss: 0.0484 - val_mean_absolute_percentage_error: 8.5205 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0374 - mean_absolute_percentage_error: 42.1177 - val_loss: 0.0357 - val_mean_absolute_percentage_error: 6.6557 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0331 - mean_absolute_percentage_error: 38.9715 - val_loss: 0.0348 - val_mean_absolute_percentage_error: 7.0378 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0311 - mean_absolute_percentage_error: 43.6707 - val_loss: 0.0270 - val_mean_absolute_percentage_error: 5.5244 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0311 - mean_absolute_percentage_error: 55.8145 - val_loss: 0.0395 - val_mean_absolute_percentage_error: 9.0488 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0281 - mean_absolute_percentage_error: 46.2079 - val_loss: 0.0341 - val_mean_absolute_percentage_error: 7.9373 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0263 - mean_absolute_percentage_error: 45.4102 - val_loss: 0.0329 - val_mean_absolute_percentage_error: 7.5639 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0269 - mean_absolute_percentage_error: 50.1604 - val_loss: 0.0265 - val_mean_absolute_percentage_error: 6.3652 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0263 - mean_absolute_percentage_error: 45.3675 - val_loss: 0.0341 - val_mean_absolute_percentage_error: 8.0112 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0243 - mean_absolute_percentage_error: 38.0129 - val_loss: 0.0266 - val_mean_absolute_percentage_error: 6.2008 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0252 - mean_absolute_percentage_error: 39.4456 - val_loss: 0.0350 - val_mean_absolute_percentage_error: 8.8287 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0241 - mean_absolute_percentage_error: 38.7981 - val_loss: 0.0270 - val_mean_absolute_percentage_error: 6.6151 - lr: 6.0653e-04\n",
      "Learning rate of the model:  0.00060653087\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.0270 - mean_absolute_percentage_error: 6.6151\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0667 - mean_absolute_percentage_error: 14.0855\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2394 - mean_absolute_percentage_error: 165.0958 - val_loss: 0.4515 - val_mean_absolute_percentage_error: 38.7292 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.1104 - mean_absolute_percentage_error: 112.7378 - val_loss: 0.3181 - val_mean_absolute_percentage_error: 32.1163 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0854 - mean_absolute_percentage_error: 112.5314 - val_loss: 0.2767 - val_mean_absolute_percentage_error: 31.7423 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0640 - mean_absolute_percentage_error: 72.8653 - val_loss: 0.1941 - val_mean_absolute_percentage_error: 25.5116 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0567 - mean_absolute_percentage_error: 83.2940 - val_loss: 0.1481 - val_mean_absolute_percentage_error: 21.2519 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0453 - mean_absolute_percentage_error: 75.8689 - val_loss: 0.1265 - val_mean_absolute_percentage_error: 20.2397 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0405 - mean_absolute_percentage_error: 74.8544 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 12.9531 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0366 - mean_absolute_percentage_error: 70.3951 - val_loss: 0.0754 - val_mean_absolute_percentage_error: 14.1888 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0381 - mean_absolute_percentage_error: 66.2493 - val_loss: 0.0800 - val_mean_absolute_percentage_error: 15.3356 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0340 - mean_absolute_percentage_error: 66.3368 - val_loss: 0.0315 - val_mean_absolute_percentage_error: 6.3440 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0286 - mean_absolute_percentage_error: 55.5713 - val_loss: 0.0500 - val_mean_absolute_percentage_error: 10.9209 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0282 - mean_absolute_percentage_error: 50.3188 - val_loss: 0.0449 - val_mean_absolute_percentage_error: 9.7327 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0279 - mean_absolute_percentage_error: 57.7294 - val_loss: 0.0427 - val_mean_absolute_percentage_error: 10.3035 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0267 - mean_absolute_percentage_error: 58.7186 - val_loss: 0.0583 - val_mean_absolute_percentage_error: 13.8476 - lr: 7.4082e-04\n",
      "Learning rate of the model:  0.0007408184\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.0583 - mean_absolute_percentage_error: 13.8476\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1467 - mean_absolute_percentage_error: 22.3257\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2230 - mean_absolute_percentage_error: 122.6964 - val_loss: 0.4935 - val_mean_absolute_percentage_error: 42.1122 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.1077 - mean_absolute_percentage_error: 94.3210 - val_loss: 0.2414 - val_mean_absolute_percentage_error: 26.6474 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0795 - mean_absolute_percentage_error: 70.4266 - val_loss: 0.1595 - val_mean_absolute_percentage_error: 20.9849 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0620 - mean_absolute_percentage_error: 60.9763 - val_loss: 0.1134 - val_mean_absolute_percentage_error: 17.2451 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0530 - mean_absolute_percentage_error: 66.4482 - val_loss: 0.1318 - val_mean_absolute_percentage_error: 21.2395 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0468 - mean_absolute_percentage_error: 70.9021 - val_loss: 0.0497 - val_mean_absolute_percentage_error: 8.7837 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0442 - mean_absolute_percentage_error: 77.8239 - val_loss: 0.0497 - val_mean_absolute_percentage_error: 9.7103 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0399 - mean_absolute_percentage_error: 58.6390 - val_loss: 0.0611 - val_mean_absolute_percentage_error: 12.1516 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0345 - mean_absolute_percentage_error: 51.7849 - val_loss: 0.0549 - val_mean_absolute_percentage_error: 10.6468 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0322 - mean_absolute_percentage_error: 52.3507 - val_loss: 0.0852 - val_mean_absolute_percentage_error: 16.8379 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0296 - mean_absolute_percentage_error: 44.9523 - val_loss: 0.0603 - val_mean_absolute_percentage_error: 13.3031 - lr: 8.6071e-04\n",
      "Learning rate of the model:  0.00086070807\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0603 - mean_absolute_percentage_error: 13.3031\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1319 - mean_absolute_percentage_error: 20.6379\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2644 - mean_absolute_percentage_error: 145.3009 - val_loss: 0.2766 - val_mean_absolute_percentage_error: 26.9290 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.1095 - mean_absolute_percentage_error: 102.3718 - val_loss: 0.1630 - val_mean_absolute_percentage_error: 19.0744 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0784 - mean_absolute_percentage_error: 76.2173 - val_loss: 0.1494 - val_mean_absolute_percentage_error: 20.3737 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0686 - mean_absolute_percentage_error: 80.6566 - val_loss: 0.1052 - val_mean_absolute_percentage_error: 16.0829 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0675 - mean_absolute_percentage_error: 59.4697 - val_loss: 0.0533 - val_mean_absolute_percentage_error: 6.5927 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0502 - mean_absolute_percentage_error: 63.8843 - val_loss: 0.0600 - val_mean_absolute_percentage_error: 9.4550 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0433 - mean_absolute_percentage_error: 52.9746 - val_loss: 0.0559 - val_mean_absolute_percentage_error: 10.5732 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0470 - mean_absolute_percentage_error: 55.6506 - val_loss: 0.0683 - val_mean_absolute_percentage_error: 12.3686 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.0402 - mean_absolute_percentage_error: 50.2290 - val_loss: 0.0701 - val_mean_absolute_percentage_error: 14.3366 - lr: 9.5123e-04\n",
      "Learning rate of the model:  0.0009512295\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.0701 - mean_absolute_percentage_error: 14.3366\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1452 - mean_absolute_percentage_error: 21.2176\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 7s 13ms/step - loss: 0.2165 - mean_absolute_percentage_error: 117.6371 - val_loss: 0.4928 - val_mean_absolute_percentage_error: 43.4473 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.1105 - mean_absolute_percentage_error: 99.8449 - val_loss: 0.2578 - val_mean_absolute_percentage_error: 28.3563 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0823 - mean_absolute_percentage_error: 93.9595 - val_loss: 0.1894 - val_mean_absolute_percentage_error: 24.2413 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0651 - mean_absolute_percentage_error: 66.6440 - val_loss: 0.1013 - val_mean_absolute_percentage_error: 14.7883 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0532 - mean_absolute_percentage_error: 57.1280 - val_loss: 0.0829 - val_mean_absolute_percentage_error: 14.2267 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0447 - mean_absolute_percentage_error: 60.8912 - val_loss: 0.0566 - val_mean_absolute_percentage_error: 9.5419 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0427 - mean_absolute_percentage_error: 62.5054 - val_loss: 0.0563 - val_mean_absolute_percentage_error: 11.0177 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0367 - mean_absolute_percentage_error: 46.7142 - val_loss: 0.0493 - val_mean_absolute_percentage_error: 9.8914 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0371 - mean_absolute_percentage_error: 71.4942 - val_loss: 0.0471 - val_mean_absolute_percentage_error: 9.8581 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0325 - mean_absolute_percentage_error: 47.6851 - val_loss: 0.0637 - val_mean_absolute_percentage_error: 13.4362 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0310 - mean_absolute_percentage_error: 41.9075 - val_loss: 0.0351 - val_mean_absolute_percentage_error: 7.2369 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0311 - mean_absolute_percentage_error: 53.9658 - val_loss: 0.0377 - val_mean_absolute_percentage_error: 8.0734 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0254 - mean_absolute_percentage_error: 39.3483 - val_loss: 0.0447 - val_mean_absolute_percentage_error: 10.6096 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0283 - mean_absolute_percentage_error: 58.9327 - val_loss: 0.0664 - val_mean_absolute_percentage_error: 14.4725 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0276 - mean_absolute_percentage_error: 56.3193 - val_loss: 0.0454 - val_mean_absolute_percentage_error: 10.4156 - lr: 7.0469e-04\n",
      "Learning rate of the model:  0.00070468825\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0454 - mean_absolute_percentage_error: 10.4156\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0992 - mean_absolute_percentage_error: 17.8591\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 11ms/step - loss: 0.2204 - mean_absolute_percentage_error: 150.1770 - val_loss: 0.3407 - val_mean_absolute_percentage_error: 31.9001 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.1235 - mean_absolute_percentage_error: 103.8793 - val_loss: 0.2337 - val_mean_absolute_percentage_error: 26.5903 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0865 - mean_absolute_percentage_error: 95.8391 - val_loss: 0.2031 - val_mean_absolute_percentage_error: 25.8238 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0658 - mean_absolute_percentage_error: 79.2910 - val_loss: 0.1555 - val_mean_absolute_percentage_error: 21.5372 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0594 - mean_absolute_percentage_error: 57.9797 - val_loss: 0.0832 - val_mean_absolute_percentage_error: 13.2679 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0478 - mean_absolute_percentage_error: 67.9271 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 10.0816 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0431 - mean_absolute_percentage_error: 79.6494 - val_loss: 0.0431 - val_mean_absolute_percentage_error: 7.1656 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0386 - mean_absolute_percentage_error: 76.4901 - val_loss: 0.0505 - val_mean_absolute_percentage_error: 9.8965 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0346 - mean_absolute_percentage_error: 90.7631 - val_loss: 0.0402 - val_mean_absolute_percentage_error: 8.0340 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0328 - mean_absolute_percentage_error: 66.4491 - val_loss: 0.0364 - val_mean_absolute_percentage_error: 7.3248 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0298 - mean_absolute_percentage_error: 55.7045 - val_loss: 0.0425 - val_mean_absolute_percentage_error: 8.8955 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0322 - mean_absolute_percentage_error: 67.8543 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 7.6425 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0281 - mean_absolute_percentage_error: 64.5054 - val_loss: 0.0279 - val_mean_absolute_percentage_error: 6.4851 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0272 - mean_absolute_percentage_error: 58.7739 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 5.5750 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0267 - mean_absolute_percentage_error: 60.5910 - val_loss: 0.0299 - val_mean_absolute_percentage_error: 7.1103 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0246 - mean_absolute_percentage_error: 59.2258 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 5.5936 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0232 - mean_absolute_percentage_error: 60.4479 - val_loss: 0.0222 - val_mean_absolute_percentage_error: 5.3685 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0225 - mean_absolute_percentage_error: 53.6791 - val_loss: 0.0277 - val_mean_absolute_percentage_error: 6.9882 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0231 - mean_absolute_percentage_error: 53.0994 - val_loss: 0.0242 - val_mean_absolute_percentage_error: 6.2721 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0215 - mean_absolute_percentage_error: 55.8556 - val_loss: 0.0226 - val_mean_absolute_percentage_error: 5.5890 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0211 - mean_absolute_percentage_error: 52.4782 - val_loss: 0.0207 - val_mean_absolute_percentage_error: 5.3680 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0196 - mean_absolute_percentage_error: 59.9462 - val_loss: 0.0239 - val_mean_absolute_percentage_error: 6.4777 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0203 - mean_absolute_percentage_error: 37.2514 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 6.2622 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0199 - mean_absolute_percentage_error: 50.8923 - val_loss: 0.0289 - val_mean_absolute_percentage_error: 8.1319 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0215 - mean_absolute_percentage_error: 64.7879 - val_loss: 0.0211 - val_mean_absolute_percentage_error: 5.4524 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0211 - mean_absolute_percentage_error: 5.4524\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0588 - mean_absolute_percentage_error: 13.4795\n",
      "Epoch 1/60\n",
      "339/339 [==============================] - 6s 12ms/step - loss: 0.2629 - mean_absolute_percentage_error: 151.0521 - val_loss: 0.5799 - val_mean_absolute_percentage_error: 48.3184 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.1010 - mean_absolute_percentage_error: 109.3680 - val_loss: 0.3755 - val_mean_absolute_percentage_error: 37.8629 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0744 - mean_absolute_percentage_error: 89.4638 - val_loss: 0.1834 - val_mean_absolute_percentage_error: 24.0959 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0678 - mean_absolute_percentage_error: 83.4027 - val_loss: 0.3606 - val_mean_absolute_percentage_error: 40.7520 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.0532 - mean_absolute_percentage_error: 67.3167 - val_loss: 0.0894 - val_mean_absolute_percentage_error: 13.7573 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0470 - mean_absolute_percentage_error: 71.6853 - val_loss: 0.0517 - val_mean_absolute_percentage_error: 9.0953 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0389 - mean_absolute_percentage_error: 62.4320 - val_loss: 0.0813 - val_mean_absolute_percentage_error: 15.5553 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0365 - mean_absolute_percentage_error: 69.8039 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 12.4815 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0326 - mean_absolute_percentage_error: 56.7037 - val_loss: 0.0566 - val_mean_absolute_percentage_error: 12.9845 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0334 - mean_absolute_percentage_error: 58.6498 - val_loss: 0.0385 - val_mean_absolute_percentage_error: 8.5776 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0308 - mean_absolute_percentage_error: 56.1602 - val_loss: 0.0444 - val_mean_absolute_percentage_error: 10.2808 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0284 - mean_absolute_percentage_error: 56.1908 - val_loss: 0.0450 - val_mean_absolute_percentage_error: 10.8912 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.0271 - mean_absolute_percentage_error: 64.3263 - val_loss: 0.0674 - val_mean_absolute_percentage_error: 16.2154 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.0273 - mean_absolute_percentage_error: 47.5282 - val_loss: 0.0449 - val_mean_absolute_percentage_error: 11.8969 - lr: 7.4082e-04\n",
      "Learning rate of the model:  0.0007408184\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0449 - mean_absolute_percentage_error: 11.8969\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1113 - mean_absolute_percentage_error: 18.8308\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1801 - mean_absolute_percentage_error: 385.9789 - val_loss: 0.0988 - val_mean_absolute_percentage_error: 11.1812 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0749 - mean_absolute_percentage_error: 220.1945 - val_loss: 0.0587 - val_mean_absolute_percentage_error: 13.2866 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0481 - mean_absolute_percentage_error: 194.4874 - val_loss: 0.0358 - val_mean_absolute_percentage_error: 8.2602 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0343 - mean_absolute_percentage_error: 110.5105 - val_loss: 0.0414 - val_mean_absolute_percentage_error: 19.4545 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0261 - mean_absolute_percentage_error: 253.3654 - val_loss: 0.0221 - val_mean_absolute_percentage_error: 9.5794 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0203 - mean_absolute_percentage_error: 193.3283 - val_loss: 0.0195 - val_mean_absolute_percentage_error: 12.0222 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0167 - mean_absolute_percentage_error: 149.4713 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 6.2742 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0157 - mean_absolute_percentage_error: 223.7661 - val_loss: 0.0146 - val_mean_absolute_percentage_error: 9.1516 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0132 - mean_absolute_percentage_error: 178.5656 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 6.1417 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 139.5446 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 5.4417 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 97.6064 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 7.5219 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0102 - mean_absolute_percentage_error: 72.3206 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 5.2086 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0113 - mean_absolute_percentage_error: 121.2853 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 6.0673 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 128.4813 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 7.1484 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 135.3753 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.7768 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 103.5960 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 4.8230 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 115.8538 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 5.1976 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 172.8483 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 6.5877 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 136.2683 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 6.1236 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 167.8051 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 5.2711 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 148.3532 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.0745 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 114.3397 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 6.0197 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 154.2255 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 6.3471 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 151.4192 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 7.1305 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 162.6112 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 7.2071 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0063 - mean_absolute_percentage_error: 7.2071\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0202 - mean_absolute_percentage_error: 11.9077\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 13ms/step - loss: 0.1727 - mean_absolute_percentage_error: 852.7599 - val_loss: 0.0842 - val_mean_absolute_percentage_error: 15.5089 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0582 - mean_absolute_percentage_error: 267.2636 - val_loss: 0.0446 - val_mean_absolute_percentage_error: 12.1606 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0370 - mean_absolute_percentage_error: 225.0192 - val_loss: 0.0296 - val_mean_absolute_percentage_error: 10.3908 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0262 - mean_absolute_percentage_error: 229.1717 - val_loss: 0.0228 - val_mean_absolute_percentage_error: 12.3371 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0212 - mean_absolute_percentage_error: 250.4355 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 11.8273 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0185 - mean_absolute_percentage_error: 205.4550 - val_loss: 0.0148 - val_mean_absolute_percentage_error: 10.1862 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0173 - mean_absolute_percentage_error: 220.3490 - val_loss: 0.0122 - val_mean_absolute_percentage_error: 7.9416 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0155 - mean_absolute_percentage_error: 146.1455 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 5.8833 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0140 - mean_absolute_percentage_error: 112.2183 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 11.5666 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 224.5603 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 6.9203 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 158.1137 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 8.9900 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 197.5248 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 8.5733 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 178.5698 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 9.0140 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 128.5790 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 7.0442 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0100 - mean_absolute_percentage_error: 189.2020 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 4.8904 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 202.8336 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 7.0150 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 164.4254 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 6.6601 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 190.9891 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.8407 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0086 - mean_absolute_percentage_error: 134.2720 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 8.8835 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 126.0742 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 6.8668 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 141.6175 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 7.1556 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 113.4546 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 14.0741 - lr: 4.9659e-04\n",
      "Learning rate of the model:  0.0004965855\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0134 - mean_absolute_percentage_error: 14.0741\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0251 - mean_absolute_percentage_error: 12.6302\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1715 - mean_absolute_percentage_error: 643.9572 - val_loss: 0.1044 - val_mean_absolute_percentage_error: 13.7687 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0783 - mean_absolute_percentage_error: 325.3604 - val_loss: 0.0596 - val_mean_absolute_percentage_error: 10.1085 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0500 - mean_absolute_percentage_error: 162.3607 - val_loss: 0.0398 - val_mean_absolute_percentage_error: 8.6121 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0345 - mean_absolute_percentage_error: 118.1044 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 8.3683 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0270 - mean_absolute_percentage_error: 197.2925 - val_loss: 0.0197 - val_mean_absolute_percentage_error: 6.3572 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0207 - mean_absolute_percentage_error: 159.7269 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 14.6305 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0179 - mean_absolute_percentage_error: 207.6280 - val_loss: 0.0217 - val_mean_absolute_percentage_error: 12.3698 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0157 - mean_absolute_percentage_error: 161.7290 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 8.2656 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0136 - mean_absolute_percentage_error: 217.9415 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 8.2524 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0116 - mean_absolute_percentage_error: 175.8142 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 7.6106 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0114 - mean_absolute_percentage_error: 218.7986 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 6.0489 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0102 - mean_absolute_percentage_error: 133.6603 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 4.8924 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0098 - mean_absolute_percentage_error: 171.6447 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 5.9135 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0090 - mean_absolute_percentage_error: 173.8962 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 3.6873 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 96.1716 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 5.2220 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0090 - mean_absolute_percentage_error: 186.3466 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 5.5496 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 180.5032 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 6.0013 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 108.8121 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 5.5957 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 194.6197 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 6.4228 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 132.2260 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 6.8272 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 129.9862 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 4.8462 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 108.8583 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 6.4074 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 131.2413 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.2618 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 211.5538 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 5.2359 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0067 - mean_absolute_percentage_error: 223.2757 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 8.5726 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 217.2398 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 4.8537 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0063 - mean_absolute_percentage_error: 98.3056 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 6.3105 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 146.0464 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 4.9451 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 186.4223 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 6.4558 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 119.3496 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 4.8602 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 75.4544 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 7.6806 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 132.7844 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 4.9885 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 126.0845 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 5.4193 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 89.3071 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 7.3282 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 105.6477 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 5.6790 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0055 - mean_absolute_percentage_error: 113.8694 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.3768 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 138.0217 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 5.8863 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 103.2506 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 5.2136 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 122.4374 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 5.5731 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 102.5275 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 4.0581 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 108.1064 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 6.1361 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 98.6017 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 4.6472 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 134.5532 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.8073 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0052 - mean_absolute_percentage_error: 146.6311 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 4.3963 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 78.3888 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 5.6187 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0051 - mean_absolute_percentage_error: 149.7543 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 4.2681 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 110.6091 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 6.7142 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 122.3335 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 6.6382 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 120.6586 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 6.2414 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 143.1899 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 4.7553 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 150.8175 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 5.0119 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 104.9212 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 4.9336 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 147.0620 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 5.3577 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0050 - mean_absolute_percentage_error: 135.6682 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 6.4634 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0040 - mean_absolute_percentage_error: 6.4634\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0158 - mean_absolute_percentage_error: 9.7994\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1625 - mean_absolute_percentage_error: 689.2893 - val_loss: 0.1064 - val_mean_absolute_percentage_error: 15.4407 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0716 - mean_absolute_percentage_error: 247.2305 - val_loss: 0.0676 - val_mean_absolute_percentage_error: 16.5774 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0456 - mean_absolute_percentage_error: 230.1195 - val_loss: 0.0361 - val_mean_absolute_percentage_error: 9.9770 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0319 - mean_absolute_percentage_error: 145.5082 - val_loss: 0.0285 - val_mean_absolute_percentage_error: 10.2735 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0256 - mean_absolute_percentage_error: 202.9132 - val_loss: 0.0196 - val_mean_absolute_percentage_error: 8.3372 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0210 - mean_absolute_percentage_error: 166.8479 - val_loss: 0.0151 - val_mean_absolute_percentage_error: 6.7600 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0174 - mean_absolute_percentage_error: 186.7455 - val_loss: 0.0143 - val_mean_absolute_percentage_error: 8.1969 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0157 - mean_absolute_percentage_error: 118.0985 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 5.7444 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0137 - mean_absolute_percentage_error: 150.0378 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 8.0362 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 195.6248 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 5.6716 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0117 - mean_absolute_percentage_error: 151.6543 - val_loss: 0.0138 - val_mean_absolute_percentage_error: 9.5842 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 70.6645 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 6.4191 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0104 - mean_absolute_percentage_error: 91.3870 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 5.9977 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 181.6517 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 4.4849 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0091 - mean_absolute_percentage_error: 147.1686 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 4.9134 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 147.8739 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 6.3453 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 154.8466 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 6.5021 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 256.5901 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 7.2365 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0081 - mean_absolute_percentage_error: 157.1094 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 4.4600 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 212.0341 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 6.0371 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 195.1084 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 4.4551 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 175.4983 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 4.2207 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 154.2252 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.6099 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 119.6144 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 3.3556 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 104.1862 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 3.7251 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 94.8620 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 4.1360 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 120.3457 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 4.5163 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 84.5599 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.2109 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 91.2468 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 4.4894 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 82.3916 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.5308 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 99.0476 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.8142 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "354/354 [==============================] - 3s 9ms/step - loss: 0.0060 - mean_absolute_percentage_error: 93.5534 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.6629 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 83.1384 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.4682 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 102.2045 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 4.4513 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 123.4604 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.6107 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 100.6772 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.0634 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0058 - mean_absolute_percentage_error: 93.4530 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 4.2161 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 125.8129 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 3.7986 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 82.9499 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.1180 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 83.3605 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 3.7779 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 98.1705 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.0107 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 85.9003 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 3.6823 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 105.2884 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.6474 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 122.7155 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.6043 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 95.7763 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.7229 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 89.1780 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.3091 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0053 - mean_absolute_percentage_error: 81.8976 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.0047 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 117.9043 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.9994 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 111.0585 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.8364 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 120.6277 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 3.6641 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 77.1439 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 3.5720 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 103.4672 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.8856 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 65.6943 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 3.7492 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 82.6896 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.7275 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0051 - mean_absolute_percentage_error: 100.3369 - val_loss: 0.0035 - val_mean_absolute_percentage_error: 3.7711 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 89.7775 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 4.3587 - lr: 2.0190e-04\n",
      "Epoch 57/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 99.8477 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.8238 - lr: 2.0190e-04\n",
      "Epoch 58/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 101.0083 - val_loss: 0.0035 - val_mean_absolute_percentage_error: 3.5041 - lr: 2.0190e-04\n",
      "Epoch 59/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 114.4088 - val_loss: 0.0034 - val_mean_absolute_percentage_error: 3.5980 - lr: 2.0190e-04\n",
      "Epoch 60/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0050 - mean_absolute_percentage_error: 133.2141 - val_loss: 0.0035 - val_mean_absolute_percentage_error: 3.6791 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_absolute_percentage_error: 3.6791\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0181 - mean_absolute_percentage_error: 8.6757\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 7s 13ms/step - loss: 0.1986 - mean_absolute_percentage_error: 357.0362 - val_loss: 0.1355 - val_mean_absolute_percentage_error: 29.0283 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0647 - mean_absolute_percentage_error: 275.8530 - val_loss: 0.0511 - val_mean_absolute_percentage_error: 12.4872 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0413 - mean_absolute_percentage_error: 252.1073 - val_loss: 0.0320 - val_mean_absolute_percentage_error: 10.4437 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0295 - mean_absolute_percentage_error: 238.1890 - val_loss: 0.0218 - val_mean_absolute_percentage_error: 7.8439 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0226 - mean_absolute_percentage_error: 169.6827 - val_loss: 0.0251 - val_mean_absolute_percentage_error: 12.9546 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0188 - mean_absolute_percentage_error: 261.8242 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 5.0642 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0169 - mean_absolute_percentage_error: 296.2029 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 6.7709 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0163 - mean_absolute_percentage_error: 171.6069 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 7.9794 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0144 - mean_absolute_percentage_error: 166.9997 - val_loss: 0.0210 - val_mean_absolute_percentage_error: 20.5494 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0126 - mean_absolute_percentage_error: 182.5377 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 4.5537 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0122 - mean_absolute_percentage_error: 228.4683 - val_loss: 0.0108 - val_mean_absolute_percentage_error: 8.0840 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 220.3128 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 5.4539 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0109 - mean_absolute_percentage_error: 169.3752 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 4.1836 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0107 - mean_absolute_percentage_error: 197.9519 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 5.0105 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0102 - mean_absolute_percentage_error: 154.8791 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 4.9705 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 130.3157 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 5.9045 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 162.9925 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 6.0834 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 198.6721 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 5.4039 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 177.8128 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 5.9918 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 105.2936 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 5.6238 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0089 - mean_absolute_percentage_error: 163.5088 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 6.9011 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0085 - mean_absolute_percentage_error: 83.1313 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 7.3249 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 146.5786 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 6.9548 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 80.3892 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 6.8944 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0073 - mean_absolute_percentage_error: 6.8944\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0259 - mean_absolute_percentage_error: 10.4270\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 7s 13ms/step - loss: 0.1626 - mean_absolute_percentage_error: 371.1693 - val_loss: 0.0984 - val_mean_absolute_percentage_error: 19.3232 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0639 - mean_absolute_percentage_error: 272.8099 - val_loss: 0.1128 - val_mean_absolute_percentage_error: 33.8144 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0406 - mean_absolute_percentage_error: 249.2568 - val_loss: 0.0436 - val_mean_absolute_percentage_error: 16.7882 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0299 - mean_absolute_percentage_error: 137.1111 - val_loss: 0.0341 - val_mean_absolute_percentage_error: 14.4921 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0218 - mean_absolute_percentage_error: 162.2993 - val_loss: 0.0174 - val_mean_absolute_percentage_error: 8.5988 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0191 - mean_absolute_percentage_error: 165.3483 - val_loss: 0.0150 - val_mean_absolute_percentage_error: 6.7205 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0154 - mean_absolute_percentage_error: 133.8482 - val_loss: 0.0150 - val_mean_absolute_percentage_error: 9.3681 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0158 - mean_absolute_percentage_error: 231.2242 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 6.8576 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0128 - mean_absolute_percentage_error: 160.0195 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 5.8300 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0120 - mean_absolute_percentage_error: 145.3583 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 8.8284 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0118 - mean_absolute_percentage_error: 171.6007 - val_loss: 0.0138 - val_mean_absolute_percentage_error: 10.1546 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0110 - mean_absolute_percentage_error: 217.0939 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 7.0922 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 176.2075 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 6.3194 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 117.1204 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 6.6864 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 182.3206 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 5.9958 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 132.2838 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 7.6503 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 165.3444 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 7.2137 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 163.2315 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 7.0414 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 169.4300 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 6.2097 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 119.8015 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 5.2594 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 163.4831 - val_loss: 0.0142 - val_mean_absolute_percentage_error: 11.2902 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 152.0532 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 5.8840 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 166.9790 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 4.6318 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 171.2511 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 5.1765 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 143.6730 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 5.4634 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 174.2156 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 7.0444 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 138.4922 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 5.0665 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 123.0980 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 5.0525 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 125.6410 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 5.8925 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 189.7258 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 6.4298 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 121.8589 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 5.7496 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 123.3033 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 4.9515 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 166.5370 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 5.8922 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0062 - mean_absolute_percentage_error: 131.7129 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 4.9421 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 90.4386 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.5299 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 162.4451 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 5.2352 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0062 - mean_absolute_percentage_error: 113.9829 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 6.2587 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 146.2616 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 5.0296 - lr: 2.2313e-04\n",
      "Learning rate of the model:  0.00022313035\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0046 - mean_absolute_percentage_error: 5.0296\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0178 - mean_absolute_percentage_error: 10.0386\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 7s 13ms/step - loss: 0.1717 - mean_absolute_percentage_error: 675.9330 - val_loss: 0.0906 - val_mean_absolute_percentage_error: 14.4271 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0708 - mean_absolute_percentage_error: 201.0490 - val_loss: 0.0543 - val_mean_absolute_percentage_error: 17.2181 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0441 - mean_absolute_percentage_error: 156.0274 - val_loss: 0.0413 - val_mean_absolute_percentage_error: 18.8822 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0311 - mean_absolute_percentage_error: 154.7068 - val_loss: 0.0269 - val_mean_absolute_percentage_error: 11.7827 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0234 - mean_absolute_percentage_error: 192.4434 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 12.1216 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0203 - mean_absolute_percentage_error: 195.1977 - val_loss: 0.0163 - val_mean_absolute_percentage_error: 9.0784 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0162 - mean_absolute_percentage_error: 143.3734 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 5.6176 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0152 - mean_absolute_percentage_error: 192.3894 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 6.4090 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0130 - mean_absolute_percentage_error: 210.9034 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 5.2576 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 218.8061 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 5.3654 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 142.7500 - val_loss: 0.0152 - val_mean_absolute_percentage_error: 12.2134 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0108 - mean_absolute_percentage_error: 170.0976 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 16.2056 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 154.3654 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 9.1754 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 211.7283 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 7.0723 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 142.3738 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 6.4824 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 197.8517 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 5.1032 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 188.1956 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 4.8715 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 193.3120 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 5.2653 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 115.5704 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 7.9630 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 82.6770 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 4.8566 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 179.9395 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 7.7496 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 178.2708 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 3.5227 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 136.9508 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 4.3016 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 133.3401 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 5.2586 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 96.2961 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 5.1196 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 87.7136 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 8.4507 - lr: 4.0657e-04\n",
      "Learning rate of the model:  0.0004065699\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.4507\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0201 - mean_absolute_percentage_error: 13.2554\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 12ms/step - loss: 0.1737 - mean_absolute_percentage_error: 782.9983 - val_loss: 0.0974 - val_mean_absolute_percentage_error: 16.6309 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0732 - mean_absolute_percentage_error: 377.4406 - val_loss: 0.0588 - val_mean_absolute_percentage_error: 11.0771 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0452 - mean_absolute_percentage_error: 204.3550 - val_loss: 0.0350 - val_mean_absolute_percentage_error: 8.1759 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0326 - mean_absolute_percentage_error: 148.6624 - val_loss: 0.0253 - val_mean_absolute_percentage_error: 7.2485 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0249 - mean_absolute_percentage_error: 179.2045 - val_loss: 0.0190 - val_mean_absolute_percentage_error: 6.3540 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0205 - mean_absolute_percentage_error: 174.7357 - val_loss: 0.0155 - val_mean_absolute_percentage_error: 5.5498 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0182 - mean_absolute_percentage_error: 198.9324 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 6.3779 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0154 - mean_absolute_percentage_error: 168.9577 - val_loss: 0.0162 - val_mean_absolute_percentage_error: 13.5655 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0137 - mean_absolute_percentage_error: 207.0590 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 6.4997 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0131 - mean_absolute_percentage_error: 222.2827 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 9.7126 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0119 - mean_absolute_percentage_error: 136.7275 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 9.1990 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0112 - mean_absolute_percentage_error: 203.5344 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 6.5088 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 284.9069 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 6.6924 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 206.4905 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 7.1226 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0093 - mean_absolute_percentage_error: 126.2214 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 6.5481 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 137.9182 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 5.9687 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 93.8306 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 5.1217 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 204.3720 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.5928 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 122.9449 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 5.3899 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 105.5544 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 7.1380 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 77.4713 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 5.4234 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 137.6311 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 6.1080 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 124.9952 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 5.8269 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 191.0878 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 5.5463 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 164.2697 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 4.3241 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 152.6734 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 5.7630 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 130.6954 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 4.8715 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 141.6447 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 8.0162 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 187.1968 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 9.1588 - lr: 3.4994e-04\n",
      "Learning rate of the model:  0.00034993797\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.1588\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0190 - mean_absolute_percentage_error: 11.3171\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 7s 12ms/step - loss: 0.1767 - mean_absolute_percentage_error: 573.3590 - val_loss: 0.1086 - val_mean_absolute_percentage_error: 16.3685 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0779 - mean_absolute_percentage_error: 345.6360 - val_loss: 0.0633 - val_mean_absolute_percentage_error: 12.5805 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0500 - mean_absolute_percentage_error: 302.4508 - val_loss: 0.0456 - val_mean_absolute_percentage_error: 12.1623 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0357 - mean_absolute_percentage_error: 212.8019 - val_loss: 0.0277 - val_mean_absolute_percentage_error: 8.6401 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0280 - mean_absolute_percentage_error: 195.6862 - val_loss: 0.0253 - val_mean_absolute_percentage_error: 9.7704 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0222 - mean_absolute_percentage_error: 226.9691 - val_loss: 0.0170 - val_mean_absolute_percentage_error: 7.9156 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0183 - mean_absolute_percentage_error: 140.4554 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 5.8162 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0173 - mean_absolute_percentage_error: 142.3527 - val_loss: 0.0122 - val_mean_absolute_percentage_error: 7.2594 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0144 - mean_absolute_percentage_error: 158.5746 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 5.8158 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 159.4945 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 4.8548 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0123 - mean_absolute_percentage_error: 115.3301 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 6.2060 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 224.0740 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 6.9005 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0112 - mean_absolute_percentage_error: 179.8897 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 6.8414 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 159.4476 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 5.0279 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 130.4276 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 8.6046 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 105.7596 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 6.0561 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 193.4303 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 5.6281 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 149.8388 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.2464 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 181.2727 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 5.1377 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 150.6159 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.9073 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 146.9282 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 4.9892 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 115.9278 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 5.7495 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 151.8711 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 4.6958 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 164.8043 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 7.3461 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 136.3109 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 4.7274 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 125.7602 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 5.2229 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 102.5378 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 4.6873 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 125.4993 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 4.4737 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 188.2735 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 3.9553 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 93.1762 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 4.9595 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 145.3898 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.0706 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 156.9583 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.2500 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 172.6837 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 4.4089 - lr: 2.8651e-04\n",
      "Learning rate of the model:  0.000286505\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0045 - mean_absolute_percentage_error: 4.4089\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0186 - mean_absolute_percentage_error: 7.7682\n",
      "Epoch 1/60\n",
      "354/354 [==============================] - 6s 13ms/step - loss: 0.1524 - mean_absolute_percentage_error: 1063.9791 - val_loss: 0.0886 - val_mean_absolute_percentage_error: 13.7441 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0666 - mean_absolute_percentage_error: 309.0626 - val_loss: 0.0507 - val_mean_absolute_percentage_error: 11.4239 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0427 - mean_absolute_percentage_error: 240.5954 - val_loss: 0.0311 - val_mean_absolute_percentage_error: 6.7030 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0310 - mean_absolute_percentage_error: 283.7492 - val_loss: 0.0237 - val_mean_absolute_percentage_error: 6.7488 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0231 - mean_absolute_percentage_error: 163.5501 - val_loss: 0.0212 - val_mean_absolute_percentage_error: 8.2539 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0198 - mean_absolute_percentage_error: 160.3769 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 4.7728 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0161 - mean_absolute_percentage_error: 155.4347 - val_loss: 0.0126 - val_mean_absolute_percentage_error: 5.7308 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0152 - mean_absolute_percentage_error: 137.8859 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 5.5608 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0135 - mean_absolute_percentage_error: 219.5254 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 5.4287 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 192.1309 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 6.7604 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 196.2634 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 5.3993 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 180.9866 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 6.4892 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 221.1731 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 8.0624 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 190.5696 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 5.1773 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 116.0752 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 6.3883 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 192.9924 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 4.9463 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 251.8014 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.4636 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 152.8029 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 5.3925 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 160.1141 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 4.6968 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 102.5824 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 8.1953 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 134.9777 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 4.7701 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 128.7102 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 6.7466 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 167.5023 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 6.8308 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 173.9135 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 4.4913 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "354/354 [==============================] - 3s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 117.0293 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 4.4177 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 105.0965 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.0198 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 172.1636 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 5.2138 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 142.0703 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 5.5977 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 174.2271 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 6.0759 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 128.7628 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 5.9799 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 174.1774 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 4.1571 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 155.2150 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 4.6510 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 102.9473 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 5.5938 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0059 - mean_absolute_percentage_error: 140.1057 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 4.6292 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0058 - mean_absolute_percentage_error: 122.0920 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 4.3992 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 118.6131 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 4.3760 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 100.2637 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 4.4279 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0057 - mean_absolute_percentage_error: 143.2989 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 4.7019 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 124.0711 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.3084 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 112.6957 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 5.7773 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 129.3726 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.3965 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 150.5529 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 4.5796 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 107.1438 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.1842 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0055 - mean_absolute_percentage_error: 155.9599 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.5077 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "354/354 [==============================] - 4s 12ms/step - loss: 0.0054 - mean_absolute_percentage_error: 136.4041 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 5.9187 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 106.7516 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.4623 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 121.8708 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 4.9742 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 150.8323 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.5341 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0053 - mean_absolute_percentage_error: 141.8890 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.3667 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 151.5729 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 4.3353 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "354/354 [==============================] - 4s 12ms/step - loss: 0.0052 - mean_absolute_percentage_error: 121.0480 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.8439 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0054 - mean_absolute_percentage_error: 135.8756 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 4.7579 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0053 - mean_absolute_percentage_error: 124.5092 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 4.3652 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "354/354 [==============================] - 5s 13ms/step - loss: 0.0052 - mean_absolute_percentage_error: 114.7209 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 6.1521 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "354/354 [==============================] - 4s 11ms/step - loss: 0.0052 - mean_absolute_percentage_error: 142.6851 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 11.8164 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 138.5064 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 5.4178 - lr: 2.0190e-04\n",
      "Epoch 57/60\n",
      "354/354 [==============================] - 4s 10ms/step - loss: 0.0052 - mean_absolute_percentage_error: 82.3695 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 4.7838 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0039 - mean_absolute_percentage_error: 4.7838\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0199 - mean_absolute_percentage_error: 9.3010\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 6s 12ms/step - loss: 0.1938 - mean_absolute_percentage_error: 78.3604 - val_loss: 0.1207 - val_mean_absolute_percentage_error: 47.6329 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0852 - mean_absolute_percentage_error: 33.6571 - val_loss: 0.0957 - val_mean_absolute_percentage_error: 53.6850 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0565 - mean_absolute_percentage_error: 29.8442 - val_loss: 0.0641 - val_mean_absolute_percentage_error: 30.4473 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0418 - mean_absolute_percentage_error: 21.5474 - val_loss: 0.0458 - val_mean_absolute_percentage_error: 16.1366 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0327 - mean_absolute_percentage_error: 24.5646 - val_loss: 0.0292 - val_mean_absolute_percentage_error: 16.2766 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0270 - mean_absolute_percentage_error: 20.9188 - val_loss: 0.0218 - val_mean_absolute_percentage_error: 20.3950 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0254 - mean_absolute_percentage_error: 22.0218 - val_loss: 0.0195 - val_mean_absolute_percentage_error: 21.1800 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0237 - mean_absolute_percentage_error: 21.2279 - val_loss: 0.0191 - val_mean_absolute_percentage_error: 9.0995 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0220 - mean_absolute_percentage_error: 20.4071 - val_loss: 0.0151 - val_mean_absolute_percentage_error: 12.8927 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0168 - mean_absolute_percentage_error: 18.6819 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 11.0990 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0150 - mean_absolute_percentage_error: 16.3902 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 8.1910 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0150 - mean_absolute_percentage_error: 18.1264 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 9.7302 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0163 - mean_absolute_percentage_error: 18.9408 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 6.5618 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0149 - mean_absolute_percentage_error: 17.5836 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 4.4305 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0127 - mean_absolute_percentage_error: 18.6394 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 10.2418 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0131 - mean_absolute_percentage_error: 18.1246 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 10.6361 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0126 - mean_absolute_percentage_error: 18.7546 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 3.9755 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0114 - mean_absolute_percentage_error: 18.9835 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 11.3231 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0108 - mean_absolute_percentage_error: 17.1988 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 10.1900 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0099 - mean_absolute_percentage_error: 16.4688 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 11.1786 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 18.9678 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 10.2354 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0103 - mean_absolute_percentage_error: 20.3575 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 8.9895 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.3936 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 9.2935 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 17.9942 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.6253 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 16.6914 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 6.0216 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.0050 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 7.3156 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 17.8071 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 8.3515 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0083 - mean_absolute_percentage_error: 16.9705 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 8.9482 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 20.5087 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 9.2120 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 17.3010 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 8.9051 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 19.0549 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 9.4978 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 18.4825 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 10.4102 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 16.9423 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 10.1446 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 16.5483 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 8.9541 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 17.9020 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 10.8946 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 16.9550 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 11.1081 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 17.6542 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 10.6425 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 17.4869 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 12.5462 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 17.1455 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 12.5616 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 17.3699 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 11.8066 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 16.9872 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 11.8492 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 17.7564 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 12.5428 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 17.6898 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 13.8404 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.5855 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 10.3602 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.1184 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 11.2596 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 17.8573 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 10.0571 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 18.9206 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 13.4003 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 16.1515 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 12.7651 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 19.0797 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 11.8773 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0058 - mean_absolute_percentage_error: 11.8773\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0049 - mean_absolute_percentage_error: 12.6065\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 14ms/step - loss: 0.1975 - mean_absolute_percentage_error: 48.3830 - val_loss: 0.1202 - val_mean_absolute_percentage_error: 26.2097 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0835 - mean_absolute_percentage_error: 32.0360 - val_loss: 0.0727 - val_mean_absolute_percentage_error: 31.5834 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0555 - mean_absolute_percentage_error: 32.4323 - val_loss: 0.0591 - val_mean_absolute_percentage_error: 26.7344 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0383 - mean_absolute_percentage_error: 23.0097 - val_loss: 0.0407 - val_mean_absolute_percentage_error: 28.2936 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0310 - mean_absolute_percentage_error: 27.4289 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 6.6591 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0279 - mean_absolute_percentage_error: 22.5633 - val_loss: 0.0211 - val_mean_absolute_percentage_error: 30.6596 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0230 - mean_absolute_percentage_error: 25.2562 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 21.3005 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0218 - mean_absolute_percentage_error: 21.7654 - val_loss: 0.0179 - val_mean_absolute_percentage_error: 33.1008 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0180 - mean_absolute_percentage_error: 24.2172 - val_loss: 0.0155 - val_mean_absolute_percentage_error: 15.7544 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0169 - mean_absolute_percentage_error: 22.4051 - val_loss: 0.0224 - val_mean_absolute_percentage_error: 23.7580 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0148 - mean_absolute_percentage_error: 23.2664 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 6.5944 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0156 - mean_absolute_percentage_error: 21.9456 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 11.6343 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0145 - mean_absolute_percentage_error: 19.0081 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 12.3368 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0136 - mean_absolute_percentage_error: 18.4500 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 21.8139 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0113 - mean_absolute_percentage_error: 18.9861 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 14.8086 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0125 - mean_absolute_percentage_error: 20.4311 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 17.0453 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 18.0062 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 17.3953 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0114 - mean_absolute_percentage_error: 20.4198 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 18.7342 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0102 - mean_absolute_percentage_error: 18.4316 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 18.5085 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0101 - mean_absolute_percentage_error: 18.7761 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 10.4107 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0093 - mean_absolute_percentage_error: 19.4333 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 14.0131 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0095 - mean_absolute_percentage_error: 21.6290 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 26.1659 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0097 - mean_absolute_percentage_error: 18.8466 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 12.3938 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0100 - mean_absolute_percentage_error: 21.5781 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 3.2803 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 20.7670 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 6.4246 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 19.8973 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 7.6601 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 19.7552 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 6.9782 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0087 - mean_absolute_percentage_error: 21.3342 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 12.4722 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 18.6298 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.7320 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0076 - mean_absolute_percentage_error: 19.7017 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 9.3594 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 20.2908 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 8.0380 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 18.7214 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 11.4365 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 18.5200 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 10.8775 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0069 - mean_absolute_percentage_error: 18.7063 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 12.7488 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0072 - mean_absolute_percentage_error: 18.7781 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 5.7468 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 18.7257 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 6.1033 - lr: 2.4660e-04\n",
      "Learning rate of the model:  0.00024659716\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0059 - mean_absolute_percentage_error: 6.1033\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0050 - mean_absolute_percentage_error: 10.9139\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 13ms/step - loss: 0.1927 - mean_absolute_percentage_error: 45.7038 - val_loss: 0.1162 - val_mean_absolute_percentage_error: 38.5376 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0809 - mean_absolute_percentage_error: 32.6457 - val_loss: 0.0792 - val_mean_absolute_percentage_error: 35.0222 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0544 - mean_absolute_percentage_error: 28.4096 - val_loss: 0.0583 - val_mean_absolute_percentage_error: 22.2839 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0411 - mean_absolute_percentage_error: 26.7757 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 14.7825 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0325 - mean_absolute_percentage_error: 26.3659 - val_loss: 0.0265 - val_mean_absolute_percentage_error: 7.4801 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0297 - mean_absolute_percentage_error: 21.5722 - val_loss: 0.0211 - val_mean_absolute_percentage_error: 9.2832 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0239 - mean_absolute_percentage_error: 22.8911 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 6.4246 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0230 - mean_absolute_percentage_error: 26.4537 - val_loss: 0.0192 - val_mean_absolute_percentage_error: 22.0290 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0213 - mean_absolute_percentage_error: 22.4990 - val_loss: 0.0176 - val_mean_absolute_percentage_error: 14.3646 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0178 - mean_absolute_percentage_error: 19.4840 - val_loss: 0.0135 - val_mean_absolute_percentage_error: 16.0323 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0162 - mean_absolute_percentage_error: 20.5018 - val_loss: 0.0130 - val_mean_absolute_percentage_error: 16.4743 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0154 - mean_absolute_percentage_error: 21.5984 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 17.0124 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0140 - mean_absolute_percentage_error: 19.4592 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 13.5559 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0139 - mean_absolute_percentage_error: 22.9455 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 12.0133 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 22.4557 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 7.9790 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0119 - mean_absolute_percentage_error: 19.8422 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 9.7370 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0120 - mean_absolute_percentage_error: 19.8281 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 8.8154 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0115 - mean_absolute_percentage_error: 21.1116 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 13.8292 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0106 - mean_absolute_percentage_error: 19.7906 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 12.9774 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0102 - mean_absolute_percentage_error: 20.5568 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 11.6820 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0099 - mean_absolute_percentage_error: 20.4450 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 10.0583 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 22.6355 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 9.3704 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.3288 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 12.6150 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0089 - mean_absolute_percentage_error: 19.6089 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 10.4442 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 18.3967 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 9.5130 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0090 - mean_absolute_percentage_error: 18.3769 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 10.1328 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0085 - mean_absolute_percentage_error: 21.0833 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 10.4911 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 18.2772 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 12.8626 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 17.6975 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 12.3083 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 19.3113 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 11.4896 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 16.3011 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 9.4198 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 18.7988 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 10.3426 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 16.5072 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 11.6041 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 18.0042 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 11.4007 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 17.8383 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 10.1331 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 18.4701 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 12.8603 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 17.9243 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 8.0401 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 19.0104 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 12.0691 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 17.9512 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 10.8286 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0067 - mean_absolute_percentage_error: 17.9908 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 10.5209 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 17.3189 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 13.3722 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 18.1392 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 12.4719 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 18.1021 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 11.4463 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.7417 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 8.8724 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 18.2034 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 10.7020 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 18.3189 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 14.6111 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0063 - mean_absolute_percentage_error: 18.2410 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 13.3999 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.2476 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 13.8041 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 18.6829 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 13.5976 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0060 - mean_absolute_percentage_error: 13.5976\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0052 - mean_absolute_percentage_error: 13.5032\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 13ms/step - loss: 0.1928 - mean_absolute_percentage_error: 68.0108 - val_loss: 0.1260 - val_mean_absolute_percentage_error: 27.6586 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0887 - mean_absolute_percentage_error: 30.1166 - val_loss: 0.0779 - val_mean_absolute_percentage_error: 21.2025 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0570 - mean_absolute_percentage_error: 31.0634 - val_loss: 0.0566 - val_mean_absolute_percentage_error: 27.0499 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0447 - mean_absolute_percentage_error: 28.8965 - val_loss: 0.0471 - val_mean_absolute_percentage_error: 31.3013 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0378 - mean_absolute_percentage_error: 30.0939 - val_loss: 0.0331 - val_mean_absolute_percentage_error: 32.4201 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0312 - mean_absolute_percentage_error: 24.2452 - val_loss: 0.0252 - val_mean_absolute_percentage_error: 20.0621 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0248 - mean_absolute_percentage_error: 22.1343 - val_loss: 0.0217 - val_mean_absolute_percentage_error: 27.1956 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0241 - mean_absolute_percentage_error: 24.7257 - val_loss: 0.0253 - val_mean_absolute_percentage_error: 32.0038 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0203 - mean_absolute_percentage_error: 24.2087 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 35.1703 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0192 - mean_absolute_percentage_error: 24.3396 - val_loss: 0.0145 - val_mean_absolute_percentage_error: 19.7096 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0163 - mean_absolute_percentage_error: 24.5635 - val_loss: 0.0210 - val_mean_absolute_percentage_error: 33.3679 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0172 - mean_absolute_percentage_error: 20.9639 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 34.6674 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0157 - mean_absolute_percentage_error: 23.7251 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 24.8949 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0148 - mean_absolute_percentage_error: 21.3921 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 28.7837 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0147 - mean_absolute_percentage_error: 24.0534 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 26.2421 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0134 - mean_absolute_percentage_error: 22.3847 - val_loss: 0.0135 - val_mean_absolute_percentage_error: 28.6649 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0129 - mean_absolute_percentage_error: 19.7165 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 21.5373 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 24.1617 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 16.9590 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0116 - mean_absolute_percentage_error: 25.1364 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 25.0041 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0107 - mean_absolute_percentage_error: 24.8930 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 21.1889 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0107 - mean_absolute_percentage_error: 22.8691 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 25.8632 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0107 - mean_absolute_percentage_error: 24.3011 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 20.1715 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 22.9620 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 17.0169 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0103 - mean_absolute_percentage_error: 21.7166 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 21.6328 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0096 - mean_absolute_percentage_error: 20.6051 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 22.7234 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 21.1748 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 17.1045 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0092 - mean_absolute_percentage_error: 20.5959 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 20.9287 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 18.0388 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 19.9477 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 18.7702 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 20.0177 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 19.3881 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 14.7470 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 18.3033 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 17.3097 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 19.5399 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 16.1662 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 18.8880 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 10.7716 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 19.1592 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 14.4808 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 17.8041 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 15.7378 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 19.7046 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 15.6382 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 17.8558 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 14.2065 - lr: 2.3457e-04\n",
      "Learning rate of the model:  0.00023457049\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0068 - mean_absolute_percentage_error: 14.2065\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_absolute_percentage_error: 13.2504\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 6s 12ms/step - loss: 0.1807 - mean_absolute_percentage_error: 48.4640 - val_loss: 0.1179 - val_mean_absolute_percentage_error: 24.8031 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0836 - mean_absolute_percentage_error: 25.7760 - val_loss: 0.0682 - val_mean_absolute_percentage_error: 23.5993 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0602 - mean_absolute_percentage_error: 30.6530 - val_loss: 0.0513 - val_mean_absolute_percentage_error: 25.4077 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0423 - mean_absolute_percentage_error: 28.0649 - val_loss: 0.0366 - val_mean_absolute_percentage_error: 14.5352 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0374 - mean_absolute_percentage_error: 24.7378 - val_loss: 0.0258 - val_mean_absolute_percentage_error: 17.5451 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0297 - mean_absolute_percentage_error: 24.4725 - val_loss: 0.0220 - val_mean_absolute_percentage_error: 12.1134 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0259 - mean_absolute_percentage_error: 24.0427 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 20.7850 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0217 - mean_absolute_percentage_error: 22.9129 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 17.7051 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0207 - mean_absolute_percentage_error: 25.6232 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 12.8415 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0196 - mean_absolute_percentage_error: 25.9227 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 11.4882 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0171 - mean_absolute_percentage_error: 20.2896 - val_loss: 0.0144 - val_mean_absolute_percentage_error: 18.9165 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0148 - mean_absolute_percentage_error: 19.7497 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 5.2307 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0158 - mean_absolute_percentage_error: 21.0829 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 19.0900 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 18.1791 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 6.7262 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0133 - mean_absolute_percentage_error: 18.9542 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 8.6095 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0138 - mean_absolute_percentage_error: 19.4676 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 4.9171 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0132 - mean_absolute_percentage_error: 20.2937 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 8.6911 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 18.7299 - val_loss: 0.0122 - val_mean_absolute_percentage_error: 16.6296 - lr: 6.0653e-04\n",
      "Learning rate of the model:  0.00060653087\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0122 - mean_absolute_percentage_error: 16.6296\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0089 - mean_absolute_percentage_error: 13.0736\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 13ms/step - loss: 0.1812 - mean_absolute_percentage_error: 61.2695 - val_loss: 0.1257 - val_mean_absolute_percentage_error: 32.2151 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0891 - mean_absolute_percentage_error: 31.8531 - val_loss: 0.0804 - val_mean_absolute_percentage_error: 28.1993 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0580 - mean_absolute_percentage_error: 28.5213 - val_loss: 0.0571 - val_mean_absolute_percentage_error: 25.2644 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0431 - mean_absolute_percentage_error: 25.6827 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 14.9936 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0375 - mean_absolute_percentage_error: 26.1035 - val_loss: 0.0260 - val_mean_absolute_percentage_error: 12.8734 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0310 - mean_absolute_percentage_error: 25.4501 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 16.0130 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0263 - mean_absolute_percentage_error: 25.2215 - val_loss: 0.0201 - val_mean_absolute_percentage_error: 18.6393 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0227 - mean_absolute_percentage_error: 22.2361 - val_loss: 0.0204 - val_mean_absolute_percentage_error: 12.7429 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0198 - mean_absolute_percentage_error: 23.8056 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 8.4427 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0204 - mean_absolute_percentage_error: 23.9462 - val_loss: 0.0144 - val_mean_absolute_percentage_error: 4.8805 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0169 - mean_absolute_percentage_error: 19.8301 - val_loss: 0.0126 - val_mean_absolute_percentage_error: 18.3471 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0158 - mean_absolute_percentage_error: 20.9221 - val_loss: 0.0166 - val_mean_absolute_percentage_error: 12.5279 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0144 - mean_absolute_percentage_error: 20.1784 - val_loss: 0.0110 - val_mean_absolute_percentage_error: 6.4774 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0139 - mean_absolute_percentage_error: 17.8862 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 11.9038 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0143 - mean_absolute_percentage_error: 21.9351 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 8.4803 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0136 - mean_absolute_percentage_error: 20.7917 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 14.5747 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0125 - mean_absolute_percentage_error: 18.6551 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 12.4174 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0122 - mean_absolute_percentage_error: 19.7673 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 12.1422 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0109 - mean_absolute_percentage_error: 16.4115 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 8.4034 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0108 - mean_absolute_percentage_error: 18.0486 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 11.3384 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0106 - mean_absolute_percentage_error: 18.2397 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 5.7424 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0104 - mean_absolute_percentage_error: 20.3041 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 7.3928 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 18.1428 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 7.9238 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 18.4010 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 7.6411 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 16.4314 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 10.5863 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 16.5274 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 9.0779 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 18.0829 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 6.8732 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 17.3732 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 4.8475 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 19.8561 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 4.5026 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 15.0502 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 4.8080 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 17.4515 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.8579 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 17.7423 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 2.2710 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 17.1092 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 5.4209 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 17.2156 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 10.0039 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 17.8381 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 11.6348 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0072 - mean_absolute_percentage_error: 17.2773 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 8.8328 - lr: 2.4660e-04\n",
      "Learning rate of the model:  0.00024659716\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.8328\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.1901\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 6s 12ms/step - loss: 0.1831 - mean_absolute_percentage_error: 64.4255 - val_loss: 0.1484 - val_mean_absolute_percentage_error: 29.1439 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0892 - mean_absolute_percentage_error: 31.1223 - val_loss: 0.1007 - val_mean_absolute_percentage_error: 35.5797 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0585 - mean_absolute_percentage_error: 25.6727 - val_loss: 0.0676 - val_mean_absolute_percentage_error: 21.4085 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0441 - mean_absolute_percentage_error: 28.2718 - val_loss: 0.0439 - val_mean_absolute_percentage_error: 23.3731 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0372 - mean_absolute_percentage_error: 29.5791 - val_loss: 0.0319 - val_mean_absolute_percentage_error: 21.2804 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0292 - mean_absolute_percentage_error: 26.7130 - val_loss: 0.0223 - val_mean_absolute_percentage_error: 23.0506 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0263 - mean_absolute_percentage_error: 32.6076 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 9.4316 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0259 - mean_absolute_percentage_error: 31.1518 - val_loss: 0.0196 - val_mean_absolute_percentage_error: 13.6139 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0212 - mean_absolute_percentage_error: 21.0002 - val_loss: 0.0210 - val_mean_absolute_percentage_error: 18.5368 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0175 - mean_absolute_percentage_error: 22.6956 - val_loss: 0.0175 - val_mean_absolute_percentage_error: 11.9751 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0159 - mean_absolute_percentage_error: 24.3926 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 18.4630 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0174 - mean_absolute_percentage_error: 26.7800 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 7.9350 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0139 - mean_absolute_percentage_error: 20.1452 - val_loss: 0.0145 - val_mean_absolute_percentage_error: 10.1351 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0148 - mean_absolute_percentage_error: 25.3308 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 12.1549 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0133 - mean_absolute_percentage_error: 19.8491 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 8.4240 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0131 - mean_absolute_percentage_error: 21.2699 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 6.8288 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0127 - mean_absolute_percentage_error: 20.9129 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 8.6363 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 17.2398 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 2.8916 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0119 - mean_absolute_percentage_error: 19.9624 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 15.9143 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0107 - mean_absolute_percentage_error: 18.7488 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 8.2764 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0105 - mean_absolute_percentage_error: 22.2245 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 6.1444 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0103 - mean_absolute_percentage_error: 24.0465 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 7.3288 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0098 - mean_absolute_percentage_error: 20.5477 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 6.6030 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0098 - mean_absolute_percentage_error: 17.1871 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 4.6754 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0096 - mean_absolute_percentage_error: 17.9683 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 8.5893 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0091 - mean_absolute_percentage_error: 17.6718 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.2868 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0088 - mean_absolute_percentage_error: 18.8228 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 5.7699 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0083 - mean_absolute_percentage_error: 18.1604 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 5.4016 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 20.0301 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 6.4286 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 20.4504 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.9468 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0079 - mean_absolute_percentage_error: 16.1847 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.2952 - lr: 3.1664e-04\n",
      "Learning rate of the model:  0.000316637\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0063 - mean_absolute_percentage_error: 4.2952\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0060 - mean_absolute_percentage_error: 13.3986\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 14ms/step - loss: 0.1700 - mean_absolute_percentage_error: 52.6781 - val_loss: 0.1158 - val_mean_absolute_percentage_error: 29.6533 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0891 - mean_absolute_percentage_error: 29.4012 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 27.7019 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 3s 10ms/step - loss: 0.0537 - mean_absolute_percentage_error: 23.6923 - val_loss: 0.0442 - val_mean_absolute_percentage_error: 23.4199 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0401 - mean_absolute_percentage_error: 30.1925 - val_loss: 0.0385 - val_mean_absolute_percentage_error: 25.8236 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0367 - mean_absolute_percentage_error: 27.1046 - val_loss: 0.0250 - val_mean_absolute_percentage_error: 9.4279 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0265 - mean_absolute_percentage_error: 28.7767 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 11.3544 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0236 - mean_absolute_percentage_error: 22.1144 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 14.4710 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0229 - mean_absolute_percentage_error: 23.9986 - val_loss: 0.0165 - val_mean_absolute_percentage_error: 15.1691 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0199 - mean_absolute_percentage_error: 22.2120 - val_loss: 0.0163 - val_mean_absolute_percentage_error: 18.6603 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0169 - mean_absolute_percentage_error: 20.7444 - val_loss: 0.0145 - val_mean_absolute_percentage_error: 12.0706 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0156 - mean_absolute_percentage_error: 22.1299 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 7.7655 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0161 - mean_absolute_percentage_error: 23.5983 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 12.7533 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0161 - mean_absolute_percentage_error: 24.1199 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 13.7669 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0151 - mean_absolute_percentage_error: 21.0565 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 7.8824 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0146 - mean_absolute_percentage_error: 22.4214 - val_loss: 0.0132 - val_mean_absolute_percentage_error: 11.1061 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0121 - mean_absolute_percentage_error: 18.8150 - val_loss: 0.0089 - val_mean_absolute_percentage_error: 3.8423 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0130 - mean_absolute_percentage_error: 20.9171 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 7.0206 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0132 - mean_absolute_percentage_error: 19.9001 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 15.4669 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0117 - mean_absolute_percentage_error: 18.6525 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 3.8771 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 19.3530 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 10.0161 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0102 - mean_absolute_percentage_error: 17.6320 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 12.2432 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0108 - mean_absolute_percentage_error: 18.2815 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 3.9280 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0101 - mean_absolute_percentage_error: 17.8631 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 8.5928 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 3s 10ms/step - loss: 0.0098 - mean_absolute_percentage_error: 16.6929 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 7.6081 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 17.2240 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 8.5215 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 16.3321 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 6.2122 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 18.2208 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 7.3221 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 18.8573 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 5.4680 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0084 - mean_absolute_percentage_error: 16.8129 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 3.8791 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0081 - mean_absolute_percentage_error: 15.4427 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 6.1880 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0082 - mean_absolute_percentage_error: 17.5761 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 4.1128 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0080 - mean_absolute_percentage_error: 16.5902 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 2.8457 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0079 - mean_absolute_percentage_error: 16.4961 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 6.3665 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0079 - mean_absolute_percentage_error: 15.0830 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 5.6264 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0073 - mean_absolute_percentage_error: 16.2942 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 7.9702 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 15.9206 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.9975 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0070 - mean_absolute_percentage_error: 15.2536 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.3201 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 16.6455 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 3.6040 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0069 - mean_absolute_percentage_error: 15.6126 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 3.4098 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 15.1317 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 5.4206 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 15.6243 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 6.4965 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0070 - mean_absolute_percentage_error: 15.7998 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 7.3194 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0067 - mean_absolute_percentage_error: 15.4466 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 13.7107 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0065 - mean_absolute_percentage_error: 13.7107\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_absolute_percentage_error: 24.4801\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 7s 14ms/step - loss: 0.1832 - mean_absolute_percentage_error: 45.8702 - val_loss: 0.1260 - val_mean_absolute_percentage_error: 22.8883 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0892 - mean_absolute_percentage_error: 30.4471 - val_loss: 0.0789 - val_mean_absolute_percentage_error: 15.9010 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0591 - mean_absolute_percentage_error: 24.4500 - val_loss: 0.0548 - val_mean_absolute_percentage_error: 14.2042 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0431 - mean_absolute_percentage_error: 29.2900 - val_loss: 0.0559 - val_mean_absolute_percentage_error: 20.8872 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0387 - mean_absolute_percentage_error: 23.5533 - val_loss: 0.0300 - val_mean_absolute_percentage_error: 13.3185 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0296 - mean_absolute_percentage_error: 24.1798 - val_loss: 0.0294 - val_mean_absolute_percentage_error: 24.3838 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0266 - mean_absolute_percentage_error: 24.7374 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 14.4525 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0210 - mean_absolute_percentage_error: 19.4671 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 20.2656 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0194 - mean_absolute_percentage_error: 16.6255 - val_loss: 0.0237 - val_mean_absolute_percentage_error: 15.7940 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0179 - mean_absolute_percentage_error: 21.2271 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 11.5397 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0166 - mean_absolute_percentage_error: 21.0655 - val_loss: 0.0159 - val_mean_absolute_percentage_error: 8.5125 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0174 - mean_absolute_percentage_error: 20.8878 - val_loss: 0.0138 - val_mean_absolute_percentage_error: 15.3891 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0157 - mean_absolute_percentage_error: 20.2257 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 3.4039 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0140 - mean_absolute_percentage_error: 19.1718 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 14.1516 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0130 - mean_absolute_percentage_error: 19.2133 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 9.2597 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0134 - mean_absolute_percentage_error: 20.1849 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 8.6323 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0123 - mean_absolute_percentage_error: 19.3013 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 6.6728 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0122 - mean_absolute_percentage_error: 18.0639 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 5.6099 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0115 - mean_absolute_percentage_error: 17.8104 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 5.7620 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0107 - mean_absolute_percentage_error: 19.6154 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 7.2399 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0101 - mean_absolute_percentage_error: 18.2198 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 6.7137 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0106 - mean_absolute_percentage_error: 17.9448 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 3.0651 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0099 - mean_absolute_percentage_error: 19.4036 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 2.9515 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.3413 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 13.0592 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0096 - mean_absolute_percentage_error: 17.8434 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 8.9705 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0089 - mean_absolute_percentage_error: 17.5065 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 8.1786 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 19.1367 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 7.0631 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0083 - mean_absolute_percentage_error: 17.5875 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 7.2994 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0081 - mean_absolute_percentage_error: 16.8423 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 9.6403 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 17.5910 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 13.7862 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0077 - mean_absolute_percentage_error: 17.2460 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 8.6527 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 17.0274 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 3.9032 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0077 - mean_absolute_percentage_error: 16.0084 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 9.0233 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 16.1845 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 7.6091 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0072 - mean_absolute_percentage_error: 17.7728 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 3.6602 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 17.4083 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 8.4250 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0069 - mean_absolute_percentage_error: 16.0792 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 6.0759 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 15.9968 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 7.6261 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0067 - mean_absolute_percentage_error: 16.8437 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 7.4722 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 17.1125 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 7.6007 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0065 - mean_absolute_percentage_error: 16.3600 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 7.0640 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0065 - mean_absolute_percentage_error: 16.5802 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 6.5461 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0065 - mean_absolute_percentage_error: 16.7984 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 7.6007 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 18.3605 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 8.4260 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "360/360 [==============================] - 3s 9ms/step - loss: 0.0064 - mean_absolute_percentage_error: 17.7804 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 9.1532 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 17.4263 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 9.1084 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0059 - mean_absolute_percentage_error: 17.5281 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 7.4210 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0061 - mean_absolute_percentage_error: 17.3929 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 11.5523 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 16.5455 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 7.5598 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 17.9414 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 8.5501 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0063 - mean_absolute_percentage_error: 19.1795 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 10.4118 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0058 - mean_absolute_percentage_error: 16.6408 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 7.8075 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0057 - mean_absolute_percentage_error: 16.8925 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 9.1389 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0057 - mean_absolute_percentage_error: 16.6319 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 7.1261 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0056 - mean_absolute_percentage_error: 15.8068 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 10.0027 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0057 - mean_absolute_percentage_error: 17.6954 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 11.8849 - lr: 2.0190e-04\n",
      "Epoch 57/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0057 - mean_absolute_percentage_error: 17.2424 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 11.9297 - lr: 2.0190e-04\n",
      "Epoch 58/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0058 - mean_absolute_percentage_error: 16.6033 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 9.7221 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0052 - mean_absolute_percentage_error: 9.7221\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0044 - mean_absolute_percentage_error: 11.4331\n",
      "Epoch 1/60\n",
      "360/360 [==============================] - 8s 13ms/step - loss: 0.1767 - mean_absolute_percentage_error: 50.8058 - val_loss: 0.1194 - val_mean_absolute_percentage_error: 48.0515 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0758 - mean_absolute_percentage_error: 31.0748 - val_loss: 0.0751 - val_mean_absolute_percentage_error: 32.8937 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0553 - mean_absolute_percentage_error: 30.3172 - val_loss: 0.0543 - val_mean_absolute_percentage_error: 34.9605 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0453 - mean_absolute_percentage_error: 27.9000 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 19.6649 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0317 - mean_absolute_percentage_error: 21.7052 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 19.1690 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0297 - mean_absolute_percentage_error: 23.3511 - val_loss: 0.0385 - val_mean_absolute_percentage_error: 26.3951 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0294 - mean_absolute_percentage_error: 26.3436 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 8.2568 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0222 - mean_absolute_percentage_error: 21.7968 - val_loss: 0.0186 - val_mean_absolute_percentage_error: 12.7697 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "360/360 [==============================] - 5s 14ms/step - loss: 0.0207 - mean_absolute_percentage_error: 21.5221 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 17.2282 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0201 - mean_absolute_percentage_error: 19.6667 - val_loss: 0.0143 - val_mean_absolute_percentage_error: 6.1241 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0178 - mean_absolute_percentage_error: 20.2268 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 7.8741 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0173 - mean_absolute_percentage_error: 21.0455 - val_loss: 0.0179 - val_mean_absolute_percentage_error: 15.4563 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0151 - mean_absolute_percentage_error: 17.1007 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 9.9372 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0148 - mean_absolute_percentage_error: 19.6711 - val_loss: 0.0148 - val_mean_absolute_percentage_error: 17.1918 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0139 - mean_absolute_percentage_error: 20.1188 - val_loss: 0.0168 - val_mean_absolute_percentage_error: 19.8742 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0141 - mean_absolute_percentage_error: 18.9482 - val_loss: 0.0108 - val_mean_absolute_percentage_error: 5.5107 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0141 - mean_absolute_percentage_error: 24.1750 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 5.2464 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0134 - mean_absolute_percentage_error: 19.0014 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 9.8984 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0129 - mean_absolute_percentage_error: 19.2141 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 14.7307 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0122 - mean_absolute_percentage_error: 19.2345 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 4.8108 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0112 - mean_absolute_percentage_error: 18.3360 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 14.2732 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0108 - mean_absolute_percentage_error: 18.3359 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 6.6972 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0107 - mean_absolute_percentage_error: 18.6517 - val_loss: 0.0119 - val_mean_absolute_percentage_error: 13.8876 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 17.9760 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 7.3942 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 19.4694 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 12.0050 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0094 - mean_absolute_percentage_error: 17.0533 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 5.3365 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 17.7771 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 13.9819 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 20.7746 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 7.5976 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0090 - mean_absolute_percentage_error: 17.3499 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 10.7700 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.6745 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 10.5113 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 16.3948 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 10.3630 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0082 - mean_absolute_percentage_error: 16.7768 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 16.0061 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 19.0557 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 9.0716 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 15.8042 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 12.6674 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 17.0214 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 13.8810 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0076 - mean_absolute_percentage_error: 17.2120 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 18.3569 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 19.1574 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 10.0190 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0081 - mean_absolute_percentage_error: 16.6413 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 11.2939 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "360/360 [==============================] - 4s 12ms/step - loss: 0.0073 - mean_absolute_percentage_error: 17.2626 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 15.1760 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 16.1832 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 14.7262 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 17.7808 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 13.5929 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 18.0565 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 17.8315 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "360/360 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 16.0798 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 12.1422 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "360/360 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 17.3312 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 12.3910 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 16.0679 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 13.2944 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "360/360 [==============================] - 5s 14ms/step - loss: 0.0068 - mean_absolute_percentage_error: 16.2418 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 11.2514 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 17.5938 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 14.6231 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0070 - mean_absolute_percentage_error: 14.6231\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0060 - mean_absolute_percentage_error: 12.3593\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 7s 14ms/step - loss: 0.2115 - mean_absolute_percentage_error: 79.9930 - val_loss: 0.1143 - val_mean_absolute_percentage_error: 102.5393 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0828 - mean_absolute_percentage_error: 44.6749 - val_loss: 0.0696 - val_mean_absolute_percentage_error: 77.6030 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0534 - mean_absolute_percentage_error: 34.7733 - val_loss: 0.0499 - val_mean_absolute_percentage_error: 46.5107 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0378 - mean_absolute_percentage_error: 33.0852 - val_loss: 0.0391 - val_mean_absolute_percentage_error: 40.4783 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0298 - mean_absolute_percentage_error: 30.5836 - val_loss: 0.0291 - val_mean_absolute_percentage_error: 36.2365 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0234 - mean_absolute_percentage_error: 27.9528 - val_loss: 0.0204 - val_mean_absolute_percentage_error: 39.6067 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0204 - mean_absolute_percentage_error: 28.3014 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 34.6247 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0178 - mean_absolute_percentage_error: 29.2109 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 19.3580 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0152 - mean_absolute_percentage_error: 23.9847 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 22.9248 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0140 - mean_absolute_percentage_error: 25.7655 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 42.1746 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0128 - mean_absolute_percentage_error: 24.1220 - val_loss: 0.0160 - val_mean_absolute_percentage_error: 31.6128 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0122 - mean_absolute_percentage_error: 22.9518 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 17.1619 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0111 - mean_absolute_percentage_error: 22.9798 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 15.2434 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 22.0233 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 15.5623 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0100 - mean_absolute_percentage_error: 23.7154 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 13.8338 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 23.1777 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 15.7954 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0090 - mean_absolute_percentage_error: 24.1546 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 16.8838 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 22.4780 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 19.6908 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0088 - mean_absolute_percentage_error: 27.1649 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 14.3430 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 25.7996 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 21.0813 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0081 - mean_absolute_percentage_error: 26.1813 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 21.1193 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0083 - mean_absolute_percentage_error: 27.8992 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 21.6901 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 25.5997 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 23.0186 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0078 - mean_absolute_percentage_error: 22.0273 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 14.0235 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 28.1990 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 15.8944 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 22.3286 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 15.7280 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 24.0382 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 13.6254 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 21.2103 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 16.2815 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 25.9324 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 17.3783 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 25.2891 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 14.5947 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0064 - mean_absolute_percentage_error: 21.8594 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 15.4283 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 21.7792 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 15.4495 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0064 - mean_absolute_percentage_error: 25.3485 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 16.6585 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 24.4637 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 11.8598 - lr: 2.7253e-04\n",
      "Learning rate of the model:  0.000272532\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0058 - mean_absolute_percentage_error: 11.8598\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.0113 - mean_absolute_percentage_error: 25.0511\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 7s 15ms/step - loss: 0.1739 - mean_absolute_percentage_error: 85.4931 - val_loss: 0.1110 - val_mean_absolute_percentage_error: 64.2712 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0733 - mean_absolute_percentage_error: 42.2939 - val_loss: 0.0586 - val_mean_absolute_percentage_error: 29.3638 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0511 - mean_absolute_percentage_error: 34.2920 - val_loss: 0.0383 - val_mean_absolute_percentage_error: 30.0328 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0350 - mean_absolute_percentage_error: 34.6105 - val_loss: 0.0314 - val_mean_absolute_percentage_error: 21.8589 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0273 - mean_absolute_percentage_error: 31.8790 - val_loss: 0.0229 - val_mean_absolute_percentage_error: 18.0857 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0230 - mean_absolute_percentage_error: 28.2406 - val_loss: 0.0193 - val_mean_absolute_percentage_error: 39.0000 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0194 - mean_absolute_percentage_error: 27.2166 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 22.1829 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0194 - mean_absolute_percentage_error: 31.8290 - val_loss: 0.0142 - val_mean_absolute_percentage_error: 17.4482 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0164 - mean_absolute_percentage_error: 26.7950 - val_loss: 0.0160 - val_mean_absolute_percentage_error: 24.4399 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0145 - mean_absolute_percentage_error: 24.9235 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 16.7439 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0136 - mean_absolute_percentage_error: 28.6704 - val_loss: 0.0125 - val_mean_absolute_percentage_error: 20.8160 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0132 - mean_absolute_percentage_error: 26.9944 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 22.0099 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0126 - mean_absolute_percentage_error: 24.7739 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 22.3053 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0117 - mean_absolute_percentage_error: 26.6133 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 21.7267 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 26.1853 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 17.4804 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0103 - mean_absolute_percentage_error: 23.1678 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 15.7701 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0099 - mean_absolute_percentage_error: 24.4712 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 14.0730 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0096 - mean_absolute_percentage_error: 24.6622 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 19.3073 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0095 - mean_absolute_percentage_error: 25.3263 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 18.0001 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0091 - mean_absolute_percentage_error: 22.5888 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 17.8681 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 24.5800 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 14.5907 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0093 - mean_absolute_percentage_error: 25.3238 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 18.9512 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0082 - mean_absolute_percentage_error: 23.8810 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 13.9579 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0080 - mean_absolute_percentage_error: 22.5521 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 19.7714 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0074 - mean_absolute_percentage_error: 22.7220 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 18.5815 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0079 - mean_absolute_percentage_error: 21.4418 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 20.7294 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 24.2799 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 13.5177 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0074 - mean_absolute_percentage_error: 20.0526 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 16.5060 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 22.6116 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 12.7257 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 21.3948 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 19.7923 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0069 - mean_absolute_percentage_error: 22.7481 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 12.6033 - lr: 3.1664e-04\n",
      "Learning rate of the model:  0.000316637\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0062 - mean_absolute_percentage_error: 12.6033\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0127 - mean_absolute_percentage_error: 68.3691\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 7s 14ms/step - loss: 0.4138 - mean_absolute_percentage_error: 81.3096 - val_loss: 0.4747 - val_mean_absolute_percentage_error: 71.1211 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.2067 - mean_absolute_percentage_error: 50.8437 - val_loss: 0.2624 - val_mean_absolute_percentage_error: 58.8359 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.1195 - mean_absolute_percentage_error: 39.6720 - val_loss: 0.1522 - val_mean_absolute_percentage_error: 67.3227 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0760 - mean_absolute_percentage_error: 38.7429 - val_loss: 0.0919 - val_mean_absolute_percentage_error: 29.6234 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0506 - mean_absolute_percentage_error: 34.2406 - val_loss: 0.0585 - val_mean_absolute_percentage_error: 23.0167 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0351 - mean_absolute_percentage_error: 30.3054 - val_loss: 0.0391 - val_mean_absolute_percentage_error: 30.1652 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0275 - mean_absolute_percentage_error: 26.4689 - val_loss: 0.0296 - val_mean_absolute_percentage_error: 26.5020 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0216 - mean_absolute_percentage_error: 29.9326 - val_loss: 0.0241 - val_mean_absolute_percentage_error: 43.5409 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0198 - mean_absolute_percentage_error: 28.9982 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 19.2819 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0155 - mean_absolute_percentage_error: 26.3276 - val_loss: 0.0159 - val_mean_absolute_percentage_error: 18.7808 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0145 - mean_absolute_percentage_error: 28.7803 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 20.1725 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0141 - mean_absolute_percentage_error: 29.7029 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 29.8593 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0123 - mean_absolute_percentage_error: 31.1727 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 26.9416 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0109 - mean_absolute_percentage_error: 29.6243 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 30.7060 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0110 - mean_absolute_percentage_error: 26.3120 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 18.8185 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0095 - mean_absolute_percentage_error: 29.0838 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 28.6439 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0105 - mean_absolute_percentage_error: 27.7279 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 23.1829 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0088 - mean_absolute_percentage_error: 24.5246 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 21.6566 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0097 - mean_absolute_percentage_error: 26.4780 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 21.3637 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0089 - mean_absolute_percentage_error: 25.7457 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 19.9720 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0083 - mean_absolute_percentage_error: 28.8880 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 18.8915 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 23.7334 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 15.3970 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 21.9690 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 23.4117 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0075 - mean_absolute_percentage_error: 24.8747 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 22.6407 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 28.4581 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 20.6907 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 23.5382 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 28.7714 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 20.1962 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 28.5841 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0069 - mean_absolute_percentage_error: 20.7992 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 19.6023 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 21.3965 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 15.3489 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 22.2273 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 19.9841 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 24.1418 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 16.5994 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0065 - mean_absolute_percentage_error: 25.0964 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 19.6814 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0065 - mean_absolute_percentage_error: 24.4945 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 17.3070 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 24.2160 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 23.1607 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0061 - mean_absolute_percentage_error: 21.2580 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 19.8862 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 21.9744 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 20.1436 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0061 - mean_absolute_percentage_error: 22.3236 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.8704 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0059 - mean_absolute_percentage_error: 21.3996 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 16.5344 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 24.2558 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.6782 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0059 - mean_absolute_percentage_error: 21.2227 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 18.6153 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0059 - mean_absolute_percentage_error: 22.5725 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 14.2324 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0059 - mean_absolute_percentage_error: 22.4268 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 29.2010 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 19.8335 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 15.5429 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.2664 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 19.4996 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.4156 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 16.1790 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0057 - mean_absolute_percentage_error: 22.6994 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 13.8564 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0058 - mean_absolute_percentage_error: 23.3380 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 13.8549 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.4425 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 16.1537 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0050 - mean_absolute_percentage_error: 16.1537\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0107 - mean_absolute_percentage_error: 28.3933\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 6s 13ms/step - loss: 0.1835 - mean_absolute_percentage_error: 66.4173 - val_loss: 0.1211 - val_mean_absolute_percentage_error: 56.6899 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0732 - mean_absolute_percentage_error: 39.6700 - val_loss: 0.0691 - val_mean_absolute_percentage_error: 48.2461 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0468 - mean_absolute_percentage_error: 30.5100 - val_loss: 0.0490 - val_mean_absolute_percentage_error: 41.2581 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0343 - mean_absolute_percentage_error: 42.0544 - val_loss: 0.0389 - val_mean_absolute_percentage_error: 34.0934 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0264 - mean_absolute_percentage_error: 33.2810 - val_loss: 0.0314 - val_mean_absolute_percentage_error: 30.3042 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0239 - mean_absolute_percentage_error: 31.4424 - val_loss: 0.0204 - val_mean_absolute_percentage_error: 26.1619 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0188 - mean_absolute_percentage_error: 26.6049 - val_loss: 0.0171 - val_mean_absolute_percentage_error: 28.0650 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0163 - mean_absolute_percentage_error: 26.6367 - val_loss: 0.0174 - val_mean_absolute_percentage_error: 23.8626 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0156 - mean_absolute_percentage_error: 26.1568 - val_loss: 0.0122 - val_mean_absolute_percentage_error: 26.9548 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0141 - mean_absolute_percentage_error: 25.3551 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 24.7177 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0144 - mean_absolute_percentage_error: 24.6653 - val_loss: 0.0143 - val_mean_absolute_percentage_error: 35.6400 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 24.6247 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 18.8783 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0118 - mean_absolute_percentage_error: 25.6648 - val_loss: 0.0129 - val_mean_absolute_percentage_error: 22.7954 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0115 - mean_absolute_percentage_error: 25.0941 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 20.1747 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0111 - mean_absolute_percentage_error: 23.8255 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 13.0727 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0105 - mean_absolute_percentage_error: 24.4790 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 23.2793 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0101 - mean_absolute_percentage_error: 24.9856 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 24.1819 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0093 - mean_absolute_percentage_error: 22.6196 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 16.4728 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0094 - mean_absolute_percentage_error: 21.8937 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 18.5836 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0091 - mean_absolute_percentage_error: 22.1506 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 18.2580 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0091 - mean_absolute_percentage_error: 27.7472 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 17.1302 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0086 - mean_absolute_percentage_error: 22.0748 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 22.0858 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0083 - mean_absolute_percentage_error: 20.7163 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 17.9335 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 21.0720 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 23.9044 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0078 - mean_absolute_percentage_error: 22.2134 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 18.5790 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0079 - mean_absolute_percentage_error: 22.1269 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 19.9089 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0081 - mean_absolute_percentage_error: 22.5929 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 16.4342 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0074 - mean_absolute_percentage_error: 23.3446 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 17.6568 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0075 - mean_absolute_percentage_error: 21.4767 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 13.0714 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 19.2521 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 16.8656 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 21.1014 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 16.6025 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0071 - mean_absolute_percentage_error: 21.2026 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 14.3776 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 20.7113 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 11.9564 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 22.3046 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 16.5204 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 19.3531 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 16.0168 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0065 - mean_absolute_percentage_error: 19.2067 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 15.6044 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0065 - mean_absolute_percentage_error: 22.0219 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 18.3366 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 21.0349 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 14.6836 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 19.3152 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 13.2345 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0062 - mean_absolute_percentage_error: 19.8638 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 12.8263 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0063 - mean_absolute_percentage_error: 22.3473 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 14.7958 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 20.1084 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 13.9968 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 19.9926 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 14.9639 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 20.3798 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 13.1699 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 20.3042 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 16.1790 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 19.1686 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 13.7576 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0061 - mean_absolute_percentage_error: 21.0394 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 15.7609 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 21.4723 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 14.0219 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0060 - mean_absolute_percentage_error: 19.8236 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.6508 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0060 - mean_absolute_percentage_error: 21.6203 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 16.5496 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0060 - mean_absolute_percentage_error: 22.0313 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 14.7417 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 21.2567 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.9960 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 21.5145 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 14.7301 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 20.0754 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 17.0824 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 24.0387 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.3995 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 23.2417 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 13.5909 - lr: 2.0190e-04\n",
      "Epoch 57/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 19.9767 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 15.2197 - lr: 2.0190e-04\n",
      "Epoch 58/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 23.3278 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 16.2252 - lr: 2.0190e-04\n",
      "Epoch 59/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 23.0285 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 14.4697 - lr: 2.0190e-04\n",
      "Epoch 60/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 20.3403 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 13.3495 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0055 - mean_absolute_percentage_error: 13.3495\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0113 - mean_absolute_percentage_error: 67.1587\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 8s 15ms/step - loss: 0.1679 - mean_absolute_percentage_error: 62.9233 - val_loss: 0.0941 - val_mean_absolute_percentage_error: 80.2204 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.0678 - mean_absolute_percentage_error: 48.7621 - val_loss: 0.0551 - val_mean_absolute_percentage_error: 69.3925 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0428 - mean_absolute_percentage_error: 33.8075 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 47.0204 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0308 - mean_absolute_percentage_error: 38.1968 - val_loss: 0.0261 - val_mean_absolute_percentage_error: 23.5400 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0254 - mean_absolute_percentage_error: 33.7053 - val_loss: 0.0213 - val_mean_absolute_percentage_error: 42.0307 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0206 - mean_absolute_percentage_error: 27.4723 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 35.9125 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0188 - mean_absolute_percentage_error: 26.5984 - val_loss: 0.0145 - val_mean_absolute_percentage_error: 37.2536 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.0168 - mean_absolute_percentage_error: 29.5079 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 35.5760 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.0147 - mean_absolute_percentage_error: 24.5097 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 25.3890 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0130 - mean_absolute_percentage_error: 26.6292 - val_loss: 0.0166 - val_mean_absolute_percentage_error: 32.4279 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0138 - mean_absolute_percentage_error: 26.7470 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 25.5292 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0123 - mean_absolute_percentage_error: 28.0078 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 15.5410 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0118 - mean_absolute_percentage_error: 24.3660 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 25.0919 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 24.7777 - val_loss: 0.0144 - val_mean_absolute_percentage_error: 37.7255 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0110 - mean_absolute_percentage_error: 28.6983 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 17.2133 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0096 - mean_absolute_percentage_error: 24.1513 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 16.4460 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 25.5612 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 17.2343 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0103 - mean_absolute_percentage_error: 24.2186 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 16.7925 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 25.6683 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 19.4162 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 22.0823 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 14.7849 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 25.2328 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 12.0266 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 26.5689 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 15.6855 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0081 - mean_absolute_percentage_error: 23.0562 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 12.9038 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 23.3756 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 28.4013 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 22.3663 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 12.7313 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 22.4262 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 15.7632 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 21.9206 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 27.3314 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 24.8793 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 16.4724 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0078 - mean_absolute_percentage_error: 26.4309 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 14.2209 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 22.3241 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 22.2147 - lr: 3.3287e-04\n",
      "Learning rate of the model:  0.0003328713\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0070 - mean_absolute_percentage_error: 22.2147\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_absolute_percentage_error: 62.2152\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 6s 12ms/step - loss: 0.1846 - mean_absolute_percentage_error: 52.6451 - val_loss: 0.1027 - val_mean_absolute_percentage_error: 39.5672 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0705 - mean_absolute_percentage_error: 35.4107 - val_loss: 0.0599 - val_mean_absolute_percentage_error: 30.5442 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0448 - mean_absolute_percentage_error: 33.3821 - val_loss: 0.0520 - val_mean_absolute_percentage_error: 42.1203 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0347 - mean_absolute_percentage_error: 28.9963 - val_loss: 0.0278 - val_mean_absolute_percentage_error: 24.9963 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0253 - mean_absolute_percentage_error: 29.3851 - val_loss: 0.0205 - val_mean_absolute_percentage_error: 16.8257 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0245 - mean_absolute_percentage_error: 31.9792 - val_loss: 0.0216 - val_mean_absolute_percentage_error: 22.0744 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0195 - mean_absolute_percentage_error: 30.5422 - val_loss: 0.0371 - val_mean_absolute_percentage_error: 45.9670 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0179 - mean_absolute_percentage_error: 28.5912 - val_loss: 0.0234 - val_mean_absolute_percentage_error: 57.7935 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0157 - mean_absolute_percentage_error: 27.0731 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 26.4168 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0146 - mean_absolute_percentage_error: 24.4415 - val_loss: 0.0119 - val_mean_absolute_percentage_error: 30.0616 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0138 - mean_absolute_percentage_error: 27.3482 - val_loss: 0.0120 - val_mean_absolute_percentage_error: 19.1715 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0119 - mean_absolute_percentage_error: 26.1204 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 35.2192 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0121 - mean_absolute_percentage_error: 26.9548 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 22.7376 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 27.5445 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 51.2807 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 26.1479 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 34.8257 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0105 - mean_absolute_percentage_error: 26.1638 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 20.4628 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0102 - mean_absolute_percentage_error: 25.2470 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 19.1806 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0102 - mean_absolute_percentage_error: 25.5318 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 24.0639 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0091 - mean_absolute_percentage_error: 26.8201 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 30.0969 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0090 - mean_absolute_percentage_error: 22.1881 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 45.5172 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0092 - mean_absolute_percentage_error: 23.8713 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 18.2855 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 26.5781 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 21.6764 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 24.8474 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 18.6315 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0079 - mean_absolute_percentage_error: 23.0990 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 39.6425 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0080 - mean_absolute_percentage_error: 24.8039 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 44.0880 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0083 - mean_absolute_percentage_error: 44.0880\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0161 - mean_absolute_percentage_error: 95.2052\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 7s 14ms/step - loss: 0.1900 - mean_absolute_percentage_error: 61.6933 - val_loss: 0.1301 - val_mean_absolute_percentage_error: 81.5105 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0822 - mean_absolute_percentage_error: 44.4188 - val_loss: 0.0751 - val_mean_absolute_percentage_error: 49.3075 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0541 - mean_absolute_percentage_error: 36.4609 - val_loss: 0.0552 - val_mean_absolute_percentage_error: 31.4329 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0379 - mean_absolute_percentage_error: 31.7023 - val_loss: 0.0358 - val_mean_absolute_percentage_error: 29.3126 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0290 - mean_absolute_percentage_error: 31.5622 - val_loss: 0.0250 - val_mean_absolute_percentage_error: 44.0110 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0235 - mean_absolute_percentage_error: 28.6030 - val_loss: 0.0212 - val_mean_absolute_percentage_error: 32.3450 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0197 - mean_absolute_percentage_error: 28.4992 - val_loss: 0.0158 - val_mean_absolute_percentage_error: 36.7863 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0176 - mean_absolute_percentage_error: 28.7422 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 35.8239 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0175 - mean_absolute_percentage_error: 30.1548 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 25.9423 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0152 - mean_absolute_percentage_error: 28.3043 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 29.2907 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0142 - mean_absolute_percentage_error: 30.0061 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 21.1332 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 28.5811 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 26.2362 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0113 - mean_absolute_percentage_error: 26.2282 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 20.1948 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0114 - mean_absolute_percentage_error: 28.5801 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 19.0136 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0103 - mean_absolute_percentage_error: 28.0722 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 22.8356 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0102 - mean_absolute_percentage_error: 28.5677 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 36.3307 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0100 - mean_absolute_percentage_error: 23.7168 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 25.2416 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 24.7724 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 15.8467 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0091 - mean_absolute_percentage_error: 21.5532 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 19.5883 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0089 - mean_absolute_percentage_error: 25.8351 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 19.8168 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0088 - mean_absolute_percentage_error: 24.8898 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 14.1463 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 25.4919 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 15.9933 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0078 - mean_absolute_percentage_error: 25.9296 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 20.7127 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0079 - mean_absolute_percentage_error: 27.6191 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 25.3008 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 22.6918 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 22.5236 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0074 - mean_absolute_percentage_error: 23.5486 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 13.6955 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 24.5159 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 16.3785 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0070 - mean_absolute_percentage_error: 26.0320 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 16.8065 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 22.5178 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 18.6712 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 22.1541 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 14.7920 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0067 - mean_absolute_percentage_error: 23.5228 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 16.6521 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0066 - mean_absolute_percentage_error: 24.2118 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 14.6644 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 22.9722 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 17.1082 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0064 - mean_absolute_percentage_error: 21.9284 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 17.6056 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 23.6906 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 17.7166 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0062 - mean_absolute_percentage_error: 22.5963 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 23.5673 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0060 - mean_absolute_percentage_error: 22.1756 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 18.8036 - lr: 2.3457e-04\n",
      "Learning rate of the model:  0.00023457049\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 5ms/step - loss: 0.0064 - mean_absolute_percentage_error: 18.8035\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0122 - mean_absolute_percentage_error: 47.8579\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 6s 11ms/step - loss: 0.1674 - mean_absolute_percentage_error: 53.5692 - val_loss: 0.1029 - val_mean_absolute_percentage_error: 49.1780 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0684 - mean_absolute_percentage_error: 32.5378 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 28.7093 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0432 - mean_absolute_percentage_error: 32.1148 - val_loss: 0.0440 - val_mean_absolute_percentage_error: 27.8784 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0318 - mean_absolute_percentage_error: 37.7457 - val_loss: 0.0340 - val_mean_absolute_percentage_error: 42.8304 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0249 - mean_absolute_percentage_error: 31.5065 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 32.2311 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0228 - mean_absolute_percentage_error: 33.4368 - val_loss: 0.0231 - val_mean_absolute_percentage_error: 33.5854 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0190 - mean_absolute_percentage_error: 33.1527 - val_loss: 0.0191 - val_mean_absolute_percentage_error: 24.9018 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0176 - mean_absolute_percentage_error: 36.4370 - val_loss: 0.0138 - val_mean_absolute_percentage_error: 20.7807 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0149 - mean_absolute_percentage_error: 26.7907 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 24.9430 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0151 - mean_absolute_percentage_error: 24.9168 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 23.8014 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 31.1221 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 35.9341 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0129 - mean_absolute_percentage_error: 31.2102 - val_loss: 0.0191 - val_mean_absolute_percentage_error: 67.3464 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0120 - mean_absolute_percentage_error: 27.3319 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 16.8989 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 25.2605 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 31.2240 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0114 - mean_absolute_percentage_error: 30.2587 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 33.0689 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 25.1621 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 18.4491 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0109 - mean_absolute_percentage_error: 26.7076 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 16.2398 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 25.6306 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 15.3118 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0097 - mean_absolute_percentage_error: 24.5154 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 18.1170 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 25.3428 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 14.8549 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 22.5306 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 14.8183 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 26.9009 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 19.4476 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 22.1021 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 13.8026 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 21.7945 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 12.8865 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 21.2631 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 28.2948 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 21.8526 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 19.0810 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 23.3466 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 20.3272 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 21.6788 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 18.2205 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 21.0041 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 13.8967 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.0077 - mean_absolute_percentage_error: 22.9738 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 17.6577 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 22.1495 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 33.1438 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 21.8916 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 13.2630 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 21.6229 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 13.3629 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 22.2653 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 14.3044 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 22.5923 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 23.0753 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 21.5989 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 14.7049 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0068 - mean_absolute_percentage_error: 22.8774 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 13.0495 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 22.0800 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 20.5111 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 21.9362 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 14.5012 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 19.9817 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 16.5726 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 22.3308 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 12.5376 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 21.6605 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 13.0007 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 22.4981 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 25.6833 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 21.6092 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 16.0383 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 20.3089 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 20.7644 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_absolute_percentage_error: 20.7644\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0111 - mean_absolute_percentage_error: 48.0903\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 7s 15ms/step - loss: 0.1668 - mean_absolute_percentage_error: 86.5537 - val_loss: 0.1149 - val_mean_absolute_percentage_error: 44.4034 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0779 - mean_absolute_percentage_error: 39.4888 - val_loss: 0.0705 - val_mean_absolute_percentage_error: 50.0616 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0505 - mean_absolute_percentage_error: 37.0446 - val_loss: 0.0520 - val_mean_absolute_percentage_error: 44.1853 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0359 - mean_absolute_percentage_error: 31.0688 - val_loss: 0.0371 - val_mean_absolute_percentage_error: 27.0505 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0290 - mean_absolute_percentage_error: 32.6281 - val_loss: 0.0223 - val_mean_absolute_percentage_error: 19.4782 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0233 - mean_absolute_percentage_error: 34.3805 - val_loss: 0.0258 - val_mean_absolute_percentage_error: 43.3144 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0202 - mean_absolute_percentage_error: 27.5009 - val_loss: 0.0269 - val_mean_absolute_percentage_error: 24.4547 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0172 - mean_absolute_percentage_error: 24.5347 - val_loss: 0.0190 - val_mean_absolute_percentage_error: 38.2650 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0160 - mean_absolute_percentage_error: 30.2745 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 16.2637 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0157 - mean_absolute_percentage_error: 29.0671 - val_loss: 0.0152 - val_mean_absolute_percentage_error: 14.2425 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0130 - mean_absolute_percentage_error: 25.8821 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 21.9673 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0125 - mean_absolute_percentage_error: 26.5761 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 15.0868 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0125 - mean_absolute_percentage_error: 26.1637 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 15.1958 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0108 - mean_absolute_percentage_error: 23.1219 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 17.0439 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 5s 12ms/step - loss: 0.0111 - mean_absolute_percentage_error: 24.0512 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 18.8894 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0102 - mean_absolute_percentage_error: 27.1707 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 19.7989 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0100 - mean_absolute_percentage_error: 25.5179 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 11.8716 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0094 - mean_absolute_percentage_error: 22.4253 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 24.0556 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0089 - mean_absolute_percentage_error: 25.0613 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 14.4042 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 23.5512 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 14.7216 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 23.7043 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 21.2095 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 25.0998 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 20.4819 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 19.6485 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 11.8900 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 21.9997 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 12.1855 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 22.4560 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 15.0430 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0073 - mean_absolute_percentage_error: 23.4455 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 15.7020 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 24.9186 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 14.9463 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 21.9722 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 15.4975 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 21.7561 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 14.4078 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0070 - mean_absolute_percentage_error: 22.8492 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 14.2035 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0068 - mean_absolute_percentage_error: 21.3672 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 17.0128 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 22.0487 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 15.1785 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0064 - mean_absolute_percentage_error: 21.1355 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 19.1887 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 21.0427 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 14.4545 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 23.2685 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 25.3115 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 19.6584 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 11.3113 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 20.9324 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 15.5366 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 20.6665 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 23.4037 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 21.1188 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 19.2655 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 21.0067 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 14.2638 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 21.6773 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 13.3032 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 22.0117 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 16.4546 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 19.9253 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 9.9636 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 20.8115 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 11.2659 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 19.4798 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 14.8121 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.6740 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 28.3290 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 23.0524 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 11.9291 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 20.0054 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 16.2763 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.6375 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 12.9260 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 20.2463 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 13.0110 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 20.1789 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 11.8523 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 22.1123 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 11.9119 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 19.6590 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 18.7589 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 21.4366 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 16.1372 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 21.7050 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 16.6550 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0050 - mean_absolute_percentage_error: 16.6550\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.0110 - mean_absolute_percentage_error: 42.5961\n",
      "Epoch 1/60\n",
      "363/363 [==============================] - 6s 11ms/step - loss: 0.1979 - mean_absolute_percentage_error: 67.3531 - val_loss: 0.1390 - val_mean_absolute_percentage_error: 73.3287 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0901 - mean_absolute_percentage_error: 42.9816 - val_loss: 0.0756 - val_mean_absolute_percentage_error: 36.5721 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0578 - mean_absolute_percentage_error: 35.4117 - val_loss: 0.0593 - val_mean_absolute_percentage_error: 34.5914 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0418 - mean_absolute_percentage_error: 34.5085 - val_loss: 0.0405 - val_mean_absolute_percentage_error: 48.0559 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0347 - mean_absolute_percentage_error: 33.4336 - val_loss: 0.0275 - val_mean_absolute_percentage_error: 57.0971 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0255 - mean_absolute_percentage_error: 35.4088 - val_loss: 0.0237 - val_mean_absolute_percentage_error: 33.2007 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0224 - mean_absolute_percentage_error: 32.0701 - val_loss: 0.0206 - val_mean_absolute_percentage_error: 27.9522 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0189 - mean_absolute_percentage_error: 29.4947 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 48.0359 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.0179 - mean_absolute_percentage_error: 29.8216 - val_loss: 0.0162 - val_mean_absolute_percentage_error: 29.2955 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0154 - mean_absolute_percentage_error: 30.6628 - val_loss: 0.0167 - val_mean_absolute_percentage_error: 41.3174 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0141 - mean_absolute_percentage_error: 29.1417 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 33.7076 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0129 - mean_absolute_percentage_error: 25.3640 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 19.9409 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0120 - mean_absolute_percentage_error: 26.7768 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 29.7657 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0122 - mean_absolute_percentage_error: 28.6898 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 20.1190 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0104 - mean_absolute_percentage_error: 24.2055 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 18.5683 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 22.7866 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 21.8171 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0100 - mean_absolute_percentage_error: 23.9829 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 30.6154 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.0097 - mean_absolute_percentage_error: 23.2673 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 27.2335 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0094 - mean_absolute_percentage_error: 21.5712 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 25.4614 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 23.3727 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 25.9130 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0084 - mean_absolute_percentage_error: 23.7815 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 17.7556 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0080 - mean_absolute_percentage_error: 20.7097 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 18.4591 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 23.7567 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 14.8605 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0081 - mean_absolute_percentage_error: 23.1231 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 35.3913 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 23.3458 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 14.7222 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 21.5244 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 17.6922 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 22.2277 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 14.9486 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.0071 - mean_absolute_percentage_error: 24.3537 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 17.5144 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0070 - mean_absolute_percentage_error: 21.3957 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 23.5705 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0069 - mean_absolute_percentage_error: 22.7736 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 12.7031 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.0066 - mean_absolute_percentage_error: 23.5572 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 16.4578 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.0068 - mean_absolute_percentage_error: 21.8352 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 17.9574 - lr: 3.0119e-04\n",
      "Learning rate of the model:  0.00030119444\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0070 - mean_absolute_percentage_error: 17.9574\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0121 - mean_absolute_percentage_error: 36.6993\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 8s 15ms/step - loss: 0.1822 - mean_absolute_percentage_error: 39.9068 - val_loss: 0.1174 - val_mean_absolute_percentage_error: 19.0183 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 4s 13ms/step - loss: 0.0775 - mean_absolute_percentage_error: 27.4008 - val_loss: 0.0695 - val_mean_absolute_percentage_error: 14.8149 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0593 - mean_absolute_percentage_error: 22.6247 - val_loss: 0.0410 - val_mean_absolute_percentage_error: 9.4446 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0380 - mean_absolute_percentage_error: 21.5730 - val_loss: 0.0317 - val_mean_absolute_percentage_error: 8.1515 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0291 - mean_absolute_percentage_error: 16.9294 - val_loss: 0.0234 - val_mean_absolute_percentage_error: 5.8975 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0240 - mean_absolute_percentage_error: 23.7462 - val_loss: 0.0204 - val_mean_absolute_percentage_error: 7.8812 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0259 - mean_absolute_percentage_error: 22.3458 - val_loss: 0.0155 - val_mean_absolute_percentage_error: 4.7160 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0191 - mean_absolute_percentage_error: 18.1510 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 7.1134 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0191 - mean_absolute_percentage_error: 22.6196 - val_loss: 0.0160 - val_mean_absolute_percentage_error: 9.6653 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0149 - mean_absolute_percentage_error: 19.7616 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 4.4137 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0145 - mean_absolute_percentage_error: 20.8279 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 4.2334 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0148 - mean_absolute_percentage_error: 19.7932 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 5.2286 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0124 - mean_absolute_percentage_error: 16.1937 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 6.4133 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0113 - mean_absolute_percentage_error: 14.1888 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 5.3303 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0112 - mean_absolute_percentage_error: 14.2860 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 3.8807 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0121 - mean_absolute_percentage_error: 14.2483 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 4.9830 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0100 - mean_absolute_percentage_error: 14.9812 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 3.2853 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0102 - mean_absolute_percentage_error: 13.3080 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 4.9119 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0096 - mean_absolute_percentage_error: 10.9407 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 3.0278 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.3623 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 2.6516 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0113 - mean_absolute_percentage_error: 14.1708 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 3.1183 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 9.7625 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 2.7071 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0082 - mean_absolute_percentage_error: 10.3004 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 2.8382 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 13.3520 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 3.0129 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0078 - mean_absolute_percentage_error: 10.0987 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 4.2684 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0078 - mean_absolute_percentage_error: 8.8946 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.1946 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 10.8902 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 2.7736 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 12.2622 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 5.3969 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0074 - mean_absolute_percentage_error: 11.1345 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.6468 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 12.2660 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.7184 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0071 - mean_absolute_percentage_error: 11.4937 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 4.4737 - lr: 3.1664e-04\n",
      "Learning rate of the model:  0.000316637\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0060 - mean_absolute_percentage_error: 4.4737\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0176 - mean_absolute_percentage_error: 13.1481\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 14ms/step - loss: 0.1681 - mean_absolute_percentage_error: 41.9330 - val_loss: 0.1070 - val_mean_absolute_percentage_error: 15.8076 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0780 - mean_absolute_percentage_error: 27.9156 - val_loss: 0.0656 - val_mean_absolute_percentage_error: 12.7852 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0551 - mean_absolute_percentage_error: 23.9311 - val_loss: 0.0420 - val_mean_absolute_percentage_error: 8.8991 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0378 - mean_absolute_percentage_error: 22.4661 - val_loss: 0.0368 - val_mean_absolute_percentage_error: 15.2609 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0305 - mean_absolute_percentage_error: 19.9843 - val_loss: 0.0258 - val_mean_absolute_percentage_error: 10.0137 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0254 - mean_absolute_percentage_error: 22.7467 - val_loss: 0.0189 - val_mean_absolute_percentage_error: 5.9584 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0221 - mean_absolute_percentage_error: 22.6192 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 8.0474 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0198 - mean_absolute_percentage_error: 30.2018 - val_loss: 0.0157 - val_mean_absolute_percentage_error: 6.1308 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0197 - mean_absolute_percentage_error: 23.8594 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 5.6396 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0167 - mean_absolute_percentage_error: 15.4624 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 4.7269 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0137 - mean_absolute_percentage_error: 14.3769 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 4.1775 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0127 - mean_absolute_percentage_error: 19.6354 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 5.5663 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0135 - mean_absolute_percentage_error: 16.8889 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 5.9974 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 14.9955 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 5.9057 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0132 - mean_absolute_percentage_error: 14.7154 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 7.8300 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0114 - mean_absolute_percentage_error: 11.6140 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 2.9707 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0103 - mean_absolute_percentage_error: 12.9912 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 4.2443 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0101 - mean_absolute_percentage_error: 11.2341 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 5.1719 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 11.5857 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 6.1969 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.8065 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 6.4513 - lr: 5.4881e-04\n",
      "Learning rate of the model:  0.00054881186\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0084 - mean_absolute_percentage_error: 6.4513\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0308 - mean_absolute_percentage_error: 18.4824\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 15ms/step - loss: 0.2454 - mean_absolute_percentage_error: 34.9923 - val_loss: 0.0878 - val_mean_absolute_percentage_error: 7.2598 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0787 - mean_absolute_percentage_error: 25.0136 - val_loss: 0.0521 - val_mean_absolute_percentage_error: 6.8135 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0515 - mean_absolute_percentage_error: 20.7299 - val_loss: 0.0364 - val_mean_absolute_percentage_error: 5.2405 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0390 - mean_absolute_percentage_error: 24.0246 - val_loss: 0.0281 - val_mean_absolute_percentage_error: 5.2089 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0325 - mean_absolute_percentage_error: 21.1996 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 4.3383 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0271 - mean_absolute_percentage_error: 23.0050 - val_loss: 0.0185 - val_mean_absolute_percentage_error: 3.7195 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0225 - mean_absolute_percentage_error: 19.8720 - val_loss: 0.0158 - val_mean_absolute_percentage_error: 3.7264 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0265 - mean_absolute_percentage_error: 23.5749 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 3.5501 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0188 - mean_absolute_percentage_error: 19.9968 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 5.4542 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0176 - mean_absolute_percentage_error: 15.8144 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 3.4805 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0161 - mean_absolute_percentage_error: 17.9392 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 6.0125 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0146 - mean_absolute_percentage_error: 12.4837 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 5.8718 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0154 - mean_absolute_percentage_error: 15.4072 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 3.7778 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0133 - mean_absolute_percentage_error: 15.9627 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 3.1870 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0124 - mean_absolute_percentage_error: 14.3307 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 3.6237 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0112 - mean_absolute_percentage_error: 11.9073 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 2.8331 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0141 - mean_absolute_percentage_error: 13.9177 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 3.1964 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0112 - mean_absolute_percentage_error: 11.1938 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 2.9705 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0106 - mean_absolute_percentage_error: 12.3116 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 4.7263 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0099 - mean_absolute_percentage_error: 9.6877 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 2.7836 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0096 - mean_absolute_percentage_error: 9.8703 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 3.9703 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0105 - mean_absolute_percentage_error: 11.8342 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 3.2450 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0094 - mean_absolute_percentage_error: 10.9136 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 4.2038 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0089 - mean_absolute_percentage_error: 9.9218 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 3.4920 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0085 - mean_absolute_percentage_error: 11.1995 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 2.6270 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0086 - mean_absolute_percentage_error: 11.5450 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 3.8067 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.6627 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 3.0107 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.8978 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 2.8899 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 10.9592 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.1393 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.8966 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.0083 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0077 - mean_absolute_percentage_error: 10.2549 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 4.1913 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0077 - mean_absolute_percentage_error: 10.0690 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 2.6821 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0073 - mean_absolute_percentage_error: 9.0913 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 3.1812 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0073 - mean_absolute_percentage_error: 8.9293 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 4.3185 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0075 - mean_absolute_percentage_error: 10.0117 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 3.0486 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 9.1690 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 4.2127 - lr: 2.4660e-04\n",
      "Learning rate of the model:  0.00024659716\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0059 - mean_absolute_percentage_error: 4.2127\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0203 - mean_absolute_percentage_error: 14.4917\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 6s 12ms/step - loss: 0.2032 - mean_absolute_percentage_error: 54.4420 - val_loss: 0.1456 - val_mean_absolute_percentage_error: 27.1193 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.1014 - mean_absolute_percentage_error: 21.6094 - val_loss: 0.0953 - val_mean_absolute_percentage_error: 19.4461 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0681 - mean_absolute_percentage_error: 22.8952 - val_loss: 0.0642 - val_mean_absolute_percentage_error: 15.1432 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0516 - mean_absolute_percentage_error: 22.3487 - val_loss: 0.0424 - val_mean_absolute_percentage_error: 9.1411 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0376 - mean_absolute_percentage_error: 27.0315 - val_loss: 0.0293 - val_mean_absolute_percentage_error: 8.2021 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0316 - mean_absolute_percentage_error: 18.4917 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 5.7808 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0269 - mean_absolute_percentage_error: 18.3118 - val_loss: 0.0194 - val_mean_absolute_percentage_error: 6.5493 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0220 - mean_absolute_percentage_error: 20.5785 - val_loss: 0.0164 - val_mean_absolute_percentage_error: 5.3265 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0194 - mean_absolute_percentage_error: 23.1988 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 9.9394 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0184 - mean_absolute_percentage_error: 20.2411 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 6.6270 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0175 - mean_absolute_percentage_error: 22.0633 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 3.9331 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0176 - mean_absolute_percentage_error: 23.5467 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 5.0751 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0161 - mean_absolute_percentage_error: 17.7181 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 3.9424 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0139 - mean_absolute_percentage_error: 12.7312 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 4.4342 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0118 - mean_absolute_percentage_error: 11.6782 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 4.4869 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0131 - mean_absolute_percentage_error: 16.0119 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 3.9817 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0127 - mean_absolute_percentage_error: 16.2859 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 3.3797 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0104 - mean_absolute_percentage_error: 12.8332 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 3.0485 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 14.0837 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 3.0425 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0094 - mean_absolute_percentage_error: 11.6378 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 3.7233 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0089 - mean_absolute_percentage_error: 14.1352 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 4.5612 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0087 - mean_absolute_percentage_error: 11.2605 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 4.2941 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0087 - mean_absolute_percentage_error: 17.0263 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 3.4263 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0086 - mean_absolute_percentage_error: 12.6831 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.1351 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.3935 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 4.3274 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0080 - mean_absolute_percentage_error: 11.3794 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.2215 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 12.6253 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.1398 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 9.7523 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.2872 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 11.4467 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 2.8038 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0070 - mean_absolute_percentage_error: 13.3287 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 2.8596 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0070 - mean_absolute_percentage_error: 12.2016 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 3.4643 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.9863 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 4.3992 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.7793 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 4.0852 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0064 - mean_absolute_percentage_error: 9.0594 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 2.6969 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.3562 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.1046 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0063 - mean_absolute_percentage_error: 9.0715 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 4.7231 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 12.3105 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 4.2104 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0077 - mean_absolute_percentage_error: 14.4256 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 4.5391 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0060 - mean_absolute_percentage_error: 9.4873 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 4.3503 - lr: 2.1225e-04\n",
      "Learning rate of the model:  0.00021224817\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0053 - mean_absolute_percentage_error: 4.3503\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0202 - mean_absolute_percentage_error: 14.7160\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 14ms/step - loss: 0.1764 - mean_absolute_percentage_error: 45.3023 - val_loss: 0.1152 - val_mean_absolute_percentage_error: 18.2922 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0822 - mean_absolute_percentage_error: 27.1995 - val_loss: 0.0779 - val_mean_absolute_percentage_error: 17.3333 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0539 - mean_absolute_percentage_error: 27.4816 - val_loss: 0.0526 - val_mean_absolute_percentage_error: 13.3384 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0449 - mean_absolute_percentage_error: 29.6983 - val_loss: 0.0420 - val_mean_absolute_percentage_error: 13.2452 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0317 - mean_absolute_percentage_error: 26.2713 - val_loss: 0.0302 - val_mean_absolute_percentage_error: 9.9186 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0256 - mean_absolute_percentage_error: 21.4354 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 9.8843 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0212 - mean_absolute_percentage_error: 24.7330 - val_loss: 0.0217 - val_mean_absolute_percentage_error: 10.2316 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0215 - mean_absolute_percentage_error: 22.1949 - val_loss: 0.0160 - val_mean_absolute_percentage_error: 6.3193 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0182 - mean_absolute_percentage_error: 20.4721 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 6.5530 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0156 - mean_absolute_percentage_error: 17.5792 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 5.2732 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0165 - mean_absolute_percentage_error: 19.7010 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 12.9984 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0145 - mean_absolute_percentage_error: 15.8387 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 6.9511 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0131 - mean_absolute_percentage_error: 18.1329 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 8.7315 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 13.9626 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 6.5537 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0166 - mean_absolute_percentage_error: 16.0771 - val_loss: 0.0103 - val_mean_absolute_percentage_error: 5.6641 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0121 - mean_absolute_percentage_error: 14.4910 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 12.6170 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 16.2556 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 5.7480 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0108 - mean_absolute_percentage_error: 14.1821 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 8.6137 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0099 - mean_absolute_percentage_error: 12.2538 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 6.1642 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0092 - mean_absolute_percentage_error: 15.0986 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 6.3827 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0102 - mean_absolute_percentage_error: 15.8117 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 5.3132 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0090 - mean_absolute_percentage_error: 11.1511 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 4.9998 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0094 - mean_absolute_percentage_error: 13.3896 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 6.2347 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 3s 10ms/step - loss: 0.0087 - mean_absolute_percentage_error: 12.3995 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 7.5590 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0084 - mean_absolute_percentage_error: 14.2480 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 5.5713 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0086 - mean_absolute_percentage_error: 12.1447 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 8.5622 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0081 - mean_absolute_percentage_error: 12.7326 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 6.7216 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0076 - mean_absolute_percentage_error: 12.1225 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 6.0433 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 9.5418 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 5.0516 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0074 - mean_absolute_percentage_error: 10.9351 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 8.2950 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0072 - mean_absolute_percentage_error: 12.9419 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 7.2087 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0068 - mean_absolute_percentage_error: 10.5753 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 5.7899 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0070 - mean_absolute_percentage_error: 12.2465 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.3734 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 3s 9ms/step - loss: 0.0067 - mean_absolute_percentage_error: 11.1274 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 6.4487 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0067 - mean_absolute_percentage_error: 11.7185 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 6.0296 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0064 - mean_absolute_percentage_error: 8.4938 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 5.0977 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0064 - mean_absolute_percentage_error: 9.8385 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 5.1151 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 10.9932 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 4.4496 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 10.5584 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 5.5421 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0061 - mean_absolute_percentage_error: 10.2528 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.6664 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0060 - mean_absolute_percentage_error: 9.6537 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 5.2909 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.8929 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 6.0870 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0068 - mean_absolute_percentage_error: 6.0870\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0301 - mean_absolute_percentage_error: 19.0299\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 14ms/step - loss: 0.2282 - mean_absolute_percentage_error: 47.1996 - val_loss: 0.1020 - val_mean_absolute_percentage_error: 11.1388 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0833 - mean_absolute_percentage_error: 25.2738 - val_loss: 0.0635 - val_mean_absolute_percentage_error: 10.2385 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0541 - mean_absolute_percentage_error: 21.6384 - val_loss: 0.0417 - val_mean_absolute_percentage_error: 7.8109 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0388 - mean_absolute_percentage_error: 22.0864 - val_loss: 0.0282 - val_mean_absolute_percentage_error: 5.0500 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0358 - mean_absolute_percentage_error: 18.1362 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 8.7592 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0277 - mean_absolute_percentage_error: 19.1842 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 13.5830 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0285 - mean_absolute_percentage_error: 20.3025 - val_loss: 0.0177 - val_mean_absolute_percentage_error: 5.1958 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0211 - mean_absolute_percentage_error: 17.4741 - val_loss: 0.0139 - val_mean_absolute_percentage_error: 3.4262 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0202 - mean_absolute_percentage_error: 16.3401 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 4.3734 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0174 - mean_absolute_percentage_error: 13.8537 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 3.7013 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0155 - mean_absolute_percentage_error: 15.9811 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 4.2577 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0136 - mean_absolute_percentage_error: 12.1707 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 6.1657 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0134 - mean_absolute_percentage_error: 14.7213 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 3.5566 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0171 - mean_absolute_percentage_error: 17.2694 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 6.2291 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0133 - mean_absolute_percentage_error: 14.6537 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 5.0134 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0115 - mean_absolute_percentage_error: 12.0034 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 4.3848 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0111 - mean_absolute_percentage_error: 16.5978 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 6.8324 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0113 - mean_absolute_percentage_error: 16.0342 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 4.2134 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 13.5486 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 3.4380 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0094 - mean_absolute_percentage_error: 16.1225 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 4.3869 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0088 - mean_absolute_percentage_error: 13.5381 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 3.2789 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 13.3128 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 5.0383 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.9030 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 3.8444 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 13.1674 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 3.2854 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 11.6859 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 4.5986 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0082 - mean_absolute_percentage_error: 11.1538 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 3.0945 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 9.7519 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 4.2788 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 10.4971 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 3.6461 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 9.9473 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 2.9629 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0076 - mean_absolute_percentage_error: 9.5711 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 2.7602 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 4s 11ms/step - loss: 0.0069 - mean_absolute_percentage_error: 8.9100 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 3.7026 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.0111 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 2.5427 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 4s 10ms/step - loss: 0.0072 - mean_absolute_percentage_error: 9.0490 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 3.5952 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0068 - mean_absolute_percentage_error: 9.9289 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 5.7358 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 9.9134 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 2.9583 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0068 - mean_absolute_percentage_error: 10.2643 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 2.9134 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.2286 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 4.6947 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0064 - mean_absolute_percentage_error: 8.2614 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.2855 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0064 - mean_absolute_percentage_error: 8.2246 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.4328 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0068 - mean_absolute_percentage_error: 9.2733 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.1480 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 9.3346 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 3.2161 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 9.1275 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 2.3743 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 7.5621 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.7291 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.5159 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 3.1971 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.0036 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 2.3789 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 8.6759 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 2.0213 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 10.5500 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 3.0145 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 8.4926 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 2.1689 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 9.1289 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 2.5500 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 8.5916 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 3.1313 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 7.9762 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 3.1162 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 10.1623 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 3.9198 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0047 - mean_absolute_percentage_error: 3.9198\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_absolute_percentage_error: 12.2741\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 15ms/step - loss: 0.1997 - mean_absolute_percentage_error: 71.6165 - val_loss: 0.0973 - val_mean_absolute_percentage_error: 10.6630 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0809 - mean_absolute_percentage_error: 23.3706 - val_loss: 0.0578 - val_mean_absolute_percentage_error: 7.9069 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0603 - mean_absolute_percentage_error: 19.6571 - val_loss: 0.0406 - val_mean_absolute_percentage_error: 7.6544 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0407 - mean_absolute_percentage_error: 20.6678 - val_loss: 0.0319 - val_mean_absolute_percentage_error: 7.6653 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0312 - mean_absolute_percentage_error: 22.1434 - val_loss: 0.0254 - val_mean_absolute_percentage_error: 6.5461 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0257 - mean_absolute_percentage_error: 19.0634 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 6.9000 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0249 - mean_absolute_percentage_error: 23.4873 - val_loss: 0.0177 - val_mean_absolute_percentage_error: 6.9648 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0219 - mean_absolute_percentage_error: 19.9581 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 7.8684 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0218 - mean_absolute_percentage_error: 19.3231 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 3.7165 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0173 - mean_absolute_percentage_error: 15.5455 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 6.6119 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0149 - mean_absolute_percentage_error: 17.0483 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 3.8193 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0149 - mean_absolute_percentage_error: 16.1472 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 4.4508 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 14.3235 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 3.6102 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 14.0911 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 3.5240 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 13.1636 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 4.1695 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 17.7225 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 5.0170 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 13.1593 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 4.6263 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 14.1750 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 3.4603 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0094 - mean_absolute_percentage_error: 11.3344 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 5.1151 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0094 - mean_absolute_percentage_error: 13.3819 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 3.7963 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 13.1677 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 3.8891 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 12.4299 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 3.5946 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0088 - mean_absolute_percentage_error: 11.3636 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.3243 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 9.5457 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 2.9043 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 8.9468 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 2.8569 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 11.6302 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 4.7267 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0077 - mean_absolute_percentage_error: 7.9891 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 4.4047 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 10.6307 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 4.3787 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 9.7556 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 3.6083 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.2476 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 3.8282 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 7.9788 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.7880 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 9.7999 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 2.6153 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.3928 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.3756 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 8.0692 - val_loss: 0.0047 - val_mean_absolute_percentage_error: 2.9105 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 8.6408 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.5403 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.7810 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 2.8358 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 7.7340 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 3.9395 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 8.5673 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 3.1574 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 8.1509 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 2.6453 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 8.2821 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 3.3748 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 8.8844 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 3.1667 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 7.7674 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 3.4284 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 8.2587 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 2.7918 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 8.8744 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 3.7423 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 7.4357 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.3032 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 8.4702 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 2.6921 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 8.6512 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.2272 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 9.8217 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 3.3196 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 8.0480 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 2.8428 - lr: 2.0190e-04\n",
      "Epoch 50/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 8.3176 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 2.8873 - lr: 2.0190e-04\n",
      "Epoch 51/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 8.6603 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 4.0872 - lr: 2.0190e-04\n",
      "Epoch 52/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 8.6853 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 3.1910 - lr: 2.0190e-04\n",
      "Epoch 53/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 7.8167 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 3.3084 - lr: 2.0190e-04\n",
      "Epoch 54/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 7.8287 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 3.3163 - lr: 2.0190e-04\n",
      "Epoch 55/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0051 - mean_absolute_percentage_error: 8.1546 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 2.6744 - lr: 2.0190e-04\n",
      "Epoch 56/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0052 - mean_absolute_percentage_error: 7.3741 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 2.8748 - lr: 2.0190e-04\n",
      "Epoch 57/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 8.5951 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 2.5241 - lr: 2.0190e-04\n",
      "Epoch 58/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 9.4108 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 3.8099 - lr: 2.0190e-04\n",
      "Epoch 59/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 9.4046 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 3.1464 - lr: 2.0190e-04\n",
      "Epoch 60/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0051 - mean_absolute_percentage_error: 11.9229 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 3.4642 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0039 - mean_absolute_percentage_error: 3.4642\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0135 - mean_absolute_percentage_error: 11.4696\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 8s 15ms/step - loss: 0.1700 - mean_absolute_percentage_error: 38.4003 - val_loss: 0.1313 - val_mean_absolute_percentage_error: 24.8448 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0783 - mean_absolute_percentage_error: 29.9251 - val_loss: 0.0818 - val_mean_absolute_percentage_error: 24.2912 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0525 - mean_absolute_percentage_error: 24.3762 - val_loss: 0.0483 - val_mean_absolute_percentage_error: 12.5065 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0377 - mean_absolute_percentage_error: 21.2415 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 13.8966 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0402 - mean_absolute_percentage_error: 26.2807 - val_loss: 0.0279 - val_mean_absolute_percentage_error: 10.3043 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0261 - mean_absolute_percentage_error: 19.5185 - val_loss: 0.0206 - val_mean_absolute_percentage_error: 5.6863 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0280 - mean_absolute_percentage_error: 22.0974 - val_loss: 0.0179 - val_mean_absolute_percentage_error: 5.1834 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0229 - mean_absolute_percentage_error: 18.0691 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 4.4331 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0212 - mean_absolute_percentage_error: 16.2993 - val_loss: 0.0137 - val_mean_absolute_percentage_error: 4.5740 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0187 - mean_absolute_percentage_error: 16.5421 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 6.2176 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0156 - mean_absolute_percentage_error: 16.0078 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 3.9005 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0155 - mean_absolute_percentage_error: 14.6688 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 3.4189 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0138 - mean_absolute_percentage_error: 14.6152 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 3.7914 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0136 - mean_absolute_percentage_error: 14.8766 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 2.6361 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0121 - mean_absolute_percentage_error: 14.5759 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 4.1120 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 17.0177 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 3.0548 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0107 - mean_absolute_percentage_error: 13.5837 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 3.8534 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 14.4634 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 4.6587 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0108 - mean_absolute_percentage_error: 13.6662 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 4.6983 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 13.2516 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 5.3954 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0097 - mean_absolute_percentage_error: 11.4915 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 4.0768 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 11.6367 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 4.4124 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.3025 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 4.0106 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 13.5854 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 5.6833 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.4344 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.1050 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 13.8800 - val_loss: 0.0073 - val_mean_absolute_percentage_error: 5.6376 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 13.1777 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 3.8852 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 10.3654 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 4.9971 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 14ms/step - loss: 0.0075 - mean_absolute_percentage_error: 9.7603 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.0767 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 10.4380 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.8237 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 8.0572 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.8853 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 9.7643 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 3.8810 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 10.0045 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 3.9991 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 10.6017 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 4.1504 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 10.3591 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 4.3149 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.0731 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 4.5204 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.4174 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 4.2866 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 11.4054 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 4.2122 - lr: 2.2313e-04\n",
      "Learning rate of the model:  0.00022313035\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0057 - mean_absolute_percentage_error: 4.2122\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0217 - mean_absolute_percentage_error: 15.4683\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 15ms/step - loss: 0.1885 - mean_absolute_percentage_error: 32.7033 - val_loss: 0.1506 - val_mean_absolute_percentage_error: 35.8901 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0810 - mean_absolute_percentage_error: 24.1987 - val_loss: 0.0682 - val_mean_absolute_percentage_error: 12.4662 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0546 - mean_absolute_percentage_error: 19.9529 - val_loss: 0.0664 - val_mean_absolute_percentage_error: 25.1119 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0419 - mean_absolute_percentage_error: 21.1600 - val_loss: 0.0330 - val_mean_absolute_percentage_error: 8.4567 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0334 - mean_absolute_percentage_error: 24.1203 - val_loss: 0.0235 - val_mean_absolute_percentage_error: 5.8778 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0324 - mean_absolute_percentage_error: 25.5336 - val_loss: 0.0202 - val_mean_absolute_percentage_error: 5.1363 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0237 - mean_absolute_percentage_error: 23.6017 - val_loss: 0.0193 - val_mean_absolute_percentage_error: 7.8156 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0202 - mean_absolute_percentage_error: 17.9220 - val_loss: 0.0153 - val_mean_absolute_percentage_error: 4.8784 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0212 - mean_absolute_percentage_error: 20.2656 - val_loss: 0.0162 - val_mean_absolute_percentage_error: 6.3828 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0191 - mean_absolute_percentage_error: 19.6485 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 5.1498 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0175 - mean_absolute_percentage_error: 19.9349 - val_loss: 0.0148 - val_mean_absolute_percentage_error: 10.0734 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0166 - mean_absolute_percentage_error: 21.3535 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 6.8081 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0146 - mean_absolute_percentage_error: 18.2773 - val_loss: 0.0104 - val_mean_absolute_percentage_error: 4.5565 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0130 - mean_absolute_percentage_error: 16.5685 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 6.7493 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0130 - mean_absolute_percentage_error: 19.7050 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 6.4602 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0122 - mean_absolute_percentage_error: 16.7445 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 4.6674 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0114 - mean_absolute_percentage_error: 14.3942 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 4.0752 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0107 - mean_absolute_percentage_error: 12.2425 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 4.8957 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0100 - mean_absolute_percentage_error: 14.4162 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 3.3012 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0110 - mean_absolute_percentage_error: 12.5278 - val_loss: 0.0082 - val_mean_absolute_percentage_error: 6.2308 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 13.2815 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 3.5092 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 14.5948 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 2.8975 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 13.5807 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 4.5858 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 10.5231 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 4.0070 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.6669 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 3.5631 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 11.4164 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 4.6621 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 10.0220 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 4.1827 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.9329 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 3.5806 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.7579 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 3.0333 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 10.1586 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 3.1459 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0074 - mean_absolute_percentage_error: 9.4070 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 3.1730 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 7.9398 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 2.9277 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 9.5215 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 2.9651 - lr: 2.8651e-04\n",
      "Epoch 34/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 11.5153 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 4.6617 - lr: 2.7253e-04\n",
      "Epoch 35/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0070 - mean_absolute_percentage_error: 11.1397 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 2.6708 - lr: 2.5924e-04\n",
      "Epoch 36/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 12.1313 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 4.1372 - lr: 2.4660e-04\n",
      "Epoch 37/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0070 - mean_absolute_percentage_error: 10.9519 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 4.1469 - lr: 2.3457e-04\n",
      "Epoch 38/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0068 - mean_absolute_percentage_error: 10.7428 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 3.2835 - lr: 2.2313e-04\n",
      "Epoch 39/60\n",
      "358/358 [==============================] - 4s 12ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.8866 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 3.0076 - lr: 2.1225e-04\n",
      "Epoch 40/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 10.8719 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 3.7747 - lr: 2.0190e-04\n",
      "Epoch 41/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 10.1302 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.3327 - lr: 2.0190e-04\n",
      "Epoch 42/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.0378 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 3.8088 - lr: 2.0190e-04\n",
      "Epoch 43/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 8.4977 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 2.9178 - lr: 2.0190e-04\n",
      "Epoch 44/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 10.4557 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 3.2993 - lr: 2.0190e-04\n",
      "Epoch 45/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 10.9207 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.7534 - lr: 2.0190e-04\n",
      "Epoch 46/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 9.7679 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 3.6989 - lr: 2.0190e-04\n",
      "Epoch 47/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 10.7814 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.6631 - lr: 2.0190e-04\n",
      "Epoch 48/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 9.3803 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 3.4929 - lr: 2.0190e-04\n",
      "Epoch 49/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 8.6609 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 5.1085 - lr: 2.0190e-04\n",
      "Learning rate of the model:  0.0002018967\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0055 - mean_absolute_percentage_error: 5.1085\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0214 - mean_absolute_percentage_error: 15.2885\n",
      "Epoch 1/60\n",
      "358/358 [==============================] - 7s 15ms/step - loss: 0.2660 - mean_absolute_percentage_error: 44.2574 - val_loss: 0.1127 - val_mean_absolute_percentage_error: 20.8505 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0798 - mean_absolute_percentage_error: 24.5935 - val_loss: 0.0582 - val_mean_absolute_percentage_error: 9.5638 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0504 - mean_absolute_percentage_error: 18.6857 - val_loss: 0.0387 - val_mean_absolute_percentage_error: 7.2288 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0367 - mean_absolute_percentage_error: 21.7115 - val_loss: 0.0304 - val_mean_absolute_percentage_error: 7.6619 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0332 - mean_absolute_percentage_error: 19.6659 - val_loss: 0.0254 - val_mean_absolute_percentage_error: 8.2497 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0256 - mean_absolute_percentage_error: 17.5844 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 5.4779 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0209 - mean_absolute_percentage_error: 16.0121 - val_loss: 0.0158 - val_mean_absolute_percentage_error: 5.2986 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0203 - mean_absolute_percentage_error: 16.6638 - val_loss: 0.0133 - val_mean_absolute_percentage_error: 5.1232 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0219 - mean_absolute_percentage_error: 21.3099 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 6.9771 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0173 - mean_absolute_percentage_error: 16.2064 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 4.4766 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0159 - mean_absolute_percentage_error: 17.3459 - val_loss: 0.0125 - val_mean_absolute_percentage_error: 6.5557 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0151 - mean_absolute_percentage_error: 13.1141 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 3.4869 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0137 - mean_absolute_percentage_error: 13.3400 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 6.0989 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0120 - mean_absolute_percentage_error: 10.3986 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 3.0933 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0119 - mean_absolute_percentage_error: 10.5116 - val_loss: 0.0087 - val_mean_absolute_percentage_error: 4.5056 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0120 - mean_absolute_percentage_error: 14.3492 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 4.2276 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0108 - mean_absolute_percentage_error: 12.9960 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 6.7963 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0113 - mean_absolute_percentage_error: 14.8176 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 3.4130 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 12.3096 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 3.3895 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 14.2942 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 3.0632 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 11.3137 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 3.0424 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 12.2423 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 4.9319 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0089 - mean_absolute_percentage_error: 10.4842 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 4.1574 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "358/358 [==============================] - 5s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 12.2724 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 4.4024 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0068 - mean_absolute_percentage_error: 4.4024\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0199 - mean_absolute_percentage_error: 13.8957\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1767 - mean_absolute_percentage_error: 53.1341 - val_loss: 0.2316 - val_mean_absolute_percentage_error: 34.2446 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0824 - mean_absolute_percentage_error: 32.3832 - val_loss: 0.1366 - val_mean_absolute_percentage_error: 24.6318 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0523 - mean_absolute_percentage_error: 24.1229 - val_loss: 0.0896 - val_mean_absolute_percentage_error: 20.1674 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0364 - mean_absolute_percentage_error: 21.2568 - val_loss: 0.0717 - val_mean_absolute_percentage_error: 19.3040 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0295 - mean_absolute_percentage_error: 24.1014 - val_loss: 0.0531 - val_mean_absolute_percentage_error: 16.7430 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0280 - mean_absolute_percentage_error: 23.8309 - val_loss: 0.0408 - val_mean_absolute_percentage_error: 13.6032 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0198 - mean_absolute_percentage_error: 22.4347 - val_loss: 0.0445 - val_mean_absolute_percentage_error: 15.9111 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0188 - mean_absolute_percentage_error: 24.1980 - val_loss: 0.0522 - val_mean_absolute_percentage_error: 18.3814 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0193 - mean_absolute_percentage_error: 23.3528 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 13.9303 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0167 - mean_absolute_percentage_error: 22.2538 - val_loss: 0.0489 - val_mean_absolute_percentage_error: 18.5181 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0152 - mean_absolute_percentage_error: 22.4734 - val_loss: 0.0311 - val_mean_absolute_percentage_error: 13.4260 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0139 - mean_absolute_percentage_error: 17.9865 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 11.5919 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0129 - mean_absolute_percentage_error: 19.0234 - val_loss: 0.0247 - val_mean_absolute_percentage_error: 11.1149 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0115 - mean_absolute_percentage_error: 18.3472 - val_loss: 0.0241 - val_mean_absolute_percentage_error: 11.3657 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0113 - mean_absolute_percentage_error: 17.8581 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 9.2572 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 17.1420 - val_loss: 0.0414 - val_mean_absolute_percentage_error: 16.4397 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0105 - mean_absolute_percentage_error: 16.4536 - val_loss: 0.0234 - val_mean_absolute_percentage_error: 11.7497 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0105 - mean_absolute_percentage_error: 16.9941 - val_loss: 0.0181 - val_mean_absolute_percentage_error: 9.3544 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 17.1179 - val_loss: 0.0174 - val_mean_absolute_percentage_error: 8.9571 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 15.7213 - val_loss: 0.0192 - val_mean_absolute_percentage_error: 9.7774 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 17.3409 - val_loss: 0.0201 - val_mean_absolute_percentage_error: 10.5807 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 16.1230 - val_loss: 0.0197 - val_mean_absolute_percentage_error: 10.4098 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 15.6603 - val_loss: 0.0316 - val_mean_absolute_percentage_error: 13.9312 - lr: 4.7237e-04\n",
      "Learning rate of the model:  0.00047236675\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0316 - mean_absolute_percentage_error: 13.9312\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0289 - mean_absolute_percentage_error: 14.3545\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 8s 16ms/step - loss: 0.1899 - mean_absolute_percentage_error: 50.0167 - val_loss: 0.2258 - val_mean_absolute_percentage_error: 32.7089 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0830 - mean_absolute_percentage_error: 32.4896 - val_loss: 0.1332 - val_mean_absolute_percentage_error: 24.3196 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0577 - mean_absolute_percentage_error: 29.8787 - val_loss: 0.0944 - val_mean_absolute_percentage_error: 20.7662 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0375 - mean_absolute_percentage_error: 26.1599 - val_loss: 0.0748 - val_mean_absolute_percentage_error: 20.3104 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0339 - mean_absolute_percentage_error: 28.2773 - val_loss: 0.0406 - val_mean_absolute_percentage_error: 11.9839 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0237 - mean_absolute_percentage_error: 24.3898 - val_loss: 0.0390 - val_mean_absolute_percentage_error: 13.0372 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0214 - mean_absolute_percentage_error: 24.9780 - val_loss: 0.0325 - val_mean_absolute_percentage_error: 11.8172 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0193 - mean_absolute_percentage_error: 23.6969 - val_loss: 0.0270 - val_mean_absolute_percentage_error: 10.7066 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0185 - mean_absolute_percentage_error: 24.5869 - val_loss: 0.0171 - val_mean_absolute_percentage_error: 8.0505 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0151 - mean_absolute_percentage_error: 19.7539 - val_loss: 0.0238 - val_mean_absolute_percentage_error: 10.2818 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0147 - mean_absolute_percentage_error: 20.8599 - val_loss: 0.0246 - val_mean_absolute_percentage_error: 11.1985 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 18.4635 - val_loss: 0.0216 - val_mean_absolute_percentage_error: 10.0325 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0136 - mean_absolute_percentage_error: 19.2950 - val_loss: 0.0199 - val_mean_absolute_percentage_error: 9.9336 - lr: 7.7880e-04\n",
      "Learning rate of the model:  0.0007788009\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0199 - mean_absolute_percentage_error: 9.9336\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0185 - mean_absolute_percentage_error: 9.6694\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1814 - mean_absolute_percentage_error: 61.4290 - val_loss: 0.2160 - val_mean_absolute_percentage_error: 31.4429 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0869 - mean_absolute_percentage_error: 34.4084 - val_loss: 0.1456 - val_mean_absolute_percentage_error: 26.6940 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0584 - mean_absolute_percentage_error: 26.8400 - val_loss: 0.0871 - val_mean_absolute_percentage_error: 19.4783 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0418 - mean_absolute_percentage_error: 24.2507 - val_loss: 0.0772 - val_mean_absolute_percentage_error: 19.7546 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0367 - mean_absolute_percentage_error: 24.8515 - val_loss: 0.0634 - val_mean_absolute_percentage_error: 17.9781 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0268 - mean_absolute_percentage_error: 24.3843 - val_loss: 0.0806 - val_mean_absolute_percentage_error: 23.5679 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0217 - mean_absolute_percentage_error: 23.6047 - val_loss: 0.0477 - val_mean_absolute_percentage_error: 16.0024 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0241 - mean_absolute_percentage_error: 23.0882 - val_loss: 0.0495 - val_mean_absolute_percentage_error: 16.7029 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0184 - mean_absolute_percentage_error: 23.0450 - val_loss: 0.0363 - val_mean_absolute_percentage_error: 13.2553 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0178 - mean_absolute_percentage_error: 20.9217 - val_loss: 0.0326 - val_mean_absolute_percentage_error: 12.9724 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0161 - mean_absolute_percentage_error: 19.2087 - val_loss: 0.0350 - val_mean_absolute_percentage_error: 13.8870 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0151 - mean_absolute_percentage_error: 20.1197 - val_loss: 0.0387 - val_mean_absolute_percentage_error: 15.8780 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0137 - mean_absolute_percentage_error: 18.1910 - val_loss: 0.0310 - val_mean_absolute_percentage_error: 13.3142 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0134 - mean_absolute_percentage_error: 18.7081 - val_loss: 0.0311 - val_mean_absolute_percentage_error: 13.3088 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 17.2410 - val_loss: 0.0288 - val_mean_absolute_percentage_error: 13.1130 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0117 - mean_absolute_percentage_error: 18.1865 - val_loss: 0.0311 - val_mean_absolute_percentage_error: 14.1028 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0109 - mean_absolute_percentage_error: 17.6589 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 13.4951 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 17.2517 - val_loss: 0.0200 - val_mean_absolute_percentage_error: 10.1523 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0105 - mean_absolute_percentage_error: 17.1651 - val_loss: 0.0208 - val_mean_absolute_percentage_error: 10.5945 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 18.2301 - val_loss: 0.0239 - val_mean_absolute_percentage_error: 11.9972 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0100 - mean_absolute_percentage_error: 18.1207 - val_loss: 0.0287 - val_mean_absolute_percentage_error: 13.3232 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 18.7737 - val_loss: 0.0247 - val_mean_absolute_percentage_error: 12.1261 - lr: 4.9659e-04\n",
      "Learning rate of the model:  0.0004965855\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0247 - mean_absolute_percentage_error: 12.1262\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0269 - mean_absolute_percentage_error: 13.7261\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1969 - mean_absolute_percentage_error: 54.2289 - val_loss: 0.1856 - val_mean_absolute_percentage_error: 24.4710 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0938 - mean_absolute_percentage_error: 29.8513 - val_loss: 0.1044 - val_mean_absolute_percentage_error: 16.7875 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0565 - mean_absolute_percentage_error: 25.1007 - val_loss: 0.0862 - val_mean_absolute_percentage_error: 18.1958 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0464 - mean_absolute_percentage_error: 28.8597 - val_loss: 0.0706 - val_mean_absolute_percentage_error: 18.1971 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0321 - mean_absolute_percentage_error: 22.3356 - val_loss: 0.0543 - val_mean_absolute_percentage_error: 15.7524 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0311 - mean_absolute_percentage_error: 24.8260 - val_loss: 0.0416 - val_mean_absolute_percentage_error: 13.4037 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0232 - mean_absolute_percentage_error: 23.1087 - val_loss: 0.0292 - val_mean_absolute_percentage_error: 10.0905 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0197 - mean_absolute_percentage_error: 20.3717 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 12.4862 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0210 - mean_absolute_percentage_error: 24.2263 - val_loss: 0.0306 - val_mean_absolute_percentage_error: 12.1215 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0177 - mean_absolute_percentage_error: 21.1692 - val_loss: 0.0361 - val_mean_absolute_percentage_error: 14.3282 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0150 - mean_absolute_percentage_error: 21.5859 - val_loss: 0.0313 - val_mean_absolute_percentage_error: 12.8399 - lr: 8.6071e-04\n",
      "Learning rate of the model:  0.00086070807\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0313 - mean_absolute_percentage_error: 12.8398\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0329 - mean_absolute_percentage_error: 14.2758\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 8s 15ms/step - loss: 0.1711 - mean_absolute_percentage_error: 44.2944 - val_loss: 0.1814 - val_mean_absolute_percentage_error: 26.2245 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0869 - mean_absolute_percentage_error: 27.7498 - val_loss: 0.1196 - val_mean_absolute_percentage_error: 21.2836 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0589 - mean_absolute_percentage_error: 27.0513 - val_loss: 0.0910 - val_mean_absolute_percentage_error: 19.6428 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0400 - mean_absolute_percentage_error: 23.4009 - val_loss: 0.0575 - val_mean_absolute_percentage_error: 14.4269 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0315 - mean_absolute_percentage_error: 26.2913 - val_loss: 0.0849 - val_mean_absolute_percentage_error: 22.1034 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0320 - mean_absolute_percentage_error: 30.4260 - val_loss: 0.0551 - val_mean_absolute_percentage_error: 16.6261 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0259 - mean_absolute_percentage_error: 26.2379 - val_loss: 0.0567 - val_mean_absolute_percentage_error: 17.8122 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0210 - mean_absolute_percentage_error: 24.9993 - val_loss: 0.0246 - val_mean_absolute_percentage_error: 9.1592 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0175 - mean_absolute_percentage_error: 23.2307 - val_loss: 0.0446 - val_mean_absolute_percentage_error: 15.8049 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0165 - mean_absolute_percentage_error: 23.3015 - val_loss: 0.0404 - val_mean_absolute_percentage_error: 15.0086 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0160 - mean_absolute_percentage_error: 23.5923 - val_loss: 0.0436 - val_mean_absolute_percentage_error: 16.2834 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0136 - mean_absolute_percentage_error: 21.2296 - val_loss: 0.0481 - val_mean_absolute_percentage_error: 17.8010 - lr: 8.1873e-04\n",
      "Learning rate of the model:  0.00081873086\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0481 - mean_absolute_percentage_error: 17.8009\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0562 - mean_absolute_percentage_error: 20.6089\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1708 - mean_absolute_percentage_error: 46.5780 - val_loss: 0.1827 - val_mean_absolute_percentage_error: 27.1670 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0819 - mean_absolute_percentage_error: 30.6198 - val_loss: 0.1043 - val_mean_absolute_percentage_error: 19.6588 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0518 - mean_absolute_percentage_error: 25.1414 - val_loss: 0.0711 - val_mean_absolute_percentage_error: 17.1254 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0475 - mean_absolute_percentage_error: 28.3366 - val_loss: 0.0605 - val_mean_absolute_percentage_error: 16.2190 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0297 - mean_absolute_percentage_error: 26.0967 - val_loss: 0.0525 - val_mean_absolute_percentage_error: 15.9807 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0275 - mean_absolute_percentage_error: 24.6483 - val_loss: 0.0408 - val_mean_absolute_percentage_error: 13.0336 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0212 - mean_absolute_percentage_error: 25.6858 - val_loss: 0.0278 - val_mean_absolute_percentage_error: 10.0689 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0216 - mean_absolute_percentage_error: 26.7153 - val_loss: 0.0340 - val_mean_absolute_percentage_error: 12.4819 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0187 - mean_absolute_percentage_error: 23.4399 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 14.7277 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0156 - mean_absolute_percentage_error: 19.5512 - val_loss: 0.0286 - val_mean_absolute_percentage_error: 12.1876 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0157 - mean_absolute_percentage_error: 20.8994 - val_loss: 0.0208 - val_mean_absolute_percentage_error: 9.6023 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0145 - mean_absolute_percentage_error: 19.2658 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 6.1948 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0125 - mean_absolute_percentage_error: 20.1036 - val_loss: 0.0334 - val_mean_absolute_percentage_error: 13.9525 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 17.7620 - val_loss: 0.0232 - val_mean_absolute_percentage_error: 10.9120 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0146 - mean_absolute_percentage_error: 19.8822 - val_loss: 0.0212 - val_mean_absolute_percentage_error: 9.8554 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0119 - mean_absolute_percentage_error: 16.9464 - val_loss: 0.0172 - val_mean_absolute_percentage_error: 8.4635 - lr: 6.7032e-04\n",
      "Learning rate of the model:  0.00067032024\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0172 - mean_absolute_percentage_error: 8.4635\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0169 - mean_absolute_percentage_error: 9.3243\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1934 - mean_absolute_percentage_error: 43.8065 - val_loss: 0.1865 - val_mean_absolute_percentage_error: 26.6316 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0856 - mean_absolute_percentage_error: 30.6274 - val_loss: 0.1185 - val_mean_absolute_percentage_error: 20.8684 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0554 - mean_absolute_percentage_error: 25.1484 - val_loss: 0.0725 - val_mean_absolute_percentage_error: 15.0499 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0420 - mean_absolute_percentage_error: 25.9248 - val_loss: 0.0519 - val_mean_absolute_percentage_error: 12.5898 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0360 - mean_absolute_percentage_error: 26.2582 - val_loss: 0.0447 - val_mean_absolute_percentage_error: 12.2521 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0306 - mean_absolute_percentage_error: 24.6203 - val_loss: 0.0313 - val_mean_absolute_percentage_error: 9.7974 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0233 - mean_absolute_percentage_error: 23.4099 - val_loss: 0.0402 - val_mean_absolute_percentage_error: 13.4815 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0232 - mean_absolute_percentage_error: 24.2638 - val_loss: 0.0353 - val_mean_absolute_percentage_error: 12.4111 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0207 - mean_absolute_percentage_error: 22.6876 - val_loss: 0.0358 - val_mean_absolute_percentage_error: 13.2977 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0175 - mean_absolute_percentage_error: 20.6951 - val_loss: 0.0368 - val_mean_absolute_percentage_error: 14.6884 - lr: 9.0484e-04\n",
      "Learning rate of the model:  0.0009048375\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0368 - mean_absolute_percentage_error: 14.6884\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0396 - mean_absolute_percentage_error: 15.9549\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1842 - mean_absolute_percentage_error: 52.8658 - val_loss: 0.1792 - val_mean_absolute_percentage_error: 26.5449 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0844 - mean_absolute_percentage_error: 28.2362 - val_loss: 0.1306 - val_mean_absolute_percentage_error: 24.6555 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0568 - mean_absolute_percentage_error: 23.5085 - val_loss: 0.0709 - val_mean_absolute_percentage_error: 15.5507 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0447 - mean_absolute_percentage_error: 23.5566 - val_loss: 0.0877 - val_mean_absolute_percentage_error: 22.5140 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0324 - mean_absolute_percentage_error: 21.5767 - val_loss: 0.0478 - val_mean_absolute_percentage_error: 14.4770 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0267 - mean_absolute_percentage_error: 23.8377 - val_loss: 0.0441 - val_mean_absolute_percentage_error: 14.3731 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0243 - mean_absolute_percentage_error: 26.0428 - val_loss: 0.0365 - val_mean_absolute_percentage_error: 13.1434 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0271 - mean_absolute_percentage_error: 24.9981 - val_loss: 0.0575 - val_mean_absolute_percentage_error: 18.8753 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0187 - mean_absolute_percentage_error: 21.1738 - val_loss: 0.0430 - val_mean_absolute_percentage_error: 15.9907 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0161 - mean_absolute_percentage_error: 22.1325 - val_loss: 0.0233 - val_mean_absolute_percentage_error: 9.6887 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0148 - mean_absolute_percentage_error: 20.7340 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 10.7792 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0138 - mean_absolute_percentage_error: 19.8539 - val_loss: 0.0261 - val_mean_absolute_percentage_error: 11.5051 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0129 - mean_absolute_percentage_error: 21.1978 - val_loss: 0.0185 - val_mean_absolute_percentage_error: 8.7575 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0124 - mean_absolute_percentage_error: 20.3668 - val_loss: 0.0205 - val_mean_absolute_percentage_error: 9.9109 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0116 - mean_absolute_percentage_error: 18.4375 - val_loss: 0.0297 - val_mean_absolute_percentage_error: 13.6489 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0125 - mean_absolute_percentage_error: 19.1127 - val_loss: 0.0222 - val_mean_absolute_percentage_error: 10.9002 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0110 - mean_absolute_percentage_error: 19.1588 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 10.0207 - lr: 6.3763e-04\n",
      "Learning rate of the model:  0.00063762837\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0198 - mean_absolute_percentage_error: 10.0207\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0219 - mean_absolute_percentage_error: 11.7128\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 8s 15ms/step - loss: 0.2173 - mean_absolute_percentage_error: 63.7577 - val_loss: 0.1951 - val_mean_absolute_percentage_error: 25.1891 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0975 - mean_absolute_percentage_error: 28.5996 - val_loss: 0.1544 - val_mean_absolute_percentage_error: 25.7884 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0664 - mean_absolute_percentage_error: 24.0887 - val_loss: 0.1168 - val_mean_absolute_percentage_error: 22.6032 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0519 - mean_absolute_percentage_error: 26.6335 - val_loss: 0.0938 - val_mean_absolute_percentage_error: 21.2041 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0404 - mean_absolute_percentage_error: 29.6940 - val_loss: 0.0791 - val_mean_absolute_percentage_error: 19.9366 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0386 - mean_absolute_percentage_error: 27.3081 - val_loss: 0.0914 - val_mean_absolute_percentage_error: 23.6752 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0256 - mean_absolute_percentage_error: 22.8156 - val_loss: 0.0503 - val_mean_absolute_percentage_error: 15.4183 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0239 - mean_absolute_percentage_error: 25.0754 - val_loss: 0.0374 - val_mean_absolute_percentage_error: 12.8921 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0192 - mean_absolute_percentage_error: 23.3566 - val_loss: 0.0310 - val_mean_absolute_percentage_error: 11.9116 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0205 - mean_absolute_percentage_error: 21.6557 - val_loss: 0.0354 - val_mean_absolute_percentage_error: 13.3432 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0189 - mean_absolute_percentage_error: 22.2806 - val_loss: 0.0519 - val_mean_absolute_percentage_error: 18.2762 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0174 - mean_absolute_percentage_error: 19.9171 - val_loss: 0.0309 - val_mean_absolute_percentage_error: 12.2571 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0148 - mean_absolute_percentage_error: 18.1294 - val_loss: 0.0300 - val_mean_absolute_percentage_error: 12.3007 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0125 - mean_absolute_percentage_error: 17.2953 - val_loss: 0.0243 - val_mean_absolute_percentage_error: 10.7868 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0143 - mean_absolute_percentage_error: 19.6967 - val_loss: 0.0287 - val_mean_absolute_percentage_error: 12.1578 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 18.3625 - val_loss: 0.0246 - val_mean_absolute_percentage_error: 11.0484 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 18.0338 - val_loss: 0.0208 - val_mean_absolute_percentage_error: 9.8632 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 15.8211 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 10.4308 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 17.4687 - val_loss: 0.0211 - val_mean_absolute_percentage_error: 10.1994 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0101 - mean_absolute_percentage_error: 18.5074 - val_loss: 0.0183 - val_mean_absolute_percentage_error: 9.8524 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 17.1603 - val_loss: 0.0203 - val_mean_absolute_percentage_error: 10.3383 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 19.3946 - val_loss: 0.0187 - val_mean_absolute_percentage_error: 9.9450 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 18.3189 - val_loss: 0.0206 - val_mean_absolute_percentage_error: 10.3024 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0088 - mean_absolute_percentage_error: 17.6052 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 10.0542 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0198 - mean_absolute_percentage_error: 10.0542\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0162 - mean_absolute_percentage_error: 9.4068\n",
      "Epoch 1/60\n",
      "365/365 [==============================] - 7s 15ms/step - loss: 0.1987 - mean_absolute_percentage_error: 48.1434 - val_loss: 0.1925 - val_mean_absolute_percentage_error: 28.5298 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0888 - mean_absolute_percentage_error: 27.6469 - val_loss: 0.1051 - val_mean_absolute_percentage_error: 18.0267 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0570 - mean_absolute_percentage_error: 21.8126 - val_loss: 0.0781 - val_mean_absolute_percentage_error: 17.1297 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0416 - mean_absolute_percentage_error: 24.1381 - val_loss: 0.0529 - val_mean_absolute_percentage_error: 12.9405 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0335 - mean_absolute_percentage_error: 24.0957 - val_loss: 0.0350 - val_mean_absolute_percentage_error: 8.9133 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0294 - mean_absolute_percentage_error: 20.8283 - val_loss: 0.0433 - val_mean_absolute_percentage_error: 14.1637 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0245 - mean_absolute_percentage_error: 23.4647 - val_loss: 0.0321 - val_mean_absolute_percentage_error: 10.4509 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0232 - mean_absolute_percentage_error: 24.5528 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 11.6376 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0191 - mean_absolute_percentage_error: 20.5667 - val_loss: 0.0356 - val_mean_absolute_percentage_error: 13.4338 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "365/365 [==============================] - 5s 14ms/step - loss: 0.0199 - mean_absolute_percentage_error: 23.5836 - val_loss: 0.0339 - val_mean_absolute_percentage_error: 12.8298 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0167 - mean_absolute_percentage_error: 22.1384 - val_loss: 0.0261 - val_mean_absolute_percentage_error: 10.4496 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0158 - mean_absolute_percentage_error: 20.1122 - val_loss: 0.0222 - val_mean_absolute_percentage_error: 9.2202 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0185 - mean_absolute_percentage_error: 21.2195 - val_loss: 0.0359 - val_mean_absolute_percentage_error: 14.4167 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0140 - mean_absolute_percentage_error: 19.9863 - val_loss: 0.0338 - val_mean_absolute_percentage_error: 13.7491 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 20.6498 - val_loss: 0.0231 - val_mean_absolute_percentage_error: 10.3976 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0119 - mean_absolute_percentage_error: 17.4999 - val_loss: 0.0217 - val_mean_absolute_percentage_error: 9.9834 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0125 - mean_absolute_percentage_error: 18.7596 - val_loss: 0.0243 - val_mean_absolute_percentage_error: 11.3421 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0130 - mean_absolute_percentage_error: 18.0053 - val_loss: 0.0291 - val_mean_absolute_percentage_error: 12.8555 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "365/365 [==============================] - 4s 12ms/step - loss: 0.0127 - mean_absolute_percentage_error: 18.1322 - val_loss: 0.0297 - val_mean_absolute_percentage_error: 13.6083 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "365/365 [==============================] - 5s 13ms/step - loss: 0.0111 - mean_absolute_percentage_error: 16.4427 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 10.2221 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "365/365 [==============================] - 5s 12ms/step - loss: 0.0107 - mean_absolute_percentage_error: 18.5163 - val_loss: 0.0235 - val_mean_absolute_percentage_error: 11.5444 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "365/365 [==============================] - 4s 10ms/step - loss: 0.0106 - mean_absolute_percentage_error: 16.8221 - val_loss: 0.0246 - val_mean_absolute_percentage_error: 11.6126 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "365/365 [==============================] - 3s 9ms/step - loss: 0.0103 - mean_absolute_percentage_error: 16.1678 - val_loss: 0.0272 - val_mean_absolute_percentage_error: 12.7053 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "365/365 [==============================] - 4s 11ms/step - loss: 0.0104 - mean_absolute_percentage_error: 17.8442 - val_loss: 0.0228 - val_mean_absolute_percentage_error: 11.0308 - lr: 4.4933e-04\n",
      "Learning rate of the model:  0.00044932918\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0228 - mean_absolute_percentage_error: 11.0308\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0240 - mean_absolute_percentage_error: 12.4654\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 6s 12ms/step - loss: 0.1717 - mean_absolute_percentage_error: 88.1754 - val_loss: 0.0987 - val_mean_absolute_percentage_error: 7.6632 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0767 - mean_absolute_percentage_error: 40.9342 - val_loss: 0.0640 - val_mean_absolute_percentage_error: 9.3030 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0486 - mean_absolute_percentage_error: 30.8117 - val_loss: 0.0347 - val_mean_absolute_percentage_error: 2.5537 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0372 - mean_absolute_percentage_error: 41.6818 - val_loss: 0.0302 - val_mean_absolute_percentage_error: 6.1225 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0278 - mean_absolute_percentage_error: 36.6443 - val_loss: 0.0200 - val_mean_absolute_percentage_error: 3.2522 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0212 - mean_absolute_percentage_error: 31.1878 - val_loss: 0.0154 - val_mean_absolute_percentage_error: 2.5477 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0199 - mean_absolute_percentage_error: 28.5580 - val_loss: 0.0149 - val_mean_absolute_percentage_error: 3.9480 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0165 - mean_absolute_percentage_error: 32.4042 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 2.5589 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0165 - mean_absolute_percentage_error: 36.2189 - val_loss: 0.0126 - val_mean_absolute_percentage_error: 4.4297 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0146 - mean_absolute_percentage_error: 35.6682 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 1.7772 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0133 - mean_absolute_percentage_error: 30.1894 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 2.7971 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0126 - mean_absolute_percentage_error: 29.6698 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 3.5837 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0123 - mean_absolute_percentage_error: 29.3872 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 3.5925 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0122 - mean_absolute_percentage_error: 31.0562 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 9.6736 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0117 - mean_absolute_percentage_error: 32.2134 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 1.9004 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0104 - mean_absolute_percentage_error: 24.6849 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 2.9962 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0104 - mean_absolute_percentage_error: 27.2377 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 1.8748 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0101 - mean_absolute_percentage_error: 28.0890 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 1.6216 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0104 - mean_absolute_percentage_error: 31.2738 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 1.7953 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0097 - mean_absolute_percentage_error: 27.5840 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 2.2158 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0092 - mean_absolute_percentage_error: 31.8467 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 3.4049 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 27.1134 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 2.9616 - lr: 4.9659e-04\n",
      "Learning rate of the model:  0.0004965855\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0066 - mean_absolute_percentage_error: 2.9616\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0065 - mean_absolute_percentage_error: 2.9200\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 15ms/step - loss: 0.1690 - mean_absolute_percentage_error: 62.6701 - val_loss: 0.1247 - val_mean_absolute_percentage_error: 14.2973 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0864 - mean_absolute_percentage_error: 39.9281 - val_loss: 0.0721 - val_mean_absolute_percentage_error: 9.0445 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0561 - mean_absolute_percentage_error: 39.9272 - val_loss: 0.0454 - val_mean_absolute_percentage_error: 5.9771 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0391 - mean_absolute_percentage_error: 36.8563 - val_loss: 0.0345 - val_mean_absolute_percentage_error: 6.6211 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0304 - mean_absolute_percentage_error: 38.5582 - val_loss: 0.0357 - val_mean_absolute_percentage_error: 9.9268 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0261 - mean_absolute_percentage_error: 37.4186 - val_loss: 0.0224 - val_mean_absolute_percentage_error: 6.0206 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0258 - mean_absolute_percentage_error: 35.1157 - val_loss: 0.0210 - val_mean_absolute_percentage_error: 5.9970 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0183 - mean_absolute_percentage_error: 32.6831 - val_loss: 0.0176 - val_mean_absolute_percentage_error: 6.0210 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0166 - mean_absolute_percentage_error: 31.5821 - val_loss: 0.0183 - val_mean_absolute_percentage_error: 7.2111 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0147 - mean_absolute_percentage_error: 29.4545 - val_loss: 0.0237 - val_mean_absolute_percentage_error: 9.9789 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0137 - mean_absolute_percentage_error: 28.3933 - val_loss: 0.0114 - val_mean_absolute_percentage_error: 4.0311 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0134 - mean_absolute_percentage_error: 24.9495 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 2.4980 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 31.4366 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 7.3155 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0122 - mean_absolute_percentage_error: 32.3204 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 3.7000 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0115 - mean_absolute_percentage_error: 30.2512 - val_loss: 0.0090 - val_mean_absolute_percentage_error: 3.6408 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0110 - mean_absolute_percentage_error: 28.9518 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 2.4643 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0101 - mean_absolute_percentage_error: 24.8638 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 6.8915 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 30.6360 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 1.7997 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 29.2547 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 2.2837 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 27.3566 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 3.3482 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 28.3895 - val_loss: 0.0065 - val_mean_absolute_percentage_error: 2.1595 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0089 - mean_absolute_percentage_error: 29.2633 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 2.3412 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 28.5271 - val_loss: 0.0113 - val_mean_absolute_percentage_error: 6.4529 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 27.6752 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 3.5104 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 30.3708 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 3.5281 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0081 - mean_absolute_percentage_error: 27.7423 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 3.9242 - lr: 4.0657e-04\n",
      "Learning rate of the model:  0.0004065699\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0074 - mean_absolute_percentage_error: 3.9242\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0086 - mean_absolute_percentage_error: 5.0475\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 15ms/step - loss: 0.1947 - mean_absolute_percentage_error: 91.2527 - val_loss: 0.1146 - val_mean_absolute_percentage_error: 8.1725 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0893 - mean_absolute_percentage_error: 35.5871 - val_loss: 0.0953 - val_mean_absolute_percentage_error: 15.3542 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0612 - mean_absolute_percentage_error: 34.3428 - val_loss: 0.0517 - val_mean_absolute_percentage_error: 8.0364 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0417 - mean_absolute_percentage_error: 29.3708 - val_loss: 0.0316 - val_mean_absolute_percentage_error: 3.2612 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0344 - mean_absolute_percentage_error: 31.3970 - val_loss: 0.0230 - val_mean_absolute_percentage_error: 1.9277 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0247 - mean_absolute_percentage_error: 25.7437 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 2.5665 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0216 - mean_absolute_percentage_error: 27.6074 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 3.0132 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0181 - mean_absolute_percentage_error: 26.7777 - val_loss: 0.0123 - val_mean_absolute_percentage_error: 1.9105 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0177 - mean_absolute_percentage_error: 27.0679 - val_loss: 0.0178 - val_mean_absolute_percentage_error: 7.3675 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0149 - mean_absolute_percentage_error: 28.7313 - val_loss: 0.0123 - val_mean_absolute_percentage_error: 4.6171 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0139 - mean_absolute_percentage_error: 27.0886 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 4.3757 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0128 - mean_absolute_percentage_error: 23.3651 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 1.4399 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0127 - mean_absolute_percentage_error: 21.5783 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 3.4225 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0119 - mean_absolute_percentage_error: 24.2989 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 1.5070 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0106 - mean_absolute_percentage_error: 25.2930 - val_loss: 0.0107 - val_mean_absolute_percentage_error: 5.4267 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0114 - mean_absolute_percentage_error: 25.2083 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 2.9461 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 26.5268 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 4.0139 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 27.4826 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 1.3690 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 26.7437 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 4.4153 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 25.8814 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 1.6293 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 28.7428 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 1.6162 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 23.1416 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 3.8775 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 21.2608 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 2.9057 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 22.4375 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 2.8656 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 25.8303 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 2.4808 - lr: 4.2742e-04\n",
      "Learning rate of the model:  0.00042741516\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0058 - mean_absolute_percentage_error: 2.4808\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0059 - mean_absolute_percentage_error: 2.7427\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 15ms/step - loss: 0.1862 - mean_absolute_percentage_error: 65.0871 - val_loss: 0.1067 - val_mean_absolute_percentage_error: 12.0053 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0750 - mean_absolute_percentage_error: 39.9283 - val_loss: 0.0516 - val_mean_absolute_percentage_error: 3.4028 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0485 - mean_absolute_percentage_error: 36.3645 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 5.4833 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0339 - mean_absolute_percentage_error: 34.3474 - val_loss: 0.0250 - val_mean_absolute_percentage_error: 3.1492 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0272 - mean_absolute_percentage_error: 34.3633 - val_loss: 0.0216 - val_mean_absolute_percentage_error: 4.5141 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0228 - mean_absolute_percentage_error: 30.2639 - val_loss: 0.0185 - val_mean_absolute_percentage_error: 4.7992 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0206 - mean_absolute_percentage_error: 29.8082 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 7.5056 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0201 - mean_absolute_percentage_error: 33.9538 - val_loss: 0.0156 - val_mean_absolute_percentage_error: 4.3640 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0166 - mean_absolute_percentage_error: 25.9347 - val_loss: 0.0141 - val_mean_absolute_percentage_error: 4.8656 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0149 - mean_absolute_percentage_error: 23.7466 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 1.8641 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0141 - mean_absolute_percentage_error: 24.1503 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 1.6249 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0135 - mean_absolute_percentage_error: 27.9478 - val_loss: 0.0100 - val_mean_absolute_percentage_error: 3.3526 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0127 - mean_absolute_percentage_error: 32.4860 - val_loss: 0.0121 - val_mean_absolute_percentage_error: 5.3954 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 24.0358 - val_loss: 0.0091 - val_mean_absolute_percentage_error: 2.9994 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0117 - mean_absolute_percentage_error: 27.8087 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 1.8010 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 26.4470 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 1.6889 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 23.2661 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 4.1883 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0105 - mean_absolute_percentage_error: 23.3545 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 1.3579 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0106 - mean_absolute_percentage_error: 25.7366 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 3.3637 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 24.0615 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 3.8767 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 23.2404 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 6.5279 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 27.3662 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 1.7865 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 20.7655 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 2.4473 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 21.3435 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 1.9247 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 20.7718 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 1.5479 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 25.1305 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 2.9320 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0085 - mean_absolute_percentage_error: 21.0814 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 3.0598 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0080 - mean_absolute_percentage_error: 21.4991 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 1.9730 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 22.4870 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 1.6537 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0077 - mean_absolute_percentage_error: 19.9788 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 4.2084 - lr: 3.3287e-04\n",
      "Epoch 31/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 19.8997 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 3.1607 - lr: 3.1664e-04\n",
      "Epoch 32/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0077 - mean_absolute_percentage_error: 21.3827 - val_loss: 0.0064 - val_mean_absolute_percentage_error: 2.7136 - lr: 3.0119e-04\n",
      "Epoch 33/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 21.3918 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 2.0653 - lr: 2.8651e-04\n",
      "Learning rate of the model:  0.000286505\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.0057 - mean_absolute_percentage_error: 2.0653\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0056 - mean_absolute_percentage_error: 2.4251\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 14ms/step - loss: 0.1842 - mean_absolute_percentage_error: 72.2032 - val_loss: 0.0994 - val_mean_absolute_percentage_error: 7.9856 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0777 - mean_absolute_percentage_error: 42.0485 - val_loss: 0.0620 - val_mean_absolute_percentage_error: 8.0835 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0503 - mean_absolute_percentage_error: 37.8606 - val_loss: 0.0484 - val_mean_absolute_percentage_error: 9.9354 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0383 - mean_absolute_percentage_error: 31.9930 - val_loss: 0.0302 - val_mean_absolute_percentage_error: 5.9652 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0284 - mean_absolute_percentage_error: 37.9523 - val_loss: 0.0225 - val_mean_absolute_percentage_error: 4.4143 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0233 - mean_absolute_percentage_error: 31.1304 - val_loss: 0.0163 - val_mean_absolute_percentage_error: 2.2335 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0236 - mean_absolute_percentage_error: 33.1171 - val_loss: 0.0212 - val_mean_absolute_percentage_error: 7.2588 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0189 - mean_absolute_percentage_error: 29.2802 - val_loss: 0.0179 - val_mean_absolute_percentage_error: 6.4337 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0160 - mean_absolute_percentage_error: 31.1701 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 2.6178 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0148 - mean_absolute_percentage_error: 29.8724 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 3.2242 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0140 - mean_absolute_percentage_error: 29.3218 - val_loss: 0.0105 - val_mean_absolute_percentage_error: 3.4640 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 28.4740 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 1.8231 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 27.3904 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 1.9335 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 24.8592 - val_loss: 0.0078 - val_mean_absolute_percentage_error: 1.6134 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0125 - mean_absolute_percentage_error: 28.4743 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 2.6485 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0113 - mean_absolute_percentage_error: 28.0572 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 2.2264 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0109 - mean_absolute_percentage_error: 32.4941 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 3.5091 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0107 - mean_absolute_percentage_error: 30.7590 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 1.9677 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0106 - mean_absolute_percentage_error: 26.7691 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 3.9223 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0101 - mean_absolute_percentage_error: 25.4015 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 2.9163 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 24.8170 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 2.4538 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 26.2742 - val_loss: 0.0071 - val_mean_absolute_percentage_error: 3.0677 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 23.8091 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 3.0966 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0089 - mean_absolute_percentage_error: 25.7153 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 1.6327 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 26.9272 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 3.3877 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0088 - mean_absolute_percentage_error: 27.2638 - val_loss: 0.0058 - val_mean_absolute_percentage_error: 2.0877 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 25.2312 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 2.6838 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 24.7845 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 2.5179 - lr: 3.6788e-04\n",
      "Learning rate of the model:  0.00036787966\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0060 - mean_absolute_percentage_error: 2.5179\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_absolute_percentage_error: 2.4874\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 15ms/step - loss: 0.1839 - mean_absolute_percentage_error: 96.3631 - val_loss: 0.0965 - val_mean_absolute_percentage_error: 5.7235 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0787 - mean_absolute_percentage_error: 50.9357 - val_loss: 0.0568 - val_mean_absolute_percentage_error: 3.7331 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0539 - mean_absolute_percentage_error: 37.9339 - val_loss: 0.0381 - val_mean_absolute_percentage_error: 3.2839 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0385 - mean_absolute_percentage_error: 42.3281 - val_loss: 0.0325 - val_mean_absolute_percentage_error: 6.1845 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0298 - mean_absolute_percentage_error: 42.1778 - val_loss: 0.0222 - val_mean_absolute_percentage_error: 3.6861 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0241 - mean_absolute_percentage_error: 32.0716 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 7.5771 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0208 - mean_absolute_percentage_error: 32.5775 - val_loss: 0.0147 - val_mean_absolute_percentage_error: 2.7024 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0199 - mean_absolute_percentage_error: 38.4708 - val_loss: 0.0152 - val_mean_absolute_percentage_error: 4.2596 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0171 - mean_absolute_percentage_error: 26.6535 - val_loss: 0.0273 - val_mean_absolute_percentage_error: 10.2482 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0163 - mean_absolute_percentage_error: 32.8095 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 4.9017 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0145 - mean_absolute_percentage_error: 30.7949 - val_loss: 0.0146 - val_mean_absolute_percentage_error: 5.9014 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0132 - mean_absolute_percentage_error: 32.9038 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 3.8074 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0122 - mean_absolute_percentage_error: 27.4676 - val_loss: 0.0108 - val_mean_absolute_percentage_error: 4.0230 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0118 - mean_absolute_percentage_error: 21.6978 - val_loss: 0.0116 - val_mean_absolute_percentage_error: 5.2984 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0111 - mean_absolute_percentage_error: 29.3522 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 4.2476 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0105 - mean_absolute_percentage_error: 24.7405 - val_loss: 0.0155 - val_mean_absolute_percentage_error: 7.7950 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0108 - mean_absolute_percentage_error: 24.4733 - val_loss: 0.0076 - val_mean_absolute_percentage_error: 2.5581 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0107 - mean_absolute_percentage_error: 28.9028 - val_loss: 0.0128 - val_mean_absolute_percentage_error: 6.7782 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 24.3326 - val_loss: 0.0070 - val_mean_absolute_percentage_error: 2.4286 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0095 - mean_absolute_percentage_error: 20.5301 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 1.5053 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0099 - mean_absolute_percentage_error: 26.1644 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 1.7203 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0090 - mean_absolute_percentage_error: 20.0036 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 1.7429 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0087 - mean_absolute_percentage_error: 24.2829 - val_loss: 0.0083 - val_mean_absolute_percentage_error: 4.3362 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 22.9202 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 2.9622 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 5s 14ms/step - loss: 0.0081 - mean_absolute_percentage_error: 20.6381 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 3.4804 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 27.0496 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 4.6661 - lr: 4.0657e-04\n",
      "Learning rate of the model:  0.0004065699\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0085 - mean_absolute_percentage_error: 4.6661\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_absolute_percentage_error: 5.7454\n",
      "Epoch 1/60\n",
      "347/347 [==============================] - 7s 15ms/step - loss: 0.1773 - mean_absolute_percentage_error: 75.8790 - val_loss: 0.1201 - val_mean_absolute_percentage_error: 12.1243 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0852 - mean_absolute_percentage_error: 51.4842 - val_loss: 0.0752 - val_mean_absolute_percentage_error: 10.3553 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0572 - mean_absolute_percentage_error: 47.0304 - val_loss: 0.0463 - val_mean_absolute_percentage_error: 6.0538 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0438 - mean_absolute_percentage_error: 35.3895 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 4.5024 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0325 - mean_absolute_percentage_error: 29.8671 - val_loss: 0.0286 - val_mean_absolute_percentage_error: 6.0064 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0262 - mean_absolute_percentage_error: 36.5933 - val_loss: 0.0199 - val_mean_absolute_percentage_error: 2.5096 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0243 - mean_absolute_percentage_error: 31.7644 - val_loss: 0.0168 - val_mean_absolute_percentage_error: 2.4536 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0205 - mean_absolute_percentage_error: 35.2847 - val_loss: 0.0235 - val_mean_absolute_percentage_error: 8.2581 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0187 - mean_absolute_percentage_error: 29.4405 - val_loss: 0.0190 - val_mean_absolute_percentage_error: 6.5287 - lr: 9.5123e-04\n",
      "Epoch 10/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0162 - mean_absolute_percentage_error: 27.6451 - val_loss: 0.0165 - val_mean_absolute_percentage_error: 6.2952 - lr: 9.0484e-04\n",
      "Epoch 11/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0144 - mean_absolute_percentage_error: 24.1337 - val_loss: 0.0134 - val_mean_absolute_percentage_error: 5.1433 - lr: 8.6071e-04\n",
      "Epoch 12/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0138 - mean_absolute_percentage_error: 25.3994 - val_loss: 0.0095 - val_mean_absolute_percentage_error: 2.1941 - lr: 8.1873e-04\n",
      "Epoch 13/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0129 - mean_absolute_percentage_error: 26.1501 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 2.6391 - lr: 7.7880e-04\n",
      "Epoch 14/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0126 - mean_absolute_percentage_error: 23.7628 - val_loss: 0.0081 - val_mean_absolute_percentage_error: 1.6311 - lr: 7.4082e-04\n",
      "Epoch 15/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0123 - mean_absolute_percentage_error: 28.8068 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 3.5922 - lr: 7.0469e-04\n",
      "Epoch 16/60\n",
      "347/347 [==============================] - 5s 13ms/step - loss: 0.0109 - mean_absolute_percentage_error: 24.2526 - val_loss: 0.0123 - val_mean_absolute_percentage_error: 5.8299 - lr: 6.7032e-04\n",
      "Epoch 17/60\n",
      "347/347 [==============================] - 4s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 23.3290 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 3.3894 - lr: 6.3763e-04\n",
      "Epoch 18/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0109 - mean_absolute_percentage_error: 26.1007 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 2.9874 - lr: 6.0653e-04\n",
      "Epoch 19/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0100 - mean_absolute_percentage_error: 21.5766 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 3.3100 - lr: 5.7695e-04\n",
      "Epoch 20/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0095 - mean_absolute_percentage_error: 17.7815 - val_loss: 0.0085 - val_mean_absolute_percentage_error: 4.0283 - lr: 5.4881e-04\n",
      "Epoch 21/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0093 - mean_absolute_percentage_error: 20.4687 - val_loss: 0.0062 - val_mean_absolute_percentage_error: 1.7452 - lr: 5.2205e-04\n",
      "Epoch 22/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0092 - mean_absolute_percentage_error: 26.9152 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 2.3891 - lr: 4.9659e-04\n",
      "Epoch 23/60\n",
      "347/347 [==============================] - 3s 9ms/step - loss: 0.0095 - mean_absolute_percentage_error: 31.0238 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 6.5345 - lr: 4.7237e-04\n",
      "Epoch 24/60\n",
      "347/347 [==============================] - 4s 11ms/step - loss: 0.0086 - mean_absolute_percentage_error: 18.0747 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 2.1736 - lr: 4.4933e-04\n",
      "Epoch 25/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0085 - mean_absolute_percentage_error: 28.4138 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 2.1707 - lr: 4.2742e-04\n",
      "Epoch 26/60\n",
      "347/347 [==============================] - 4s 12ms/step - loss: 0.0087 - mean_absolute_percentage_error: 24.9660 - val_loss: 0.0054 - val_mean_absolute_percentage_error: 1.7615 - lr: 4.0657e-04\n",
      "Epoch 27/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0080 - mean_absolute_percentage_error: 18.1501 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 2.1197 - lr: 3.8674e-04\n",
      "Epoch 28/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 27.7943 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 2.7403 - lr: 3.6788e-04\n",
      "Epoch 29/60\n",
      "347/347 [==============================] - 4s 10ms/step - loss: 0.0078 - mean_absolute_percentage_error: 20.9239 - val_loss: 0.0060 - val_mean_absolute_percentage_error: 2.8166 - lr: 3.4994e-04\n",
      "Epoch 30/60\n",
      "347/347 [==============================] - 3s 10ms/step - loss: 0.0076 - mean_absolute_percentage_error: 24.0542 - val_loss: 0.0094 - val_mean_absolute_percentage_error: 5.8447 - lr: 3.3287e-04\n",
      "Learning rate of the model:  0.0003328713\n",
      "Model: \"simple_stacked_lstm_2_multilr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 29, 64)            21760     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,553\n",
      "Trainable params: 56,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.0094 - mean_absolute_percentage_error: 5.8447\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0106 - mean_absolute_percentage_error: 6.5358\n",
      "Epoch 1/60\n",
      "346/347 [============================>.] - ETA: 0s - loss: 0.1778 - mean_absolute_percentage_error: 93.2225"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#main training loop\n",
    "stock_training_range = 10 #len(stock_list)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for stock_index in range(50):\n",
    "\n",
    "\n",
    "    #set up\n",
    "\n",
    "    current_stock = stock_list[stock_index] #df\n",
    "\n",
    "    column_indices = {name: i for i, name in enumerate(current_stock.columns)}\n",
    "\n",
    "    n = len(current_stock)\n",
    "    num_features = current_stock.shape[1]\n",
    "    num_row = current_stock.shape[0]\n",
    "\n",
    "    #split training, cross val and testing data\n",
    "    #note since this is a time series data, the split is fixed. No randomization\n",
    "    #no testing data, only cross val data\n",
    "\n",
    "    train_data_p = 0.7  #percentage of train data\n",
    "    val_data_p = 0.2\n",
    "\n",
    "    train_df = current_stock[ 0 : int(n * train_data_p) ]\n",
    "    val_df = current_stock[int( n * train_data_p) : int(n * (train_data_p + val_data_p)) ]\n",
    "    test_df = current_stock[int( n * (train_data_p + val_data_p)) : ]\n",
    "\n",
    "\n",
    "    #debug area\n",
    "    ########################################################################\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(\"df instances : \", num_row)\n",
    "        print(\"df features : \", num_features)\n",
    "        display(current_stock)\n",
    "\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n : \n",
    "        print(\"train_df instances : \", len(train_df))\n",
    "        display(train_df)\n",
    "        \n",
    "        for x in range(4): \n",
    "            print()\n",
    "            \n",
    "        print(\"val_df instances : \", len(val_df))\n",
    "        display(val_df)\n",
    "        \n",
    "        for x in range(4): \n",
    "            print()\n",
    "            \n",
    "        print(\"test_df instances : \", len(test_df))\n",
    "        display(test_df)\n",
    "    ########################################################################\n",
    "\n",
    "\n",
    "    #normalize data\n",
    "    train_mean = train_df.mean()\n",
    "    train_std = train_df.std()\n",
    "\n",
    "    #compute the z score to normalize data between features\n",
    "    train_df = (train_df - train_mean)/train_std\n",
    "    val_df = (val_df - train_mean)/train_std\n",
    "    test_df = (test_df - train_mean)/train_std\n",
    "\n",
    "\n",
    "    #visuliazation\n",
    "    ########################################################################\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        df_std = (current_stock - train_mean) / train_std\n",
    "        df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "        _ = ax.set_xticklabels(current_stock.keys(), rotation=90)\n",
    "    ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "    #window setup area\n",
    "    ##############################################################################################\n",
    "\n",
    "    #set up the 7 timesteps window\n",
    "    win_7 = time_window_generator(input_width = 6, label_width = 1, shift = 1, train_df=train_df, val_df=val_df, test_df=test_df, label_columns = labels)\n",
    "    #set up the batch size\n",
    "    win_7.batch_size = 8\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(win_7)\n",
    "        aux_functions.window_inspection(win_7, debug_mode, labels)\n",
    "    \n",
    "\n",
    "\n",
    "    #set up 30 timesteps window\n",
    "    win_30 = time_window_generator(input_width = 29, label_width = 1, shift = 1, train_df=train_df, val_df=val_df, test_df=test_df, label_columns = labels)\n",
    "    #set up the batch size\n",
    "    win_30.batch_size = 8\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(win_30)\n",
    "        aux_functions.window_inspection(win_30, debug_mode, labels)\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #individual stock model performance evaluate \n",
    "    result = []\n",
    "\n",
    "\n",
    "\n",
    "    #train models for n numbers of iteration to check the performance\n",
    "    for iter in range(eval_iteration):\n",
    "\n",
    "        #clear backend, prevent memory overflow\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        #tensorboard logging doesnt work for now\n",
    "        # logpath_exact = tf_log_dir + str(stock_list[stock_index].name) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        # tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logpath_exact)\n",
    "\n",
    "\n",
    "        #temp model area\n",
    "        ##############################################################################################\n",
    "\n",
    "\n",
    "        stacked_lstm_1 = Sequential(\n",
    "\n",
    "            [\n",
    "\n",
    "                LSTM(units = 32, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                LSTM(units = 32, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "            ],\n",
    "\n",
    "            name = \"simple_stacked_lstm_stock_1\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        stacked_lstm_2_multilr = Sequential(\n",
    "\n",
    "            [\n",
    "\n",
    "                LSTM(units = 64, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                LSTM(units = 64, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 24, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "            ],\n",
    "\n",
    "            name = \"simple_stacked_lstm_2_multilr\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        #chose model to run and evaluate\n",
    "        train_target = win_30\n",
    "        train_model = stacked_lstm_2_multilr\n",
    "\n",
    "\n",
    "\n",
    "        #compile and fit\n",
    "        data_model = aux_functions.compile_and_fit(train_model, train_target, epochs=60, es_patience=4, es_monitor='val_loss', es_mode='min', lr=learning_rate)\n",
    "\n",
    "\n",
    "        result.append([train_model.evaluate(train_target.val), train_model.evaluate(train_target.test)])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    average_mape_val = 0\n",
    "    average_mape_test = 0\n",
    "    \n",
    "    for result_i in range(len(result)):\n",
    "        average_mape_val += result[result_i][0][1]\n",
    "        average_mape_test += result[result_i][1][1]\n",
    "    \n",
    "    average_mape_val = average_mape_val/len(result)\n",
    "    average_mape_test = average_mape_test/len(result)\n",
    "\n",
    "\n",
    "\n",
    "    evaluation_result[stock_list[stock_index].name] = [average_mape_val, average_mape_test, result]\n",
    "\n",
    "\n",
    "\n",
    "    #data logging\n",
    "\n",
    "    if performance_log == True:\n",
    "\n",
    "        performance_log_csv = open(data_log_csv_path, 'a', encoding='UTF8', newline='')\n",
    "        csv_writer = csv.writer(performance_log_csv)\n",
    "        csv_writer.writerow([stock_list[stock_index].name, average_mape_val, average_mape_test, eval_iteration, len(train_df), len(val_df), len(test_df), train_model.name])\n",
    "        performance_log_csv.close()\n",
    "\n",
    "\n",
    "    #garbage collection test 1\n",
    "    del train_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all output of the dictionaries db\n",
    "\n",
    "for key, value in evaluation_result.items():\n",
    "    print(\"Stock Model for : \", key)\n",
    "    print(\"Average MAPE of val data_set : \", value[0])\n",
    "    print(\"Average MAPE of test data_set : \", value[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# header = [\"stock_code\",\"Average MAPE of val data_set\", \"Average MAPE of test data_set\", \"Iteration_number\"]   \n",
    "\n",
    "# with open(\"training_log/simple_models.csv\", 'w', encoding='UTF8', newline='') as file:\n",
    "\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     writer.writerow(header)\n",
    "\n",
    "#     for key, value in evaluation_result.items():\n",
    "#         writer.writerow([key, value[0], value[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e30d39d17b6777ac72c2de8bf454df1082287d1113e8e1d07731a2d8443e9a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
