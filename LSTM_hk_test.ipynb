{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "from csv import writer\n",
    "\n",
    "\n",
    "\n",
    "#tensorflow import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.activations import relu,linear\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#logging\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "#custom functions import\n",
    "from ts_functions import time_window_generator\n",
    "from aux_functions import aux_functions\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option flags\n",
    "debug_mode = True\n",
    "debug_output_n = 2\n",
    "\n",
    "performance_log = True\n",
    "data_log_csv_path = \"training_log/tencent_t1.csv\"\n",
    "\n",
    "\n",
    "#tensorboard logging doesnt work for now\n",
    "tf_log_dir = \"logs/LSTM_stocks/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "filename = os.path.join(fileDir, r\"stock_data\\tencent_04_22_day.csv\") #stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['change']\n",
    "\n",
    "df = pd.read_csv(filename).drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c452ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf46ce7",
   "metadata": {},
   "source": [
    "# Model DataFrame preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into different stock\n",
    "# stock_list = [x.sort_values(\"trade_date\", ascending = True) for _,x in df.groupby('ts_code')]\n",
    "\n",
    "stock_list = []\n",
    "\n",
    "for ts_code, x in df.groupby('ts_code'):\n",
    "    stock_list.append(x.copy().sort_values(\"trade_date\", ascending = True).reset_index().drop('index', axis=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sort by trade_date, ascending\n",
    "if debug_mode:\n",
    "    print(\"number of stocks : \", len(stock_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HSI into the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_filename = os.path.join(fileDir, r\"stock_data\\hsi_07_22_day.csv\")\n",
    "\n",
    "df_hsi = pd.read_csv(hsi_filename).drop(['index_ts_code', 'index_vol', 'index_change', 'index_vol', 'index_swing'], axis=1).sort_values(\"index_trade_date\", ascending = True).reset_index().drop('index', axis=1)\n",
    "\n",
    "display(df_hsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #append hs300 by matching dates\n",
    "# invalid_stock_list = []# the stock that is fucked\n",
    "\n",
    "\n",
    "# for i in range(len(stock_list)):\n",
    "#     stock = stock_list[i]\n",
    "#     if stock['trade_date'].iloc[-1] != df_hs300['index_trade_date'].iloc[-1]:\n",
    "#         invalid_stock_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in invalid_stock_list:\n",
    "# #     print(stock_list[i].head(1))\n",
    "\n",
    "# invalid_stock_list = sorted(invalid_stock_list, reverse=True)\n",
    "\n",
    "# print(invalid_stock_list)\n",
    "\n",
    "\n",
    "# for i in invalid_stock_list:\n",
    "#     stock_list.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list[0]['trade_date']\n",
    "print(len(stock_list[0]['trade_date']))\n",
    "\n",
    "tx = df_hsi[df_hsi['index_trade_date'].isin(stock_list[0]['trade_date'])].sort_values(\"index_trade_date\", ascending = True).reset_index().drop('index', axis=1)\n",
    "display(tx)\n",
    "\n",
    "display(stock_list[0])\n",
    "\n",
    "display(df_hsi)\n",
    "\n",
    "txp = pd.concat([stock_list[0], tx], axis=1, join='inner')\n",
    "display(txp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat\n",
    "\n",
    "for i in range(len(stock_list)):\n",
    "\n",
    "    temp = df_hsi[df_hsi['index_trade_date'].isin(stock_list[i]['trade_date'])].sort_values(\"index_trade_date\", ascending = True).reset_index().drop('index', axis=1)\n",
    "    stock_list[i] = pd.concat([stock_list[i], temp], axis=1, join='inner')#.drop('index_trade_date', axis=1)\n",
    "\n",
    "    # stock_list[i] = stock_list[i].join(df_hsi, on='str', lsuffix='trade_date', rsuffix='index_trade_date', how='inner')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stock_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check time matching\n",
    "for stock in stock_list:\n",
    "    print(stock['trade_date'].isin(stock['index_trade_date']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stock_list[0][0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time periodicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b80602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup timestamp for year periodicity \n",
    "date_time_db = []\n",
    "\n",
    "for stock_i in stock_list:\n",
    "    date_time_db.append(pd.to_datetime(stock_i.pop('trade_date'), format='%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e59e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(date_time_db[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea85e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_stamp_db = []\n",
    "\n",
    "for dt in date_time_db:\n",
    "    date_time_stamp_db.append(dt.map(pd.Timestamp.timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    date_time_stamp_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 24*60*60*(365.2425)\n",
    "\n",
    "for i in range(len(stock_list)):\n",
    "    \n",
    "    stock_list[i][\"Year sin\"] = np.sin(date_time_stamp_db[i] * (2 * np.pi / year))\n",
    "    stock_list[i][\"Year cos\"] = np.cos(date_time_stamp_db[i] * (2 * np.pi / year))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    plt.plot(np.array(stock_list[0]['Year sin'])[:1000])\n",
    "    plt.plot(np.array(stock_list[0]['Year cos'])[:1000])\n",
    "    plt.xlabel('Time [day]')\n",
    "    plt.title('Time of year signal, in day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11616a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    stock_list[5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df processing\n",
    "for stock in stock_list:\n",
    "    stock.name = stock.iloc[0,0]\n",
    "    stock.pop(\"ts_code\") #pop the stock code\n",
    "    #stock.pop(\"pre_close\") #pop previous day close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba18cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    stock_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_label = 'open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stock_list:\n",
    "    \n",
    "    #MA\n",
    "\n",
    "    processing_row = stock[ma_label].to_frame()\n",
    "\n",
    "    stock['sma5'] = processing_row[ma_label].rolling(5).mean()\n",
    "\n",
    "    stock['ema5'] = processing_row[ma_label].ewm(span=5).mean()\n",
    "\n",
    "    stock['ema20'] = processing_row[ma_label].ewm(span=20).mean()\n",
    "\n",
    "    stock['ema50'] = processing_row[ma_label].ewm(span=50).mean()\n",
    "\n",
    "    \n",
    "\n",
    "    # # Golden Cross  implementation\n",
    "    # np.where(stock['ema20'] > stock['ema50'], 1, 0)\n",
    "\n",
    "    # stock['ema20_50_GC'] = 0 \n",
    "\n",
    "    # for i in range(stock.shape[0]):\n",
    "    #     if i == 0:\n",
    "    #         pass\n",
    "    #     elif stock['ema20'][i] >= stock['ema50'][i] and stock['ema20'][i-1] < stock['ema50'][i-1]: #slow code, works for now\n",
    "    #         stock['ema20_50_GC'][i] = 1\n",
    "\n",
    "\n",
    "\n",
    "    stock.dropna(inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GC value count inspction\n",
    "# for stock in stock_list:\n",
    "#     print(stock['ema20_50_GC'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stock_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stock_list[0])\n",
    "display(stock_list[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_lstm_1 = Sequential(\n",
    "\n",
    "#     [\n",
    "\n",
    "#         LSTM(units = 32, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         LSTM(units = 32, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "#     ],\n",
    "\n",
    "#     name = \"simple_stacked_lstm_stock_1\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_lstm_1_plus = Sequential(\n",
    "\n",
    "#     [\n",
    "\n",
    "#         LSTM(units = 64, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         LSTM(units = 64, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 24, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "#         Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "#     ],\n",
    "\n",
    "#     name = \"simple_stacked_lstm_stock_1_plus\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28efbc4b",
   "metadata": {},
   "source": [
    "# Training for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data storage\n",
    "evaluation_result = {}\n",
    "\n",
    "\n",
    "#meta data\n",
    "labels = ['open']\n",
    "\n",
    "eval_iteration = 10 #the number of evaluation iterations for individual stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#main training loop\n",
    "stock_training_range = 10 #len(stock_list)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for stock_index in range(50):\n",
    "\n",
    "\n",
    "    #set up\n",
    "\n",
    "    current_stock = stock_list[stock_index] #df\n",
    "\n",
    "    column_indices = {name: i for i, name in enumerate(current_stock.columns)}\n",
    "\n",
    "    n = len(current_stock)\n",
    "    num_features = current_stock.shape[1]\n",
    "    num_row = current_stock.shape[0]\n",
    "\n",
    "    #split training, cross val and testing data\n",
    "    #note since this is a time series data, the split is fixed. No randomization\n",
    "    #no testing data, only cross val data\n",
    "\n",
    "    train_data_p = 0.7  #percentage of train data\n",
    "    val_data_p = 0.2\n",
    "\n",
    "    train_df = current_stock[ 0 : int(n * train_data_p) ]\n",
    "    val_df = current_stock[int( n * train_data_p) : int(n * (train_data_p + val_data_p)) ]\n",
    "    test_df = current_stock[int( n * (train_data_p + val_data_p)) : ]\n",
    "\n",
    "\n",
    "    #debug area\n",
    "    ########################################################################\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(\"df instances : \", num_row)\n",
    "        print(\"df features : \", num_features)\n",
    "        display(current_stock)\n",
    "\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n : \n",
    "        print(\"train_df instances : \", len(train_df))\n",
    "        display(train_df)\n",
    "        \n",
    "        for x in range(4): \n",
    "            print()\n",
    "            \n",
    "        print(\"val_df instances : \", len(val_df))\n",
    "        display(val_df)\n",
    "        \n",
    "        for x in range(4): \n",
    "            print()\n",
    "            \n",
    "        print(\"test_df instances : \", len(test_df))\n",
    "        display(test_df)\n",
    "    ########################################################################\n",
    "\n",
    "\n",
    "    #normalize data\n",
    "    train_mean = train_df.mean()\n",
    "    train_std = train_df.std()\n",
    "\n",
    "    #compute the z score to normalize data between features\n",
    "    train_df = (train_df - train_mean)/train_std\n",
    "    val_df = (val_df - train_mean)/train_std\n",
    "    test_df = (test_df - train_mean)/train_std\n",
    "\n",
    "\n",
    "    #visuliazation\n",
    "    ########################################################################\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        df_std = (current_stock - train_mean) / train_std\n",
    "        df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "        _ = ax.set_xticklabels(current_stock.keys(), rotation=90)\n",
    "    ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "    #window setup area\n",
    "    ##############################################################################################\n",
    "\n",
    "    #set up the 7 timesteps window\n",
    "    win_7 = time_window_generator(input_width = 6, label_width = 1, shift = 1, train_df=train_df, val_df=val_df, test_df=test_df, label_columns = labels)\n",
    "    #set up the batch size\n",
    "    win_7.batch_size = 8\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(win_7)\n",
    "        aux_functions.window_inspection(win_7, debug_mode, labels)\n",
    "    \n",
    "\n",
    "\n",
    "    #set up 30 timesteps window\n",
    "    win_30 = time_window_generator(input_width = 29, label_width = 1, shift = 1, train_df=train_df, val_df=val_df, test_df=test_df, label_columns = labels)\n",
    "    #set up the batch size\n",
    "    win_30.batch_size = 8\n",
    "\n",
    "    if debug_mode and stock_index < debug_output_n :\n",
    "        print(win_30)\n",
    "        aux_functions.window_inspection(win_30, debug_mode, labels)\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #individual stock model performance evaluate \n",
    "    result = []\n",
    "\n",
    "\n",
    "\n",
    "    #train models for n numbers of iteration to check the performance\n",
    "    for iter in range(eval_iteration):\n",
    "\n",
    "        #clear backend, prevent memory overflow\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        #tensorboard logging doesnt work for now\n",
    "        # logpath_exact = tf_log_dir + str(stock_list[stock_index].name) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        # tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logpath_exact)\n",
    "\n",
    "\n",
    "        #temp model area\n",
    "        ##############################################################################################\n",
    "\n",
    "\n",
    "        stacked_lstm_1 = Sequential(\n",
    "\n",
    "            [\n",
    "\n",
    "                LSTM(units = 32, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                LSTM(units = 32, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "            ],\n",
    "\n",
    "            name = \"simple_stacked_lstm_stock_1\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        stacked_lstm_2_multilr = Sequential(\n",
    "\n",
    "            [\n",
    "\n",
    "                LSTM(units = 64, activation='tanh', return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                LSTM(units = 64, activation='tanh', return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 24, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001) ),\n",
    "                Dense(units = 1, activation = 'linear') #output \n",
    "\n",
    "            ],\n",
    "\n",
    "            name = \"simple_stacked_lstm_2_multilr\"\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        #chose model to run and evaluate\n",
    "        train_target = win_30\n",
    "        train_model = stacked_lstm_2_multilr\n",
    "\n",
    "\n",
    "\n",
    "        #compile and fit\n",
    "        data_model = aux_functions.compile_and_fit(train_model, train_target, epochs=60, es_patience=4, es_monitor='val_loss', es_mode='min', lr=learning_rate)\n",
    "\n",
    "\n",
    "        result.append([train_model.evaluate(train_target.val), train_model.evaluate(train_target.test)])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    average_mape_val = 0\n",
    "    average_mape_test = 0\n",
    "    \n",
    "    for result_i in range(len(result)):\n",
    "        average_mape_val += result[result_i][0][1]\n",
    "        average_mape_test += result[result_i][1][1]\n",
    "    \n",
    "    average_mape_val = average_mape_val/len(result)\n",
    "    average_mape_test = average_mape_test/len(result)\n",
    "\n",
    "\n",
    "\n",
    "    evaluation_result[stock_list[stock_index].name] = [average_mape_val, average_mape_test, result]\n",
    "\n",
    "\n",
    "\n",
    "    #data logging\n",
    "\n",
    "    if performance_log == True:\n",
    "\n",
    "        performance_log_csv = open(data_log_csv_path, 'a', encoding='UTF8', newline='')\n",
    "        csv_writer = csv.writer(performance_log_csv)\n",
    "        csv_writer.writerow([stock_list[stock_index].name, average_mape_val, average_mape_test, eval_iteration, len(train_df), len(val_df), len(test_df), train_model.name])\n",
    "        performance_log_csv.close()\n",
    "\n",
    "\n",
    "    #garbage collection test 1\n",
    "    del train_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all output of the dictionaries db\n",
    "\n",
    "for key, value in evaluation_result.items():\n",
    "    print(\"Stock Model for : \", key)\n",
    "    print(\"Average MAPE of val data_set : \", value[0])\n",
    "    print(\"Average MAPE of test data_set : \", value[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# header = [\"stock_code\",\"Average MAPE of val data_set\", \"Average MAPE of test data_set\", \"Iteration_number\"]   \n",
    "\n",
    "# with open(\"training_log/simple_models.csv\", 'w', encoding='UTF8', newline='') as file:\n",
    "\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     writer.writerow(header)\n",
    "\n",
    "#     for key, value in evaluation_result.items():\n",
    "#         writer.writerow([key, value[0], value[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e30d39d17b6777ac72c2de8bf454df1082287d1113e8e1d07731a2d8443e9a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
